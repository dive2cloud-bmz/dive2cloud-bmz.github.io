<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>postgreSql arch summary</title>
      <link href="/2025/04/28/postgreSql-arch-summary/"/>
      <url>/2025/04/28/postgreSql-arch-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title="逻辑架构"></a>逻辑架构</h2><p>有什么模块，每个模块干什么用<br><img src="/2025/04/28/postgreSql-arch-summary/arch.png"></p><ul><li>连接管理系统<br>管理客户端连接，透传请求，C&#x2F;S软件架构</li><li>编译执行系统<br>查询模块，负责 sqlParser，生成执行计划，优化等</li><li>存储管理系统<br>支持多种索引，btree hahs gist…<br>使用 slotted page 作为页结构，有一个自己的 buffer 机制加速存储访问</li><li>事务管理系统<br>MVCC：数据库的基石</li><li>系统表<br>元数据中心，各个模块相互协作的最重要的表。<br>系统表是被经常访问的，所以是长期放到 cache 里，并通过 hash 映射能够做到最低延迟的访问<blockquote><p>但实际上这也只是一张普通的表，可以 CRUD 的，恐怖</p></blockquote></li></ul><h2 id="物理架构"><a href="#物理架构" class="headerlink" title="物理架构"></a>物理架构</h2><p>具体有哪些进程，每个进程是做什么的</p><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>jdbc odbc libpq 等等,任何客户端和 pg 进程都是一对一的关系(process-per-connection)<br>一个后端进程同一时间只能处理一条请求，所以 pg 的并发是进程级的</p><blockquote><p>看似弱鸡，实际上是有利有弊</p></blockquote><h3 id="postmaster-和-postgres"><a href="#postmaster-和-postgres" class="headerlink" title="postmaster 和 postgres"></a>postmaster 和 postgres</h3><p>多进程架构下，需要一个中央协调者，这就是 postmaster，负责系统的初始化，分配共享内存，启动后台进程 backend，关闭 server，授权等等<br>管理客户端连接时，每一个新链接，postmaster 都会分配一个 postgres 进程来提供服务。<br>每个用户建立连接之后，postmaster 就会启动一次 sysLogger, pgStat, autoVacuum, WAL, bgWriter 等进程来提供服务。<br>postmaster 就是分配这些进程给新的连接，同时监听和调度这些进程。</p><h3 id="介绍一下-postmaster-启动的这些进程"><a href="#介绍一下-postmaster-启动的这些进程" class="headerlink" title="介绍一下 postmaster 启动的这些进程"></a>介绍一下 postmaster 启动的这些进程</h3><ol><li><p>共享内存和信号库<br>使用共享内存让各个进程互相通信，保证并发数据一致性</p></li><li><p>sysLogger<br>生成系统日志</p></li><li><p>bgWriter<br>周期性把 buffer 脏页写到永久存储，LRU策略，支持 checkpoint</p><blockquote><p>pg 不依赖这个进程把所有脏页落盘，其他进程也会写</p></blockquote></li><li><p>静态收集器<br>收集静态信息，比如表的访问信息，表的行数</p></li><li><p>WAL 写进程<br>周期性将 WAL flush 到永久内存，在多用户环境里，多个事务可以打包成一次 fsync。<br>pg 用单独的进程写 WAL 日志，避免其他事务提交的时候才落盘 WAL</p></li><li><p>pgArch WAL 归档进程<br>pg 有一个对 WAL 在磁盘上的存储形式：Xlog，专门用来归档备份。<br>核心目的还是怕 wal 无限增长(也就类似 fsImage + editLog,或者常规的 wal + snapshot 的方案)<br>因为 pg 单独有个写 WAL 的进程，所以也需要一个单独进程去归档</p></li><li><p>autoVacuum<br>pg 的清理策略是标记删除，所以需要额外清理的进程。<br>自主清理包括一个 launcher 监控进程 和 一个 worker 进程</p></li><li><p>pgStat<br>收集数据库系统运行时统计数据，可以开关来控制 cpu 负载</p></li><li><p>checkpoint<br>加速恢复<br><img src="/2025/04/28/postgreSql-arch-summary/img.png" alt="物理逻辑架构图"></p></li></ol><h2 id="从-SQL-到结果"><a href="#从-SQL-到结果" class="headerlink" title="从 SQL 到结果"></a>从 SQL 到结果</h2><p>从时间顺序我们看一下从SQL提交到返回结果的过程</p><ol><li>客户端请求<br>比如执行下面的 SQL<br><code>SELECT name FROM users WHERE age &gt; 30 ORDER BY age DESC LIMIT 10;</code></li></ol><ul><li>建立连接：无论你是什么客户端，都有一个建立连接的过程</li><li>发送请求：发送 SQL 语句到 postmaster</li><li>等待 postmaster 分配 backend 进程给这次连接</li></ul><ol start="2"><li><p>连接管理<br>postmaster 监听客户端请求，创建新的 backend 进程处理请求</p></li><li><p>SQL Parser<br>词法分析+语法分析，最后生成解析树，没什么好说的，全部 SQL 执行器都有的步骤</p></li><li><p>查询重写<br>如果查询涉及 view rule，就会重写查询计划</p><blockquote><p>约等于是一个执行计划的优化吧，没什么好说的</p></blockquote></li><li><p>查询优化<br>基本就是 explain 之后的计划，常规的像：</p></li></ol><ul><li>基于 CBO</li><li>索引优化：比如 age 有索引，那么使用 index scan 而不是 seq scan(全表扫)</li><li>排序优化：ORDER BY age DESC 这个语法会让优化器决定是否使用 index sort 还是 external sort(比如磁盘排序)</li><li>LIMIT 优化：可以提前停止查询，而不是全查出来再 LIMIT</li></ul><ol start="6"><li>执行计划<br>seq scan 或 index scan 读取数据，根据 explain 的计划执行算子</li><li>存储 buffer + wal<br>查询数据先在 shared buffers 里查找，找不到再走磁盘IO<br>如果 SQL 是 UPDATE&#x2F;INSERT&#x2F;DELETE，先写 WAL</li><li>返回结果<br>backend 会将结果封装为 JSON 或者 binary 返回给客户端，返回之后会清理临时资源（比如排序缓冲区）</li><li>客户端收到结果</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> pgsql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>duckDB</title>
      <link href="/2025/04/24/duckDB/"/>
      <url>/2025/04/24/duckDB/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我作为一个 former bigdata rd，对 OLAP 还是有所了解的。<br>但是我接触的都是分布式的 OLAP 系统，比如刚毕业时负责的 hive presto,<br>以及后面了解过 sparkSQL flinkSQL<br>还有一些没那么多机会接触但知道的，比如 impala+kudu 的组合, clickhouse 的单机性能派, kylin 的预计算派, 甚至说 ES 也可以支持很多 OLAP<br>无论 spark 的 DAG Batch 模式，还是 MPP 的模式，但他们都有统一的特性：<strong>分布式</strong><br>没有一个系统是单机的（可能这就是大数据），那么现在有一个系统，他能支持较小数据量的快速分析，又不需要分布式的资源(微型 clickhouse?)<br>这就是传说中的 duckDB<br>想了解一个新系统，我们先从他的官网入手，我今天先来自己用中文翻译一下，当做入门第一砖<br><a href="https://duckdb.org/why_duckdb">https://duckdb.org/why_duckdb</a></p><h2 id="原文翻译"><a href="#原文翻译" class="headerlink" title="原文翻译"></a>原文翻译</h2><h3 id="为什么用-duckDB"><a href="#为什么用-duckDB" class="headerlink" title="为什么用 duckDB"></a>为什么用 duckDB</h3><p>世面上有很多的 DBMS，但是没有一款数据库能承接全部规模的数据。<br>各个数据库都使用不同的策略来优化特定的场景。<br>duckDB 也一样。<br>我们现在就来聊聊 duckDB 有什么样的目标。为了达到这个目标，duckDB 用了哪些技术手段。<br>一句话描述 duckDB：一个支持 SQL 的关系型数据库管理系统</p><h3 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h3><h4 id="简单"><a href="#简单" class="headerlink" title="简单"></a>简单</h4><p>sqlite 是世界上应用最广的 DBMS。安装简单，可以嵌入到进程内部使用是他成功的关键。<br>duckDB 也采用了简单和嵌入的思想。<br>无论编译还是运行时，duckDB 没有任何外部依赖。对于 duckDB 的发布版本，整个源码树被编译成两个文件，一个头文件和一个 “实现文件”, 也被称作是 amalgamation</p><blockquote><p>在软件开发中，尤其是编译器或大型代码库中，amalgamation 可能指将多个源代码文件合并成一个单一的文件。<br>这通常用于简化构建过程和优化编译性能。<br>SQLite 数据库广泛使用 amalgamation 来将所有源代码文件合并成一个单一的文件，以简化分发和使用。</p></blockquote><p>这极大的简化了部署和在其他应用中集成的难度。对于构建来说，duckDB 只需要一个 C++ 11 的编译器。</p><p>对 duckDB 来说，不需要安装、升级、维护一个 DBMS 服务器。<br>因为 duckDB 不作为单独的进程运行，而是完全嵌入到<strong>宿主进程</strong>中。<br>因为 duckDB 主要用例都是分析相关的，所以这样设计有实现数据库高速数据传输的额外好处。<br>在一些情况下，duckDB 不用复制(或者说不用导入)任何数据就能处理外部数据。<br>比如： duckDB python 库可以直接在 pandas 进行数据查询，这期间不需要导入或拷贝任何数据</p><h4 id="便携性"><a href="#便携性" class="headerlink" title="便携性"></a>便携性</h4><p>由于没有外部依赖，duckDB 天生就是便携式的。可以在所有主流操作系统和 CPU 架构上跑。<br>可以在小型且资源有限的边缘设备部署，也可以在 100核+TB内存 的超大服务器部署。<br>使用 duckDB-Wasm(<a href="https://duckdb.org/docs/stable/clients/wasm/overview.html">https://duckdb.org/docs/stable/clients/wasm/overview.html</a>) 可以让 duckDB 跑在浏览器，甚至跑在手机上<br>DuckDB 提供 java c c++ <strong>go</strong> node.js 和其他语言的 api<br>详细请看：<a href="https://duckdb.org/docs/stable/clients/overview.html">https://duckdb.org/docs/stable/clients/overview.html</a></p><h4 id="功能丰富"><a href="#功能丰富" class="headerlink" title="功能丰富"></a>功能丰富</h4><p>duckDB 提供了很强大的数据管理功能。<br>有大型库函数、窗口函数等特性来支持处理复杂 SQL 查询。<br>通过自定义的、批量优化的 MVCC 来提供事务保证(ACID)。<br>数据也可以持久化在单文件的数据库文件中。<br>支持二级索引来加速查找单表记录<br>duckDB 在 python 和 R 深度集成，交互数据分析很高效方便</p><h4 id="快"><a href="#快" class="headerlink" title="快"></a>快</h4><p>设计的目标就是支持分析查询的工作负载(OLAP)。<br>workloads(工作负载) 的特点是：处理数据集大部分的复杂、耗时长的查询。</p><blockquote><p>PS:汉语翻译 workload 这个词怎么都不顺口，fuck aws，把这种词发扬光大了</p></blockquote><p>比如：整个表的聚合；在多个大表间的级联查询；<br>数据的变更也和 OLTP 不同，更多是面向大规模、同时多行追加，或者同时修改一张表的一大堆数据</p><p>为了更高效的支持这样的工作负载，很关键的一步是降低每个独立值扩展(expended)时 cpu 的消耗周期。<br>做到这步的最新数据管理技术，要么是用向量化执行，要么是用即席查询引擎<br>duckDB 使用<strong>列存向量查询引擎</strong>，查询仍然会被解释，但是大量的值（一种”向量”）会在同一个操作里处理</p><blockquote><p>类似 SIMD 在 os 内核里一下处理一大批</p></blockquote><p>相比 pg mysql 或 sqlite 这种逐行顺序处理，这最大程度的减少了系统开销。<br>向量化查询给 OLAP 引领了一条更好的性能路径</p><blockquote><p>我一度以为向量化是 CH 首次创新的技术，实际上他也是个推广者</p></blockquote><h4 id="扩展性"><a href="#扩展性" class="headerlink" title="扩展性"></a>扩展性</h4><p>duckDB 提供了灵活的扩展机制。<br>允许自定义新的数据类型，函数，文件格式和 SQL 预发<br>实际上很多 duckDB 的关键特性，比如支持 parquet json timezone，支持 s3 http(s) 都是利用的扩展接口实现的。<br>扩展也可以在 duckDB-wasm 中使用，我们可以自己贡献更多的社区扩展(<a href="https://duckdb.org/community_extensions/">https://duckdb.org/community_extensions/</a>)</p><blockquote><p>能否有一天我也成功 contribute 到 opensource community 一次呀，小心愿已经5年了</p></blockquote><h4 id="免费"><a href="#免费" class="headerlink" title="免费"></a>免费</h4><p>省流：<br>开发团队在荷兰<br>开源协议：MIT<br>知识产权由 duckDB 基金会所有</p><h4 id="测试充分"><a href="#测试充分" class="headerlink" title="测试充分"></a>测试充分</h4><p>虽然 duckDB 是从一个研究小组孵化的，但这不是原型或者什么玩具，而是要成为成熟稳定的数据库系统。<br>为了促进这种稳定性，duckDB 使用了 CI 的密集测试。<br>测试套件包含了数百万条查询，包括兼容 sqlite pgsql monetDB 的适配。<br>在多个平台和编译器上重复测试后，每个 pr 都必须经过全部测试通过才能合入<br>除了测试套件外，也有很多是高负载的压力测试，TPC-H 和 TPC-DS 都测了。</p><blockquote><p>拿这种事当特性属实有点没活硬整</p></blockquote><h2 id="同行-review-过的论文和理论"><a href="#同行-review-过的论文和理论" class="headerlink" title="同行 review 过的论文和理论"></a>同行 review 过的论文和理论</h2><p>Runtime-Extensible Parsers (CIDR 2025)<br>Robust External Hash Aggregation in the Solid State Age (ICDE 2024)<br>These Rows Are Made for Sorting and That’s Just What We’ll Do (ICDE 2023)<br>Join Order Optimization with (Almost) No Statistics (Master thesis, 2022)<br>DuckDB-Wasm: Fast Analytical Processing for the Web (VLDB 2022 Demo)<br>Data Management for Data Science - Towards Embedded Analytics (CIDR 2020)<br>DuckDB: an Embeddable Analytical Database (SIGMOD 2019 Demo)</p><h2 id="如何构建"><a href="#如何构建" class="headerlink" title="如何构建"></a>如何构建</h2><p><a href="https://github.com/davidgasquez/awesome-duckdb">https://github.com/davidgasquez/awesome-duckdb</a></p><h2 id="站在巨人的肩膀"><a href="#站在巨人的肩膀" class="headerlink" title="站在巨人的肩膀"></a>站在巨人的肩膀</h2><blockquote><p>看到这标题，我以为 aws 是不是又来吸血了，后面看是各个实现的模块是受哪些论文启发，还好还好</p></blockquote><ol><li><p>执行引擎：向量化执行引擎是受 Peter Boncz 等人在 monetDB 发的论文启发，MonetDB&#x2F;X100 后面成为 Vectorwise 系统，学的这篇 <a href="http://cidrdb.org/cidr2005/papers/P19.pdf">http://cidrdb.org/cidr2005/papers/P19.pdf</a></p></li><li><p>优化器：学的这篇：<a href="https://15721.courses.cs.cmu.edu/spring2020/papers/20-optimizer2/p539-moerkotte.pdf">https://15721.courses.cs.cmu.edu/spring2020/papers/20-optimizer2/p539-moerkotte.pdf</a></p><blockquote><p>讲道理是不是学学 ch 或者 calcite，不过 duckDB 团队估计也有考量</p></blockquote></li><li><p>并发控制：MVCC，学的这篇 <a href="https://db.in.tum.de/~muehlbau/papers/mvcc.pdf">https://db.in.tum.de/~muehlbau/papers/mvcc.pdf</a></p></li><li><p>二级索引：学的这篇 <a href="https://db.in.tum.de/~leis/papers/ART.pdf">https://db.in.tum.de/~leis/papers/ART.pdf</a></p></li><li><p>窗口函数：函数接口使用 <a href="https://www.vldb.org/pvldb/vol8/p1058-leis.pdf">https://www.vldb.org/pvldb/vol8/p1058-leis.pdf</a> 里的 Segment Tree Aggregation</p><blockquote><p>我估计是基于 cost aggregation，后面有空研究研究</p></blockquote></li><li><p>SQL 不等式级联：IEJoin 算法，学的 <a href="https://vldb.org/pvldb/vol8/p2074-khayyat.pdf">https://vldb.org/pvldb/vol8/p2074-khayyat.pdf</a></p></li><li><p>浮点数压缩：有多种算法，Chimp, Patas, ALP(adaptive lossless floating-point compression)</p></li><li><p>SQL 解析器：重新打包了 pg 的解析器作为单独的 lib</p><blockquote><p>笑 ^_^</p></blockquote></li><li><p>shell:直接就是 sqlite shell</p></li><li><p>正则表达式：google RE2</p></li><li><p>字符串格式化：fmt, <a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a></p></li><li><p>UTF 处理：utf8proc 库检查标准化 utf8</p></li><li><p>测试框架：Catch2</p></li><li><p>测试用例：sqlite一样的</p></li><li><p>结果验证：SQLancer</p></li><li><p>查询模糊测试(query fuzzing)：SQLsmith</p></li><li><p>JSON 解析器：ANSI C 编写的库 yyjson</p></li></ol><h2 id="原文地址"><a href="#原文地址" class="headerlink" title="原文地址"></a>原文地址</h2><p><a href="https://duckdb.org/why_duckdb">https://duckdb.org/why_duckdb</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> duckDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubectl</title>
      <link href="/2025/03/31/kubectl/"/>
      <url>/2025/03/31/kubectl/</url>
      
        <content type="html"><![CDATA[<p>官网 <a href="https://kubernetes.io/zh-cn/docs/reference/kubectl/">https://kubernetes.io/zh-cn/docs/reference/kubectl/</a></p><h2 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h2><p><code>kubectl [command] [TYPE] [NAME] [flags]</code></p><ol><li>command: 指定要对一个或多个资源执行的操作，例如 create、get、describe、delete。</li><li>TYPE：指定资源类型。资源类型不区分大小写， 可以指定单数、复数或缩写形式。例如：kubectl get pods pod1</li><li>NAME：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息。例如：kubectl get pods</li><li>flags： 指定可选的参数。例如，可以使用 -s 或 –server 参数指定 Kubernetes API 服务器的地址和端口。</li></ol><p>在对多个资源执行操作时，你可以按类型和名称指定每个资源，或指定一个或多个文件</p><ol><li><p>要按类型和名称指定资源：<br>要对所有类型相同的资源进行分组，请执行以下操作：TYPE1 name1 name2 name&lt;#&gt;。<br>例子：kubectl get pod example-pod1 example-pod2</p></li><li><p>分别指定多个资源类型：TYPE1&#x2F;name1 TYPE1&#x2F;name2 TYPE2&#x2F;name3 TYPE&lt;#&gt;&#x2F;name&lt;#&gt;。<br>例子：kubectl get pod&#x2F;example-pod1 replicationcontroller&#x2F;example-rc1</p></li><li><p>用一个或多个文件指定资源：-f file1 -f file2 -f file&lt;#&gt;</p></li><li><p>使用 YAML 而不是 JSON， 因为 YAML 对用户更友好, 特别是对于配置文件。<br>例子：kubectl get -f .&#x2F;pod.yaml</p></li></ol><h2 id="集群内身份验证和命名空间覆盖"><a href="#集群内身份验证和命名空间覆盖" class="headerlink" title="集群内身份验证和命名空间覆盖"></a>集群内身份验证和命名空间覆盖</h2><h3 id="身份认证"><a href="#身份认证" class="headerlink" title="身份认证"></a>身份认证</h3><p>不是部署了 kubectl 就能用了，首先要判断是否在一个 k8s 集群里</p><ol><li>首先检查 KUBERNETES_SERVICE_HOST 环境变量</li><li>其次检查 KUBERNETES_SERVICE_PORT 环境变量</li><li>最后检查 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token 中是否存在服务帐户令牌文件。</li></ol><p>如果三个条件都被满足，则假定在集群内进行身份验证。</p><blockquote><p>如果设置了 POD_NAMESPACE 环境变量，对命名空间资源的 CLI 操作对象将使用该变量值作为默认值</p></blockquote><h3 id="kubectl-如何处理-ServiceAccount-令牌"><a href="#kubectl-如何处理-ServiceAccount-令牌" class="headerlink" title="kubectl 如何处理 ServiceAccount 令牌"></a>kubectl 如何处理 ServiceAccount 令牌</h3><p>假设：</p><ol><li>有 Kubernetes 服务帐户令牌文件挂载在 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token 上，并且 </li><li>设置了 KUBERNETES_SERVICE_HOST 环境变量，并且 </li><li>设置了 KUBERNETES_SERVICE_PORT 环境变量，并且 </li><li>你没有在 kubectl 命令行上明确指定命名空间。</li></ol><p>然后 kubectl 假定它正在你的集群中运行。<br>kubectl 工具查找该 ServiceAccount 的命名空间 （该命名空间与 Pod 的命名空间相同）并针对该命名空间进行操作。 这与集群外运行的情况不同；<br>当 kubectl 在集群外运行并且你没有指定命名空间时， kubectl 命令会针对你在客户端配置中为当前上下文设置的命名空间进行操作。<br>要为你的 kubectl 更改默认的命名空间，你可以使用以下命令：<br><code>kubectl config set-context --current --namespace=&lt;namespace-name&gt;</code></p><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><ol><li>获取 ns 下的 pods 列表<br>k -n $nsName get pods</li><li>单独看一个 pod<br>k -n $nsName describe pod $podName</li><li>查看标准输出的日志<br>k -n $nsName logs $podName</li><li>交互式的进入到容器内<br>k -n $nsName exec -it $podName – &#x2F;bin&#x2F;bash<br>假如一个 pod 有多个容器，则使用 -c 指定容器名，容器名可以通过 describe 的命令获取到<br>k -n $nsName exec -it $podName -c $containerName – &#x2F;bin&#x2F;bash<blockquote><p>其余的慢慢摸索吧，目前 RDS op 时用这三个就足够了</p></blockquote></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>software design principle</title>
      <link href="/2025/03/28/software-design-principle/"/>
      <url>/2025/03/28/software-design-principle/</url>
      
        <content type="html"><![CDATA[<h2 id="开闭原则"><a href="#开闭原则" class="headerlink" title="开闭原则"></a>开闭原则</h2><p>修改时，执行关闭原则；扩展时，执行开放原则<br>增加新功能代码时，尽量不修改已有代码，然后将扩展的代码增加到项目中</p><h2 id="迪米特原则"><a href="#迪米特原则" class="headerlink" title="迪米特原则"></a>迪米特原则</h2><p>高内聚，低耦合<br>在开发代码时，类与类之间、模块与模块之间以及系统与系统之间，尽量保持低耦合，可以使得程序达到最大的复用</p><h2 id="里氏代换原则"><a href="#里氏代换原则" class="headerlink" title="里氏代换原则"></a>里氏代换原则</h2><p>即多态<br>声明方法参数时，尽量使用父类类型代替具体的类型，就能传递该父类类型的任何子类对象</p><h2 id="依赖倒转原则"><a href="#依赖倒转原则" class="headerlink" title="依赖倒转原则"></a>依赖倒转原则</h2><p>即面向抽象编程&#x2F;面向接口编程<br>在声明一个变量时，尽量使用父类类型或接口类型进行声明，而不是具体的类型</p><h2 id="接口隔离原则"><a href="#接口隔离原则" class="headerlink" title="接口隔离原则"></a>接口隔离原则</h2><p>定义接口时，尽量使接口功能单一</p><h2 id="合成-聚合复用原则"><a href="#合成-聚合复用原则" class="headerlink" title="合成&#x2F;聚合复用原则"></a>合成&#x2F;聚合复用原则</h2><p>对象的复用时，尽量使用关联关系，来代替继承关系。</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>开闭原则和迪米特原则是最基本的两大原则。</p><h2 id="更系统的总结"><a href="#更系统的总结" class="headerlink" title="更系统的总结"></a>更系统的总结</h2><p><img src="/2025/03/28/software-design-principle/image.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> dev </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>optional pattern</title>
      <link href="/2025/03/28/optional-pattern/"/>
      <url>/2025/03/28/optional-pattern/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在程序开发中，经常会遇到模块间的相互依赖问题，比如 模块A（如MySQL）需要调用模块B（如Config:读取配置）才能正常工作，那么我们说模块A依赖了模块B。<br>若是在模块A（MySQL）中直接使用（调用）了模块B(Config)的功能，那么我们说模块A耦合了模块B，比如我们模块A要新增加一种配置类型的支持，就只能要求模块B先升级才能实现。根据控制反转原则，可以将对模块A对模块B的内部耦合，变成对B的接口的依赖，在初始化模块A的时候，将B的实现作为参数传入模块A</p><h2 id="实际意义"><a href="#实际意义" class="headerlink" title="实际意义"></a>实际意义</h2><p>在保证扩展性之外，可以随意设置配置的默认值</p><h2 id="传统方案"><a href="#传统方案" class="headerlink" title="传统方案"></a>传统方案</h2><h3 id="逐个传参"><a href="#逐个传参" class="headerlink" title="逐个传参"></a>逐个传参</h3><ol><li>笨笨枚举<br><code>func NewMySQL2(a TypeA,b TypeB,c TypeC,d TypeD)MySQL</code></li><li>最后可变（但类型一样）<br><code>func NewMySQL(a TypeA,b TypeB,c TypeC,d TypeD…)MySQL</code></li><li>最后可变（类型也可以变）<br><code>func NewMySQL(a TypeA,b TypeB,c TypeC,ps interface&#123;&#125;…)MySQL</code><br>这样函数可以支持多个参数，但是由于最后的 interface{} 导致可读性变差<br>而且需要断言才能用，使用难度大了</li></ol><h3 id="传递-struct"><a href="#传递-struct" class="headerlink" title="传递 struct"></a>传递 struct</h3><p>挨个传参对后续扩展新参数场景支持挺一般的，那么用 struct 传参可以解决这个问题，在增加新字段的同时函数签名也没变<br><code>func NewMySQL(p Params)MySQL</code></p><ol><li>笨蛋定义</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type Params struct &#123;</span><br><span class="line">    A int</span><br><span class="line">    B string</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比较简单直观，但是默认值全是零值了，参数一多写一堆 if else，很屎</p><ol start="2"><li>内部指针定义</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type Params struct &#123;</span><br><span class="line">    A *int</span><br><span class="line">    B *string</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>判断 A B 是否为 nil 来决定用什么默认值</p><h3 id="选项模式"><a href="#选项模式" class="headerlink" title="选项模式"></a>选项模式</h3><p>选项模式其英文名称叫 Functional Options Pattern，中文名功能选项模式。该模式在众多 Go 开源项目中都有使用，如 gRPC-go 项目，在 GDP2 中也有大量采用，可以帮我们提供一个更好用的函数传参的方式。<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">// Option 定义的选项类型 </span><br><span class="line">type Option interface&#123;</span><br><span class="line">   apply(do * mysqlOptions)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 也可以不定义成interface,而定义为一个func</span><br><span class="line">//  比如 type Option func(do * mysqlOptions)</span><br><span class="line"></span><br><span class="line">type mysqlOptions struct&#123;</span><br><span class="line">   readTimeout int</span><br><span class="line">   writeTimeout int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func NewMySQL(opts …Option) MySQL&#123;</span><br><span class="line">  // 默认值</span><br><span class="line">  opt:= &amp;mysqlOptions&#123;</span><br><span class="line">        readTimeout:100,</span><br><span class="line">        writeTimeout:50,</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  // 传入的选项将默认值替换掉</span><br><span class="line">  for _, o:=range opts&#123;</span><br><span class="line">     o.apply(opt)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 一个实际实现 Option 接口的 struct，代表一类 Option</span><br><span class="line">type funcsOptionTPL struct &#123;</span><br><span class="line">   f func(*mysqlOptions)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 实现 Option</span><br><span class="line">func (fdo *funcsOptionTPL) apply (do *mysqlOptions) &#123;</span><br><span class="line">   fdo.f(do)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 每个实际配置项都会 return 一个 funcsOptionTPL</span><br><span class="line">func newFuncOption(f func(*mysqlOptions)) *funcsOptionTPL &#123;</span><br><span class="line">   return &amp;funcsOptionTPL&#123;</span><br><span class="line">      f: f,</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 定义一个设置ReadTimeout的Option，实际的配置项只需要写一个匿名函数作为形参传入 newFuncOption</span><br><span class="line">func OptReadTimeout(t int) Option&#123;</span><br><span class="line">   return newFuncOption(func(opts *mysqlOptions) &#123;</span><br><span class="line">      opts.readTimeout=t</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">// 定义一个设置WriteTimeout的Option</span><br><span class="line">func OptWriteTimeout(t int) Option&#123;</span><br><span class="line">   return newFuncOption(func(opts *mysqlOptions) &#123;</span><br><span class="line">      opts.writeTimeout=t</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 实际调用</span><br><span class="line">// 方式1：使用缺省参数初始化</span><br><span class="line">client：=NewMySQL()</span><br><span class="line"></span><br><span class="line">方式2：传入option初始化</span><br><span class="line">Client:=NewMySQL(OptReadTimeout(50),OptWriteTimeout(200))</span><br></pre></td></tr></table></figure><p>这样的好处就是当增加或者减少 opts 的时候，opt 之间完全是独立的(没有耦合)<br>无脑定义鸭子类型就完事儿了，可读性也不错，是很高级的用法。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker</title>
      <link href="/2025/03/25/docker/"/>
      <url>/2025/03/25/docker/</url>
      
        <content type="html"><![CDATA[<h2 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h2><p>想要了解 docker，首先要知道容器 和 虚拟机之间的区别。<br><img src="/2025/03/25/docker/diff.png"><br>虚拟机是利用硬件虚拟化技术，将一台物理机分隔成多个逻辑隔离的单元，不同虚拟机共享相同的物理机硬件。虚拟机是在物理机的基础上做分隔，每个虚拟机都是独立的一个操作系统，互不干扰，所以它的隔离性非常好。图中的GuestOS就是一个独立的操作系统，而 Docker 中的应用都是在同一个操作系统中。<br>Docker 的目的是将运行起来的应用，隔离在一个有边界的进程中，仿佛这个边界（容器）里只有它自己，而看不到操作系统周围的其他进程</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><img src="/2025/03/25/docker/core.png"><br>docker容器能隔离宿主机有三个核心技术，分别是 ns cgroups rootfs<br>cgroups 是 ns 的一个类型，但是他尤为重要，所以单独列出</p><h3 id="首先我们思考一个问题：容器与进程有何不同？"><a href="#首先我们思考一个问题：容器与进程有何不同？" class="headerlink" title="首先我们思考一个问题：容器与进程有何不同？"></a>首先我们思考一个问题：容器与进程有何不同？</h3><ul><li><p>进程：就是程序运行起来后的计算机执行环境的总和。<br>即：计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。</p></li><li><p>容器：核心就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。<br>对于 Docker 等大多数 Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而 Namespace 技术则是用来修改进程视图的主要方法。<br>当我们通过docker run -it启动并进入一个容器之后，会发现不论是进程、网络还是文件系统，好像都被隔离了,就像这样</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@docker cpu]# docker run -it busybox</span><br><span class="line">/ # </span><br><span class="line">/ # ps</span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 sh</span><br><span class="line">    7 root      0:00 ps</span><br><span class="line">/ # ip a </span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">120: eth0@if121: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue </span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">/ # ls</span><br><span class="line">bin    dev    etc    home   lib    lib64  proc   root   sys    tmp    usr    var</span><br></pre></td></tr></table></figure><p>ps 命令看不到宿主机上的进程<br>ip 命令也只能看到容器内部的网卡<br>ls 命令看到的文件好像也和宿主机不一样<br>DOCKER 让容器和宿主机隔离开的核心，是依靠 <strong>linux 的 namespace</strong> 技术来实现了视图隔离。</p><h3 id="Linux-Namespace"><a href="#Linux-Namespace" class="headerlink" title="Linux Namespace"></a>Linux Namespace</h3><p>NameSpace是Linux中用来做资源隔离和虚拟化的特性。目的是将某个特定的全局系统资源通过抽象方法使得 namespace 中的进程看起来<strong>拥有它们自己的隔离的全局系统资源实例</strong><br>Linux提供了如下几种 NameSpace<br><img src="/2025/03/25/docker/ns.png"><br>相关的底层函数<br><img src="/2025/03/25/docker/ns-api.png"></p><ul><li>clone、unshare：加入新 namespace</li></ul><ul><li>unshare 是使 当前进程 加入新的 namespace</li><li>clone 是创建一个新的子进程，然后让 子进程 加入新的 namespace，而当前进程保持不变</li></ul><ul><li>setsns：加入已有 namespace</li><li>ioctl_ns：主要用于查询</li></ul><p>查看一个进程的 ns:<br><code>ls -l /proc/[pid]/ns</code><br><img src="/2025/03/25/docker/proc-ns.png"><br>LINUX 限制了 namespace 的数量，比如在我这台虚机中，一个虚机中 PID 最多创建62355个：<br><code>cat /proc/sys/user/max_pid_namespaces</code><br><code>62355</code><br>既然数量有限制，那已经创建的 namespace 什么时候会被销毁回收呢？<br>答案：当一个 namespace 中的所有进程都结束或者移出该 namespace 时，该 namespace 将会被销毁。<br>这也解释了为什么没有创建 namespace 的 API，因为刚创建的 namespace 没有任何进程，立马就会被回收。<br>也有特殊情况，查看<a href="https://www.lixueduan.com/posts/docker/05-namespace/">https://www.lixueduan.com/posts/docker/05-namespace/</a> 见真招<br>一句话描述：<strong>当 namespace 有被使用时就不会被回收，反之则会被回收。</strong></p><h4 id="PID"><a href="#PID" class="headerlink" title="PID"></a>PID</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@devstack:/home/sammy# ps -ef | grep python</span><br><span class="line">root 2198 2179 0 00:06 ? 00:00:00 python app.py</span><br><span class="line"></span><br><span class="line">root@devstack:/home/sammy# ps -ef | grep 2179</span><br><span class="line">root 2179 765 0 00:06 ? 00:00:00 docker-containerd-shim 8b7dd09fbcae00373207f01e2acde45740871c9e3b98286b5458b4ea09f41b3e /var/run/docker/libcontainerd/8b7dd09fbcae0038b4ea09f41b3e docker-runc</span><br><span class="line">root 2198 2179 0 00:06 ? 00:00:00 python app.py</span><br><span class="line">root 2249 1692 0 00:06 pts/0 00:00:00 grep --color=auto 2179</span><br><span class="line"></span><br><span class="line">root@devstack:/home/sammy# docker exec -it web31 ps -ef</span><br><span class="line">UID PID PPID C STIME TTY TIME CMD</span><br><span class="line">root 1 0 0 16:06 ? 00:00:00 python app.py</span><br></pre></td></tr></table></figure><p>我们能看到同一个进程，在容器内外的 PID 是不同的：</p><ul><li>在容器内 PID 是 1，PPID 是 0。</li><li>在容器外 PID 是 2198， PPID 是 2179 即 docker-containerd-shim 进程.</li></ul><p>containerd, container-shim 和 container 关系 如下<br><img src="/2025/03/25/docker/relation.png"></p><p>总结：pid namespace 通过将 host 上 PID 映射为容器内的 PID， 使得容器内的进程看起来有个独立的 PID 空间。</p><h4 id="UTS"><a href="#UTS" class="headerlink" title="UTS"></a>UTS</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@devstack:/home/sammy# hostname</span><br><span class="line">devstack</span><br><span class="line">root@devstack:/home/sammy# docker exec -it web31 hostname</span><br><span class="line">8b7dd09fbcae</span><br></pre></td></tr></table></figure><h4 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h4><p>docker 1.10 版本之前，是不支持 user namespace 的。因为在这之前这个特性有安全问题</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@devstack:/home/sammy# docker exec -ti web34 id</span><br><span class="line">uid=0(root) gid=0(root) groups=0(root)</span><br><span class="line">root@devstack:/home/sammy# id</span><br><span class="line">uid=0(root) gid=0(root) groups=0(root)</span><br></pre></td></tr></table></figure><ul><li>启动一个容器： docker run -d -v &#x2F;bin:&#x2F;host&#x2F;bin –name web34 training&#x2F;webapp python app.py </li><li>此时进程的用户在容器内和外都是root，它在容器内可以对 host 上的 &#x2F;bin 目录做任意修改<br>docker 1.10 之后，让容器内有一个假的 root 用户，他在容器内是 root，在容器外会映射到非root 用户了。也就是user ns 实现了 host users 和 container users 之间的映射。具体步骤不展示了，知道有这个映射就好</li></ul><h4 id="NETWORK"><a href="#NETWORK" class="headerlink" title="NETWORK"></a>NETWORK</h4><p>当 docker 实例被创建出来后，使用 ip netns 命令无法看到容器实例对应的 network namespace。这是因为 ip netns 命令是从 &#x2F;var&#x2F;run&#x2F;netns 文件夹中读取内容的。</p><h3 id="CGROUPS"><a href="#CGROUPS" class="headerlink" title="CGROUPS"></a>CGROUPS</h3><p>Linux Cgroups 的全称是 Linux Control Group。<br>隔离资源的核心 ns，这块是值得单独开篇讲解的。<br>cgroups 最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。<br>docker run 启动容器时可以通过增加 –cpus 或者 –memory flag 来指定 cpu、内存限制。这个功能就是借助 cgroup 完成的。</p><h3 id="能控制的资源"><a href="#能控制的资源" class="headerlink" title="能控制的资源"></a>能控制的资源</h3><p>linux 系统中 cgroups 提供给用户操作的接口，就是文件系统本身，以文件和目录形式组织到 &#x2F;sys&#x2F;fs&#x2F;cgroup 路径下<br>执行 mount -t cgroup 可以查看有哪些资源可以被 cgroup 限制</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master-876e2c3-1 ~]# mount -t cgroup</span><br><span class="line">cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)</span><br><span class="line">cgroup on /sys/fs/cgroup/tcp_throt type cgroup (rw,nosuid,nodev,noexec,relatime,tcp_throt)</span><br><span class="line">cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_cls type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls)</span><br><span class="line">cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">cgroup on /sys/fs/cgroup/tos_cgroup type cgroup (rw,nosuid,nodev,noexec,relatime,tos_cgroup)</span><br><span class="line">cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)</span><br><span class="line">cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br><span class="line">cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br></pre></td></tr></table></figure><p>这里&#x2F;sys&#x2F;fs&#x2F;cgroup下每个子目录都是一个类型，比如 blkio cpu memory 等<br>比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master-876e2c3-1 ~]# ls /sys/fs/cgroup/cpu</span><br><span class="line">cgroup.clone_children  cpuacct.bt_usage         cpuacct.usage_all          cpuacct.usage_sys   cpu.cfs_period_us  cpu.rt_period_us   notify_on_release</span><br><span class="line">cgroup.procs           cpuacct.bt_usage_percpu  cpuacct.usage_percpu       cpuacct.usage_user  cpu.cfs_quota_us   cpu.rt_runtime_us  release_agent</span><br><span class="line">cgroup.sane_behavior   cpuacct.stat             cpuacct.usage_percpu_sys   cpu.bt_shares       cpu.ht_clean_tag   cpu.shares         tasks</span><br><span class="line">cpuacct.bt_stat        cpuacct.usage            cpuacct.usage_percpu_user  cpu.cfs_burst_us    cpu.offline        cpu.stat</span><br></pre></td></tr></table></figure><p>通过改配置，可以限制某个进程对 CPU 的使用率</p><h4 id="限制-CPU-举例"><a href="#限制-CPU-举例" class="headerlink" title="限制 CPU 举例"></a>限制 CPU 举例</h4><p>需要在对应的子系统下面创建一个目录，比如，我们现在进入 &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu 目录下创建名为 container 的目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@docker ~]# cd /sys/fs/cgroup/cpu</span><br><span class="line">[root@docker cpu]# mkdir container</span><br></pre></td></tr></table></figure><p>这个目录就是一个“控制组”。操作系统会在新创建的 container 目录下，自动生成该子系统对应的资源限制文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@docker cpu]# ls container</span><br><span class="line">cgroup.clone_children  cpuacct.stat   cpuacct.usage_all     cpuacct.usage_percpu_sys   cpuacct.usage_sys   cpu.cfs_period_us  cpu.rt_period_us   cpu.shares  notify_on_release</span><br><span class="line">cgroup.procs           cpuacct.usage  cpuacct.usage_percpu  cpuacct.usage_percpu_user  cpuacct.usage_user  cpu.cfs_quota_us   cpu.rt_runtime_us  cpu.stat    tasks</span><br></pre></td></tr></table></figure><p>接下来我们就通过修改配置文件对 CPU 进行限制，这里就用前面创建的 container 这个“控制组”。<br>主要通过以下三个文件来实现</p><ol><li>cpu.cfs_quota_us：每个控制周期内，进程可以使用的 cpu 时间，默认为 -1，即不做限制。</li><li>cpu.cfs_period_us：控制周期，默认为 100 ms</li><li>tasks：记录被限制进程的 PID 列表</li></ol><p>cgroups 会限制所有在 tasks 中的进程，在 cpu.cfs_period_us 周期内，最多只能使用 cpu.cfs_quota_us 的 cpu 资源。<br>比如，100ms 能限制只能使用 20ms，即最多占用 0.2 核心<br>首先，我们在后台执行这样一条脚本:<br><code>[root@docker cpu]# while : ; do : ; done &amp;</code><br>[1] 3892<br>显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%。根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 3892。<br>执行 Top 查看一下 CPU 占用，可以看到这个 3892 进程占用了差不多 100% 的 CPU，把一个核心占满了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@docker cpu]# top</span><br><span class="line">top - 16:07:06 up 286 days,  4:31,  3 users,  load average: 0.59, 0.50, 0.50</span><br><span class="line">Tasks:  97 total,   2 running,  48 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem :  1006956 total,   166520 free,   190840 used,   649596 buff/cache</span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used.   549216 avail Mem </span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                                                                                       </span><br><span class="line"> 3892 root      20   0  115684    532      0 R 92.0  0.1   0:48.64 bash</span><br></pre></td></tr></table></figure><p>此时，我们就可以通过配置 cgroups 来实现对该进程的 CPU 使用情况进行限制。<br>默认情况下 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us），因此上述进程可以占用整个 CPU</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@docker cpu]# echo 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us</span><br><span class="line">[root@docker cpu]# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us</span><br><span class="line">20000</span><br></pre></td></tr></table></figure><p>最后则是将进程 PID 写入 tasks 文件里，是配置生效</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@docker cpu]# echo 3892 &gt; /sys/fs/cgroup/cpu/container/tasks </span><br><span class="line">[root@docker cpu]# cat /sys/fs/cgroup/cpu/container/tasks</span><br><span class="line">3892</span><br></pre></td></tr></table></figure><p>然后查看是否生效</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@docker cpu]# top</span><br><span class="line">top - 16:13:56 up 286 days,  4:38,  3 users,  load average: 0.20, 0.61, 0.59</span><br><span class="line">Tasks:  94 total,   2 running,  48 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s): 21.6 us,  0.0 sy,  0.0 ni, 78.1 id,  0.0 wa,  0.0 hi,  0.0 si,  0.3 st</span><br><span class="line">KiB Mem :  1006956 total,   166552 free,   190808 used,   649596 buff/cache</span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used.   549248 avail Mem </span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                                                                                       </span><br><span class="line"> 3892 root      20   0  115684    532      0 R 19.9  0.1   5:56.94 bash</span><br></pre></td></tr></table></figure><p>可以看到，果然 3892 CPU 被限制到了 20%</p><h4 id="检查OS是否启用了-namespace"><a href="#检查OS是否启用了-namespace" class="headerlink" title="检查OS是否启用了 namespace"></a>检查OS是否启用了 namespace</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@master-876e2c3-1 ~]# uname -a</span><br><span class="line">Linux master-876e2c3-1 5.10.0-3.0.1.8 #6 SMP Wed Mar 27 18:59:12 CST 2024 x86_64 x86_64 x86_64 GNU/Linux</span><br><span class="line">[root@master-876e2c3-1 ~]# cat /boot/config-5.10.0-3.0.1.8 |grep _NS</span><br><span class="line">CONFIG_UTS_NS=y</span><br><span class="line">CONFIG_TIME_NS=y</span><br><span class="line">CONFIG_IPC_NS=y</span><br><span class="line">CONFIG_USER_NS=y</span><br><span class="line">CONFIG_PID_NS=y</span><br><span class="line">CONFIG_NET_NS=y</span><br></pre></td></tr></table></figure><p>CONFIG_USER_NS&#x3D;y 代表 USER_NS 启用了，其他的 ns 也一样</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>cgroup 在文件系统上定义了一组限制资源的目录<br>所以对于 docker 这种容器来说，只需要在每个子系统下面添加 “控制组”的目录，在启动容器进程后将进程 pid 写到 控制组 tasks 文件中。docker run 的时候传入的参数，实际落地就是去修改这些cgroup 文件和内容</p><h3 id="rootfs"><a href="#rootfs" class="headerlink" title="rootfs"></a>rootfs</h3><h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>将运行环境打包成镜像，避免环境问题导致应用无法运行。<br>先抛出下面三个问题</p><ol><li>为什么在容器中修改了文件宿主机不受影响？</li><li>容器中的文件系统是哪儿来的？ </li><li>docker 镜像又是怎么实现的？</li></ol><h4 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h4><p>经过 mount ns 隔离后，容器中的文件系统是独立的。在容器启动前，docker 通过 mount ns 将容器根目录挂载了，所以容器修改了文件宿主机不感知。<br>linux 中的 chroot 命令很方便完成这个工作，而 mount ns 正是基于 chroot 改良而来的，它也是第一个 ns<br>第一个问题的答案就是：mount ns 隔离的</p><h4 id="rootfs-1"><a href="#rootfs-1" class="headerlink" title="rootfs"></a>rootfs</h4><p>是一个操作系统包含的文件、配置和目录，但不包含操作系统内核<br>在 linux OS 中，只有在开机启动时才会加载指定版本的内核镜像。所以 linux os 里内核和rootfs 是分开存放的<br><img src="/2025/03/25/docker/rootfs.png"></p><blockquote><p>这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。<br>但也是由于 rootfs 的存在，docker 才能一直宣传 ‘一致性” 的特性。<br>第二个问题：文件系统从哪儿来？<br>答案：构建镜像的时候打包进去的，然后容器启动时挂载到根目录下面了</p></blockquote><h3 id="镜像层"><a href="#镜像层" class="headerlink" title="镜像层"></a>镜像层</h3><p>Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。<br>这个本质上是复用了 rootfs，在docker 里这种能力称之为 union fs，他的功能是将多个不同位置的目录联合挂载到同一个目录下。</p><p>例如将目录 A 和目录 B 挂载到目录 C 下面，这样目录 C 下就包含目录 A 和目录 B 的所有文件。<br>由于看不到目录 A 和 目标 B 的存在，因此就好像 C 目录就包含这么多文件一样<br>unionfs 有不同的实现，docker info 可以查看， ubuntu 使用 aufs，centos 使用 overlay2<br>union mount 在最上层，提供了统一的视图，用户看起来好像整个系统只有一层一样，实际上下面包含了很多层。<br><img src="/2025/03/25/docker/root-image.png"></p><p>最后一个问题：docker 镜像又是怎么实现的？<br>通过引入 layer 概念进行分层，借助 联合文件系统（Union File System）进行叠加，最终构成了完整的镜像</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="镜像-Image"><a href="#镜像-Image" class="headerlink" title="镜像(Image)"></a>镜像(Image)</h3><p>相当于一个root文件系统</p><h3 id="容器-container"><a href="#容器-container" class="headerlink" title="容器(container)"></a>容器(container)</h3><p>容器与镜像的关系，类似于面向对象里实例和类一样，容器是运行时的实体。容器可以被创建、启动、停止、删除、暂停等</p><h3 id="仓库-repository"><a href="#仓库-repository" class="headerlink" title="仓库(repository)"></a>仓库(repository)</h3><p>类似github 这种代码控制中心，用于保存镜像</p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>docker 使用 C&#x2F;S 架构，使用远程 API 管理和创建 docker 容器<br><img src="/2025/03/25/docker/arch.png"><br>一些解释<br><img src="/2025/03/25/docker/arch-explain.png"></p><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p><img src="/2025/03/25/docker/usual-cmd.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>page cache</title>
      <link href="/2025/03/25/page-cache/"/>
      <url>/2025/03/25/page-cache/</url>
      
        <content type="html"><![CDATA[<h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><p><img src="/2025/03/25/page-cache/read.png"></p><ol><li>app 调用系统 read() 用户态切换到内核态 </li><li>fs 通过目录项,页缓存树看 page cahce 是否存在,有的话直接从page cache 读数据,避免物理磁盘 I&#x2F;O 操作 </li><li>page cache 不存在,则产生缺页中断, CPU 向 DMA 发出指令</li><li>DMA 向 CPU 发出数据读完的信号,由CPU 负责将数据从内核缓冲区拷贝到用户缓冲区</li><li>用户进程从内核态回到用户态,获得到文件数据</li></ol><h2 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h2><p><img src="/2025/03/25/page-cache/write.png"></p><ol><li>app 调用系统 write(),用户态进到内核态 </li><li>FS 通过目录项和 pc 树查看 page cache 是否存在,没有就要创建 </li><li>page cache 存在后,CPU 将数据从用户缓冲区拷到内核缓冲区, page cache 变为脏页(内存数据和磁盘数据不一致),写流程返回 </li><li>用户主动触发刷盘或达到特定条件内核触发刷盘,唤醒 pdflush 线程,将内核缓冲区数据刷入磁盘</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ddd</title>
      <link href="/2025/03/25/ddd/"/>
      <url>/2025/03/25/ddd/</url>
      
        <content type="html"><![CDATA[<p>这篇文章写的不错<br><a href="https://juejin.cn/post/7298160530292703244">https://juejin.cn/post/7298160530292703244</a></p><h2 id="我对-MVC-和-DDD-的理解"><a href="#我对-MVC-和-DDD-的理解" class="headerlink" title="我对 MVC 和 DDD 的理解"></a>我对 MVC 和 DDD 的理解</h2><p><img src="/2025/03/25/ddd/image.png"></p><h3 id="MVC-和-DDD-的概念区别"><a href="#MVC-和-DDD-的概念区别" class="headerlink" title="MVC 和 DDD 的概念区别"></a>MVC 和 DDD 的概念区别</h3><p>MVC 是基于贫血模型的,将数据和业务逻辑分到两层,重 Service 层,轻 BO,破坏了面向对象,是面向过程的思路<br>DDD 是充血模型的,数据和业务逻辑被封装到同一个 “类” 之中,轻 Service ,重 Domain,是符合面向对象的.</p><h3 id="DDD-优势"><a href="#DDD-优势" class="headerlink" title="DDD 优势"></a>DDD 优势</h3><p>反应真实业务而不是只有 RD 能看懂:重点放到业务领域,让开发人员更好与业务专家沟通,反应真实世界的业务逻辑<br>模块化:每个 domain 负责自己的事<br>可重用:各个应用层可以任意组合各个 domain<br>解决复杂性和变化:复杂业务问题分解为领域对象和领域服务,通过界限上下文和聚合根处理业务规则和一致性.对外部依赖也低</p><h3 id="DDD-劣势"><a href="#DDD-劣势" class="headerlink" title="DDD 劣势"></a>DDD 劣势</h3><p>先有方法论,落地还需实践<br>性能:DDD 基于聚合来组织代码,高性能场景加载聚合中大量无用字段会影响性能<br>事务:被限定到了界限上下文内,处理跨多个界限上下文时,开发人员需要面对分布式事务,难度大<br>需要领域专家:开发者要求高,必须会合理抽象这些领域对象</p><h3 id="MVC-优势"><a href="#MVC-优势" class="headerlink" title="MVC 优势"></a>MVC 优势</h3><p>简单:谁都会分三层写代码,很无脑<br>开发快(堆屎也快)<br>成熟生态体系:很多框架\工具帮 RD 干了很多事</p>]]></content>
      
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>raft</title>
      <link href="/2025/03/24/raft/"/>
      <url>/2025/03/24/raft/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>简单了解直接看 <a href="https://thesecretlivesofdata.com/raft/">https://thesecretlivesofdata.com/raft/</a><br>但是这里有一些词语不准确，可能会让人误解。<br>二手理解 blog 80%是一知半解，负分滚粗，我直接看论文<br>英文原文地址 <a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf">https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf</a><br>中文翻译地址 <a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>aft 是一个共识算法（consensus algorithm），所谓共识，就是即使是在部分节点故障、网络延时、网络分割的情况下，多个节点对某个事情也能达成一致的看法。<br>raft 是工程上使用较为广泛的强一致性、去中心化、高可用的分布式协议。<br>在 raft 之前工程上最有名的 paxos，但是 paxos 太难理解，很多人读不懂还在出书写博客瞎谈感受误导别人。</p><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>为了易于理解，raft 主要做了两件事：</p><ol><li>问题分解<br>将复杂问题“复制集中节点一致性”拆分为多个子问题，使得每个子问题可以独立地被解释、理解和解决。在 raft，子问题包括<br>leader election：当前 leader 故障时，必须有一个新 leader 被选举出来<br>log replication：leader 必须从客户端接受 log entires，然后复制到其他节点，并强制要求其他节点的日志与自己相同<br>safety：任何服务器节点已经应用了一个确定的 log entires 到他的状态机中，那么其他节点不能在同一个日志索引位置 apply 一个不同的指令<br>membership changes：有时会变更集群的配置，比如增减节点等，有一个良好的机制不用停服就能做到</li><li>状态简化<br>对算法做出一些限制，减少需要考虑的状态数，使得算法更加清晰，更少的不确定性（比如，保证新选举出来的 leader 会包含所有 commited log entry）</li></ol><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>先选出 leader，同一时间只有一个leader，leader 完全负责 replicated log 管理。<br>leader 负责接受所有客户端更新请求，请求会记录成日志，然后 leader 复制日志到 follower 节点，并在“安全”的时候执行这些请求。<br>如果 leader 故障，followers 会重新选举出新的 leader。</p><h2 id="RAFT-算法特性"><a href="#RAFT-算法特性" class="headerlink" title="RAFT 算法特性"></a>RAFT 算法特性</h2><p>raft 在任何时候都保证下面的特性<br><img src="/2025/03/24/raft/algo.png"></p><h3 id="选举安全特性"><a href="#选举安全特性" class="headerlink" title="选举安全特性"></a>选举安全特性</h3><p>对于一个给定的任期号，最多只会有一个领导人被选举出来</p><h3 id="领导人只附加原则"><a href="#领导人只附加原则" class="headerlink" title="领导人只附加原则"></a>领导人只附加原则</h3><p>领导人绝对不会删除或者覆盖自己的日志，只会增加</p><h3 id="日志匹配原则"><a href="#日志匹配原则" class="headerlink" title="日志匹配原则"></a>日志匹配原则</h3><p>如果两个日志在某一相同索引位置日志条目的任期号相同，那么我们就认为这两个日志从头到该索引位置之间的内容完全一致</p><h3 id="领导人完全特性"><a href="#领导人完全特性" class="headerlink" title="领导人完全特性"></a>领导人完全特性</h3><p>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中</p><h3 id="状态机安全特性"><a href="#状态机安全特性" class="headerlink" title="状态机安全特性"></a>状态机安全特性</h3><p>如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用到不同的日志条目</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p>raft 协议中，一个节点任一时刻处于以下三个状态之一：</p><ol><li>leader</li><li>follower</li><li>candidate</li></ol><p>给出状态转移图能很直观的直到这三个状态的区别<br><img src="/2025/03/24/raft/state.png"><br>可以看出所有节点启动时都是 follower 状态；<br>在一段时间内如果没有收到来自 leader 的心跳，从 follower 切换到 candidate，发起选举；<br>如果收到 majority 的造成票（含自己的一票）则切换到 leader 状态；<br>如果发现其他节点比自己更新，则主动切换到 follower。<br>总结一下：<br>系统中最多只有一个 leader，如果在一段时间里发现没有 leader，则大家通过选举-投票选出 leader。<br>leader 会不停地给 follower 发心跳消息，表明自己的存活状态。<br>如果 leader 故障，那么 follower 会转换成 candidate，重新选出 leader。</p><h3 id="term"><a href="#term" class="headerlink" title="term"></a>term</h3><p>从上面可以看出，哪个节点做 leader 是大家投票选举出来的，每个 leader 工作一段时间，然后选出新的 leader 继续负责。<br>这跟民主社会的选举很像，每一届新的履职期称之为一届任期，在 raft 协议中，也是这样的，对应的术语叫 term。<br><img src="/2025/03/24/raft/term.png"><br>term（任期）以选举（election）开始，然后就是一段或长或短的稳定工作期（normal Operation）。从上图可以看到，任期是递增的，这就充当了逻辑时钟的作用；另外，term 3 展示了一种情况，就是说没有选举出 leader 就结束了，然后会发起新的选举，后面会解释这种 split vote 的情况。</p><h2 id="leader-election"><a href="#leader-election" class="headerlink" title="leader election"></a>leader election</h2><p>服务器刚启动时，全部节点都是 follower；<br>当 follower 经过一段时间后还没有接到任何RPC（选举超时），那么他就认为系统中没有 leader，自己开始发起选举；<br>leader 会周期性的发送 appendEntries rpcs 来维持权威；</p><h3 id="选举过程"><a href="#选举过程" class="headerlink" title="选举过程"></a>选举过程</h3><p>如果 follower 在 election timeout 内没有收到来自 leader 的心跳，（也许此时还没有选出 leader，大家都在等；也许 leader 挂了；也许只是 leader 与该 follower 之间网络故障），则会主动发起选举。步骤如下：</p><ol><li>增加节点本地的 current term，同时自己变成 candidate 状态</li><li>投自己一票</li><li>投自己同时给其他节点发送 RequestVote rpcs</li><li>等待其他节点回复<br>这个过程会有 3 种结果：<br>a. 收到 majority (含自己) 的投票，自己成为leader<br>b. 收到 leader 的 appendEntires RPC，假如请求中携带的 term &gt;&#x3D; 自己，自己切换回 follower；假如 term &lt; 自己，那么他将回复拒绝并保持 candidate 状态<br>c. 一段时间内没有收到足够 majority 的投票，从新发起选举</li></ol><hr><p>在 a 情况下，赢得选举后会立刻广播给所以节点自己是leader 的消息，避免其他节点触发新选举。<br>在这里，先回到投票者的视角，投票者如何决定是否给一个选举请求投票呢，有以下约束：<br>i. 在任何 term 中，一个节点至多投一票<br>ii. candidate 信息 &gt;&#x3D; 当前节点，否则拒绝投票给他（log replication 和 safety 时介绍为什么）<br>iii. first come first served，谁选来谁算数</p><hr><p>在 b 情况下，比如有三个节点A B C。A B同时发起选举，而A的选举消息先到达C，C给A投了一票，当B的消息到达C时，已经不能满足上面提到的第一个约束，即C不会给B投票，而A和B显然都不会给对方投票。A胜出之后，会给B,C发心跳消息，节点B发现节点A的term不低于自己的term，知道有已经有Leader了，于是转换成follower。</p><hr><p>在 c 情况，没有任何节点获得majority投票，比如下图这种情况<br><img src="/2025/03/24/raft/no-majority.png"><br>总共有四个节点，Node C、Node D同时成为了candidate，进入了term 4，但 Node A 投了 NodeD 一票，NodeB 投了 Node C一票，这就出现了平票 split vote的情况。<br>这个时候大家都在等啊等，直到超时后重新发起选举。<br>如果出现平票的情况，那么就延长了系统不可用的时间（没有leader是不能处理客户端写请求的），因此raft引入了 randomized election timeouts 来尽量避免平票情况。<br>同时，leader-based 共识算法中，节点的数目都是奇数个，尽量保证majority的出现。</p><h3 id="random-eletion-timeout"><a href="#random-eletion-timeout" class="headerlink" title="random eletion timeout"></a>random eletion timeout</h3><p>为了减少平票轮次过多，导致 leader 总是选不出来，在节点进入 candidate 时有一个固定的选举超时时间（150-300ms随机），这分散大家发起选举的间隔，让大多数情况下只有一个节点会选举超时（随机时间最小的节点），他将发起第二次选举，此时他的 term 是最大的，他将最先赢得其他节点的选票，并在其他 candidate 第一次选举超时之前发送他的 leader 心跳；<br>下图是一个5节点集群的leader宕机导致选举时间图。<br><img src="/2025/03/24/raft/leader-down.png"><br>上面的图表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。<br>下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性</p><h2 id="log-replication"><a href="#log-replication" class="headerlink" title="log replication"></a>log replication</h2><p>当有了 leader，系统应该进入对外工作期了。客户端的一切请求来发送到 leader，leader 来调度这些并发请求的顺序，并且保证 leader与 followers 状态的一致性。raft中的做法是，将这些请求以及执行顺序告知 followers。leader 和 followers以相同的顺序来执行这些请求，保证状态一致。</p><h3 id="Replicated-state-machines"><a href="#Replicated-state-machines" class="headerlink" title="Replicated state machines"></a>Replicated state machines</h3><p>共识算法的实现一般是基于复制状态机（Replicated state machines），何为复制状态机：<br>If two identical, deterministic processes begin in the same state and get the same inputs in the same order,<br>they will produce the same output and end in the same state</p><p>简单来说：相同的初识状态 + 相同的输入 &#x3D; 相同的结束状态。引文中有一个很重要的词deterministic，就是说不同节点要以相同且确定性的函数来处理输入，而不要引入一下不确定的值，比如本地时间等。如何保证所有节点 get the same inputs in the same order，使用replicated log是一个很不错的注意，log 具有持久化、保序的特点，是大多数分布式系统的基石。<br>因此，可以这么说，在raft中，leader将客户端请求（command）封装到一个个log entry，将这些log entries复制（replicate）到所有follower节点，然后大家按相同顺序应用（apply）log entry中的command，则各个节点的状态肯定是一致的。<br>下图形象展示了这种 log-based replicated state machine<br><img src="/2025/03/24/raft/state-machine.png"></p><h3 id="请求完整流程"><a href="#请求完整流程" class="headerlink" title="请求完整流程"></a>请求完整流程</h3><p>当系统（leader）收到一个来自客户端的写请求，到返回给客户端，整个过程从leader的视角来看会经历以下步骤：</p><ol><li>leader append log entry </li><li>leader issue AppendEntries RPC in parallel </li><li>leader wait for majority response </li><li>leader apply entry to state machine </li><li>leader reply to client </li><li>leader notify follower apply log<br>可以看到日志的提交过程有点类似两阶段提交(2PC)，不过与2PC的区别在于，leader只需要大多数（majority）节点的回复即可，这样只要超过一半节点处于工作状态则系统就是可用的。<br>那么日志在每个节点上是什么样子的呢</li></ol><p><img src="/2025/03/24/raft/log-in-node.png"><br>不难看到，logs由顺序编号的log entry组成 ，每个log entry除了包含command，还包含产生该log entry时的leader term。从上图可以看到，五个节点的日志并不完全一致，raft算法为了保证高可用，并不是强一致性，而是最终一致性，leader会不断尝试给follower发log entries，直到所有节点的log entries都相同。<br>在上面的流程中，leader只需要日志被复制到大多数节点即可向客户端返回，一旦向客户端返回成功消息，那么系统就必须保证log（其实是log所包含的command）在任何异常的情况下都不会发生回滚。<br>leader 将决定什么时候把一条 entry 应用到状态机是安全的，所谓安全就是一个 entry 的状态是 commited。<br>这里有两个 entry 的状态：<br>commit（committed）：日志被复制到了大多数节点后的状态<br>apply(applied)：节点将日志应用到自己状态机后的状态</p><blockquote><p>The leader decides when it is safe to apply a log entry to the state machines; such an entry is called committed. Raft guarantees that committed entries are durable and will eventually be executed by all of the available state machines. A log entry is committed once the leader that created the entry has replicated it on a majority of the servers<br>leader</p></blockquote><p>将一个 log entry 状态转换为 committed 后，这条 entry 之前的所有 log entries 都将被提交，包括其他 leader 创建的 entry。<br>leader 跟踪着最大的将会被提交的日志 index，这个 index 的值将放到未来所有 append Entries 的 rpc 请求中，这样 follower 就知道 leader 提交到什么位置了，follower 将会把这条 log entry 和之前的log entry 都 apply 到本地状态机中。</p><h3 id="log-matching【特性3】"><a href="#log-matching【特性3】" class="headerlink" title="log matching【特性3】"></a>log matching【特性3】</h3><p>日志匹配特性就是下面这两句话</p><blockquote><p>If two entries in different logs have the same index and term, then they store the same command.<br>If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.</p></blockquote><p>第一条特性来源于：<br>一个任期至多一个leader，log entry 只能由 leader 产生，而一个 entry 一旦生成，他的位置绝对不会改变<br>第二条特性来源于：<br>leader 发送 append RPCs 时，会把新 log 前紧挨着的 log idx+term 也加到请求里。follower 假如接受到一次 appendEntry rpc，发现他找不到跟 previous 相同索引的条目，他就拒绝接受新条目；一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。<br>在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。<br><img src="/2025/03/24/raft/log-incons.png"><br>上图的例子会展示出不一致问题的一个场景<br>当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。<br>raft 中 leader 通过强制 follower 复制自己的日志来处理不一致。这将导致 follower 与 leader 冲突的日志将会被 leader 所覆盖。有一个机制会保障这样做是安全的：下面 safety-安全性论证<br>leader 想让 follower 按照自己的日志进行，先要找到俩节点最后一个一致的地方X，删除 follower X之后的全部日志，然后复制自己X之后的给 follower。为此 leader 对每个 follower 维护了一个 nextIndex，标识下一个需要发送给某个 follower 的日志索引地址。当leader 刚刚选举完成，他会初始化所以 nextIndex 值为自己最后一条日志 index +1（上图中的 log index 11）。当 follower 接受appendEntry 一致性检查未通过时，leader 就会减小这个 follower 的 nextIndex 并重新 appendEntry。最终他们一定会到某个位置（appendEntry 成功），此时 follower 会把冲突的日志全部删除并加上领导人的日志。一旦 appendEntry 成功，接下来的任期中 follower 就会一直与 leader 日志一致。<br>算法可以优化：减少 rpc 的次数，follower 在拒绝 ae 请求时附带冲突任期号和最小索引，Leader 就可以少一个任期内的 nextIndex，但实践中发现这种优化压根没用，因为失败很少，并且也不太会出现大量不一致的日志<br>借助 log matching 这种实现的机制，leader 一旦选出，就不需要任何操作来恢复一致性。他本身就正常操作，日志在 appendEntry 到 follower 的过程中自动趋于一致。leader 本身不会覆盖或删除自己的日志，只会追加【特性2 领导人只附加原则】<br>总结一下日志匹配特性是如何做到的：<br>leader会维护一个nextIndex[]数组，记录了leader可以发送每一个follower的log index，初始化为eader最后一个log index加1， 前面也提到，leader选举成功之后会立即给所有follower发送AppendEntries RPC（不包含任何log entry， 也充当心跳消息）,那么流程总结为：<br>s1 leader 初始化nextIndex[x]为 leader最后一个log index + 1<br>s2 AppendEntries里prevLogTerm prevLogIndex来自 logs[nextIndex[x] - 1]<br>s3 如果follower判断prevLogIndex位置的log term不等于prevLogTerm，那么返回 False，否则返回True<br>s4 leader收到follower的回复，如果返回值是False，则nextIndex[x] -&#x3D; 1, 跳转到s2. 否则<br>s5 同步nextIndex[x]后的所有log entries</p><h2 id="safety"><a href="#safety" class="headerlink" title="safety"></a>safety</h2><p>解释一下之前流程中在异常情况下如何保证安全<br>本质上就是在选举、日志复制时增加一些限制。<br>最后说一下 Leader Completeness Property（特性4） 是如何引导复制状态机做出正确行为的</p><h3 id="选举限制"><a href="#选举限制" class="headerlink" title="选举限制"></a>选举限制</h3><p>任何一致性算法中，leader 都必须存储所有提交过的日志。很多算法（如 Viewstamped Replication）要么是在选举阶段通过额外机制识别丢失的日志并把他们传给新 leader，要么是在选举之后很快进行，这都会对选举增加很大的复杂性。<br>requestVote rpc 增加一个限制，在请求中包含了候选人的日志信息，投票者会拒绝日志没有自己新的投票。<br>怎么定义新：通过比较两份日志最后一条的 index 就能知道谁的日志最新（任期越大越新+日志越长越新）</p><h3 id="提交之前任期的日志"><a href="#提交之前任期的日志" class="headerlink" title="提交之前任期的日志"></a>提交之前任期的日志</h3><p><img src="/2025/03/24/raft/term-no-only.png" alt="leader 无法决定之前任期的例子"><br>原文:<br>为了消除上图的情况，raft 拥有不会通过计算副本数去提交一个之前任期的日志。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。<br>我的理解:<br>某个leader选举成功之后，不会直接提交前任leader时期的日志，而是通过提交当前任期的日志的时候“顺手”把之前的日志也提交了。流程就和 log matching 部分一样，nextIndex[] 的那招。<br>那么问题来了，如果leader被选举后没有收到客户端的请求呢，论文中有提到，在任期开始的时候发立即尝试复制、提交一条空的log，也就是说刚选出来其实立马就开始递归式的 appendEntry 了。带入到上图中(c)的情况，假设 s1 刚选举成功时没有新的 4 term 的客户端输入，那么他第一次广播时就在同步 term2 了；</p><blockquote><p>Raft handles this by having each leader commit a blank no-op entry into the log at the start of its term.</p></blockquote><p>因此，在上图中，不会出现（C）时刻的情况，即 term4任期的leader s1不会复制term2的日志到s3。而是如同(e)描述的情况，通过复制-提交 term4的日志顺便提交term2的日志。如果term4的日志提交成功，那么term2的日志也一定提交成功，此时即使s1crash，s5也不会重新当选，因为超过半数的 node term 已经高于 s5了。<br>所以这个特性是保证 raft 内部能一致，与客户端的信息无关。因为在上图中客户端视角应该是连续的会断开链接，不知道提没提交过。但是可以用get的方式来确认是否提交过。<br>反过来看日志的角度，丢弃的都是没被 commit 过的日志，没 commit 过的日志也会因为 leader crash 而 commit。</p><h3 id="安全性论证"><a href="#安全性论证" class="headerlink" title="安全性论证"></a>安全性论证</h3><p>在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。<br>我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。<br>设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。<br><img src="/2025/03/24/raft/safety.png"></p><blockquote><p>如果 S1 （任期 T 的领导人）在它的任期里提交了一条新的日志，然后 S5 在之后的任期 U 里被选举为领导人，那么至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。</p></blockquote><ol><li>在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。</li><li>领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人 U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人 T 的日志条目，并且给领导人 U 投票了，如图 9。这个投票者是产生这个矛盾的关键。 </li><li>这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。 </li><li>投票者在给领导人 U 投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。 </li><li>投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。 </li><li>首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。 </li><li>除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交的日志，这里产生矛盾。 </li><li>这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。 </li><li>日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (e) 中的索引 2。</li></ol><p>经过上面的论证，结合 【特性4 领导人完全特性】保证高 term leader 会存储相同的 log，<br>验证了 【特性5 状态机安全特性：如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上；在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交】成立</p><h2 id="crash"><a href="#crash" class="headerlink" title="crash"></a>crash</h2><p>candidate 和 follower crash 后，后续发给他们的 rpc 都会失败。raft 中处理失败调用的策略就是无限次重试。当他们恢复后，那么这些rpc就恢复应该的结果了。如果一个服务器完成了一个rpc但没响应就 crash 了，在他重启之后会再次收到同意的请求。raft 的rpc 全是幂等的。比如 appendEntry：无非是第一次接受到就 commit，第二次忽略这次 rpc 罢了。</p><h2 id="时间和可用性"><a href="#时间和可用性" class="headerlink" title="时间和可用性"></a>时间和可用性</h2><p>raft 的正常工作（append log）是不依赖时间的，但是可用性不可避免的依赖时间。比如信息交换比服务器故障的超时还长，候选人就永远没可能有足够时间赢得选举了。<br>所以依赖时间的地方就是leader election。为了选举并维持一个稳定的leader，系统需要满足以下时间要求：<br><strong>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</strong><br>广播就是正常的rpc调用<br>选举就是 random 150-300 ms 的值<br>平均故障就是连续两次故障的平均时间（集群里一堆机器起了就挂，还没到选举完成就挂，也无法维持一个稳定leader）<br>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p><h2 id="变配"><a href="#变配" class="headerlink" title="变配"></a>变配</h2><p>变更集群配置是时有发生的，比如替换宕机的机器，修改复制级别。停机下配重启是最弱的实现，而且手工操作会误操作，raft 使用自动化的配置修改机制变更。</p><h3 id="配置修改机制"><a href="#配置修改机制" class="headerlink" title="配置修改机制"></a>配置修改机制</h3><p>一次性原子性的修改全部服务器是不可能的，这也导致一些不安全性（比如配置一变，导致2个leader被选出）<br><img src="/2025/03/24/raft/joint-cons.png"><br>直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。<br>备注：S1 S2 用老配置选 S2 当了 leader；S3 S4 S5 用新配置选 S3 当了 leader<br>所以为了安全，必须用2阶段方案。raft 的方法是先将集群切换到一个共同一致状态（joint consensus），一旦共同一致被提交，系统就切换到新配置。</p><h3 id="共同一致"><a href="#共同一致" class="headerlink" title="共同一致"></a>共同一致</h3><p>是新老配置的结合：</p><ol><li>日志条目被复制给集群中新、老配置的所有服务器。</li><li>新、旧配置的服务器都可以成为领导人。</li><li>达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。</li></ol><p>共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然响应客户端的请求。<br>集群配置在复制日志中以特殊的日志条目来存储和通信。<br>有一个潜在的约定：<strong>服务器总是使用最新的配置，无论他是否已经被提交</strong><br>leader 接受到 C-old 变配 C-new 请求后，会存储一个 C-old,new 的『共同一致』日志，以后就用这个配置来做出未来的决定。如果此时 leader crash，新的 leader 只可能处于 C-old 或者 C-old,new，也就是说任何情况下C-new 在这个阶段不会单方面做出决定。<br>C-old,new 被提交后，无论 C-old 还是 C-new，如果不经过另一个配置允许都不能单独做出决定，并且领导人完全特性保证了 包含 C-old,new 的条目的节点才能成为 leader，此时领导人创建一条关于 C-new 配置的日志并复制给集群就安全了。任何服务器 接到 C-new 后就会立刻按照 C-new 生效，等于旧配置的机器会在接到 C-new 的瞬间而失效。</p><h3 id="额外引入的三个问题"><a href="#额外引入的三个问题" class="headerlink" title="额外引入的三个问题"></a>额外引入的三个问题</h3><ol><li>新服务器刚进入集群，没有任何日志，需要追赶一阵子的日志，此时不能提交新条目了。<br>答： raft 在配置更新前还有一个额外的阶段：新服务器以没有投票权的身份加入到集群（只接受 log replica，但 leader 不考虑他们 是大多数）。一旦新服务器追上了新日志条目，他就会进入重新配置的阶段。</li><li>leader 在重配阶段crash，新 leader 可能不是新配置的一员。<br>答：假如 leader 按照 C-old 被选出，他会在提交 C-new 之后自己转回 follower。因为 C-new 已经提交，下一次选举一定会选择包含C-new 的节点作为leader。</li><li>移除不在 C-new 服务器可能会扰乱集群。因为这些服务器不会再接受心跳，当选举超时，他们就会发起新的选举，产生新的term 和广播 requestVote，会导致当前 leader 退回 follower 。移出的 node 因为不在配置里，没人投给他，但是就算其他正常的节点选成新 leader，都会面临 移除节点 无限的超时重选，集群的可用性将大幅降低。<br>答：当服务器确定当前 leader 存在时（正常leader 会一直发心跳，而心跳的间隔比最小选举超时时间短的多），直接忽略外来的 requestVote rpc。正常的选举至少要在选举超时后才有可能进行，突然来一个 requestVote 对任何可用节点都是没用的。</li></ol><h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><p>和 chubby&#x2F;zookeeper 一样，将一个时间点前的日志合并成一个小的 snapshot，然后丢弃这个时间点前到日志。<br><img src="/2025/03/24/raft/log-compress.png"><br>一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。<br>快照生成和日志清除都没啥可说的，增量压缩已经很成熟了。<br>但偶尔会出现 leader 复制 snapshot 给一些落后过多的 follower（比如 leader 丢失了某个 follower 的 nextIndex；或者新加了一个没任何日志的服务器），此时会通过网络发 snapshot 并将 leader 内的 nextIndex[$lostNode] 写成 snapshot.lastIndex+1<br>raft 提供了一个 安装快照的 rpc 接口<br><img src="/2025/03/24/raft/snapshot-rpc.png"><br>快照技术是违背 raft 强 leader 原则的，因为 follower 接到请求（无论哪儿来的）就能创建快照，但是 raft 团队认为违背就违背了。<br>为了优化写入快照性能，raft 利用了类似 linux fork 的写时复制技术创建状态机的内存快照。</p><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p><strong>客户端只能跟leader交互</strong></p><ol><li>客户端随便访问一个节点A </li><li>假如A不是 leader，返回 leader 地址 </li><li>假如 leader 已经 crash，客户端就会超时，进而继续随机挑选节点发送请求<br>重复执行问题：客户端调了一下 leader，leader 提交了这条日志，还没返回给客户端就 crash 了，这时客户端应该会到新 leader 重试一样的命令，导致命令重复了。<br>答：客户端每一条指令都会赋予一个唯一的序列号，状态机会追踪每条指令最新的序列号，这个序列号会在 commit 时存储，新leader 肯定是知道一个命令是不是commit过的，如果已经有一样序列号的指令，直接返回结果，而不是重复执行。<br>只读操作在不加任何限制时可能会收到脏数据（响应client 的 leader 在响应到一半的时候可能已经不是 leader 了），raft 里两个特性保证了在不使用日志的情况下，client 读不到脏数据： </li><li>领导人完全特性：leader 一旦选出，他一定有最新的提交的日志【通过刚当选就广播一次空log的 appendEntry，他就知道本地哪些日志提交过，哪些没有】 </li><li>leader 处理只读消息前检查自己是否已经被废黜（有新 leader 当选，旧 leader 的信息可能就是脏数据，因为新 leader 可能已写入更新的条目了），方法就是在接受请求一上来就广播一次心跳。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="与-paxos-的区别"><a href="#与-paxos-的区别" class="headerlink" title="与 paxos 的区别"></a>与 paxos 的区别</h3><p>raft 是强领导特性的分布式一致性算法，将更多的功能集中到 leader 简化了方案，随之也就简化了理解难度。<br>paxos 的 leader 选举是性能优化的手段，并不是他一致性必要的步骤。所以他本身的一致性算法有更多的机制，比如改造的2PC等，导致理解难度高。</p><h3 id="正确性"><a href="#正确性" class="headerlink" title="正确性"></a>正确性</h3><p>RAMCLOUD 有一个 2000 行代码的 C++的实现，帮助 RAMCloud 完成存储配置信息 FSM，并帮助 RAMCloud 协调 failover。<br>同时有一篇3500字的论文证明了安全性是完备的</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>核心就是 leader 选举成功后复制条目的性能。raft 的消息包比较少，并不太影响性能。<br>增加了随机选举超时，改善了宕机重选的时间，这也增加了系统 SLA。</p><h2 id="考试题"><a href="#考试题" class="headerlink" title="考试题"></a>考试题</h2><p><a href="https://zhuanlan.zhihu.com/p/268571088">https://zhuanlan.zhihu.com/p/268571088</a><br>问题有一些有点烂,说不明白,看看就好</p>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3PC</title>
      <link href="/2025/03/23/3PC/"/>
      <url>/2025/03/23/3PC/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了解决 2PC 存在的问题</p><ol><li>同步阻塞</li><li>协调者单点 </li><li>脑裂 </li><li>数据不一致<br><img src="/2025/03/23/3PC/image.png"></li></ol><h2 id="第一阶段：预查询"><a href="#第一阶段：预查询" class="headerlink" title="第一阶段：预查询"></a>第一阶段：预查询</h2><p>目的：知道是否大家都同意去 commit</p><ol><li>coordinator 收到 timeout 或有 participant 返回 no，则下发终止</li><li>participant timeout waiting for request from coordinator，自己终止（他会假设 coordinator 挂了）【这种是已经返回过第一阶段yes，但是很久没收到 coordinator 第二阶段请求】</li></ol><h2 id="第二阶段：预提交"><a href="#第二阶段：预提交" class="headerlink" title="第二阶段：预提交"></a>第二阶段：预提交</h2><p>目的：让全部参与者知道 commit 的决定<br>第一阶段盘问后，出现下面三种情况</p><ol><li>所有参与者都返回可以 </li><li>一个或多个参与者返回不可以 </li><li>协调者等待到超时了</li></ol><h3 id="全部反馈可以的情况"><a href="#全部反馈可以的情况" class="headerlink" title="全部反馈可以的情况"></a>全部反馈可以的情况</h3><ol><li>协调者向参与者发送执行通知</li><li>参与者执行事务但不提交</li><li>参与者将事务执行情况返回给协调者</li></ol><h3 id="有不可以或超时的情况"><a href="#有不可以或超时的情况" class="headerlink" title="有不可以或超时的情况"></a>有不可以或超时的情况</h3><p><img src="/2025/03/23/3PC/image2.png"><br>participant timeout：认为 coordinator 宕，给其他 participant 发送 abort</p><h2 id="第三阶段：正式提交"><a href="#第三阶段：正式提交" class="headerlink" title="第三阶段：正式提交"></a>第三阶段：正式提交</h2><p>在第二阶段中假如未中断，则协调者会根据全部参与者返回的操作结果来决定提交还是回滚<br>分为这三种情况</p><ol><li>所有参与者在第二阶段结束时都返回成功 </li><li>一个或多个返回 </li><li>协调者等待超时</li></ol><h3 id="全部成功"><a href="#全部成功" class="headerlink" title="全部成功"></a>全部成功</h3><p>协调者向参与者发送 commit 通知<br>参与者执行 commit，释放资源<br>参与者向协调者反馈提交结果</p><h3 id="部分失败或超时"><a href="#部分失败或超时" class="headerlink" title="部分失败或超时"></a>部分失败或超时</h3><p>协调者发送 rollback 通知<br>所有参与者 rollback，释放资源<br>参与者反馈回滚结果给协调者</p><h2 id="相比-2PC-的改动"><a href="#相比-2PC-的改动" class="headerlink" title="相比 2PC 的改动"></a>相比 2PC 的改动</h2><p>引入超时机制，参与者、协调者都具备超时处理<br>将 2PC 投票阶段 分成 can-commit 和 pre-commit 两个阶段</p><h3 id="将-2PC-投票阶段分成-2-个阶段的原因"><a href="#将-2PC-投票阶段分成-2-个阶段的原因" class="headerlink" title="将 2PC 投票阶段分成 2 个阶段的原因"></a>将 2PC 投票阶段分成 2 个阶段的原因</h3><p>在 2PC 里，假如 1 个协调者，9 个参与者，有一个参与者不具备执行事务的能力。<br>协调者发送 prepare 后其他参与者都锁了资源，执行事务，写 undo 和 redo 日志。<br>协调者收到响应请求发现有一个不能执行的参与者，所以又发出一个 rollback，其他 8 个参与者都回滚，这样做了很多无用功。<br>所以 can commit 阶段是为了在预执行之前，保证全部参与者都具备条件，减少资源浪费</p><h2 id="与-2PC-的本质区别"><a href="#与-2PC-的本质区别" class="headerlink" title="与 2PC 的本质区别"></a>与 2PC 的本质区别</h2><p>避免了单点故障，减少阻塞<br>一旦参与者无法即使接受协调者信息，默认会执行 commit，而不会一直阻塞。<br>这么做是基于概率来决定的，因为当进入到第三阶段后，说明参与者第二阶段已经收到 preCommit 请求了；<br>协调者在第二阶段开始前，只有当所有参与者都对 can-commit 返回了 yes，才会产生 pre-commit 请求；<br>所以一旦参与者收到 pre-commit，各个参与者都知道其他人已经同意执行修改了；</p><p>所以概括下来：<br>进入到第三阶段时，由于网络超时等原因，虽然参与者没有收到协调者的 commit 或 abort，但他也有理由相信：成功提交的概率是很大的，所以他自己要 commit；<br>但也因为这个设计，会导致协调者会存在数据不一致：<br>当第三阶段协调者发送 abort 请求，有个别参与者没有收到或超时，导致他在超时时间后没有和其他正常的参与者一样 abort，而是自己 commit 了，此时这个参与者的数据跟其他参与者不一致了。</p><h3 id="3PC如何解决单点故障"><a href="#3PC如何解决单点故障" class="headerlink" title="3PC如何解决单点故障"></a>3PC如何解决单点故障</h3><p>单点故障是指 2PC 中两种情况</p><ol><li>协调者发起commit 后挂，则参与者不知道该执行还是终止</li><li>协调者发起commit 后挂，参与者执行完结果（不知道成功还是失败）后挂，重选主持人后没人知道提案，因为没人知道这个执行者的执行结果，新诞生的协调者也不敢随便终止，因为怕有的参与者已经 commit ，导致不一致</li></ol><h3 id="参与者宕机"><a href="#参与者宕机" class="headerlink" title="参与者宕机"></a>参与者宕机</h3><ol><li>第一阶段宕机<br>a. 失联参与者没有接到协调者 can-commit，协调者会 abort，参与者恢复后等于无事发生<br>b. 失联参与者接受了协调者的 can-commit，协调者会进入下一阶段，参与者恢复后等协调者的重试，或者恢复太久，协调者已经终止了事务，此时参与者自行会超时，自己 abort</li><li>第二阶段宕机<br>a. 失联参与者未接受 pre-commit，协调者会因联系不到这个参与者而 abort，失联参与者恢复后本身也将处于 can-commit 等待阶段，要么接到协调者重试，要么自己 abort<br>b. 失联参与者接受 pre-commit，协调者会认为这个节点有响应，成功就进三阶段，失败就 abort，失联参与者恢复后，进入 3 阶段</li><li>第三阶段宕机<br>a. 失联的参与者没有收到协调者的 do-commit，会出现以下两个情况<br>i. 超时等待，自己 commit 了<br>ii. 接到协调者重试，完成协调者的请求<br>b. 失联的参与者接受到 do-commit 后失联，等于返回给协调者之前已经完成了协调者的事儿，协调者会重试<br>i. 没接到重试，自己 commit 了<br>ii. 参与者恢复了，执行重试的请求</li></ol><h3 id="协调者宕机"><a href="#协调者宕机" class="headerlink" title="协调者宕机"></a>协调者宕机</h3><ol><li>第一阶段宕机<br>a. 已经广播 can-commit 后宕，新选的协调者知道已经发出 can-commit 了<br>b. 未广播 can-commit，无事发生，客户端超时后发现不好使了</li><li>第二阶段宕机<br>a. 已经广播 pre-commit 后宕，新选的协调者已经知道发送过 pre-commit 了<br>b. 未广播 pre-commit，新选协调者处于 can-commit 完成阶段，广播 pre-commit</li><li>第三阶段宕机（结论：新协调者无脑发 do-commit）<br>a. 已经广播 do-commit 后宕，假设新选协调者已经接受过 do-commit 了，那么他直接广播一样的 do-commit<br>b. 还没广播 do-commit 后就宕，新协调者还停留在 pre-commit 完成的阶段，从新发起 do-commit</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>3PC 引入超时机制，阻塞发生概率变小了<br>3PC 把 2PC 的投票阶段一分为二，多了一个缓冲阶段，保证最后提交阶段前，各个参与节点的状态是一致的<br>避免了单点问题<br><img src="/2025/03/23/3PC/image3.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 3PC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go plugin</title>
      <link href="/2025/03/23/Go-plugin/"/>
      <url>/2025/03/23/Go-plugin/</url>
      
        <content type="html"><![CDATA[<p>go-pluign 是 Hashicorp 公司主导的开源项目，2013 年正在开发的 Packer 项目需要使用插件，但当时 Go 还未推出动态加载插件库特性，因此 Hashicorp 公司就自己开始着手实现。另外，在其开源的 Nomad、Consul、Vault 和 Terrform 等项目中也都有应用。<br>Hashicorp go-pluign 和 Go 原生插件库的实现方式完全不同。go-plugin 实现插件库的基本原理是多进程间的 RPC 通信，即将主程序调用插件库方法实现为同一台主机上的主程序进程和插件进程之间的通信，网络协议可以是 Go 标准库的 net&#x2F;rpc 或 gRPC，一般推荐使用 gRPC。而底层使用的协议类型可以是 TCP 或者 Unix 域套接字，引入 Unix 域套接字的原因是在实际使用时，机器上有一些端口被防火墙限制，因此基于 TCP 的方式无法工作。<br>go-plugin 插件一般由宿主进程（主程序）调用，宿主进程以插件二进制文件为映像创建子进程，然后通过单个网络连接与之通信，之所以强调通信只需建立单个网络连接，是因为后期随着 go-plugin 的迭代，其在 v3 版本支持连接的多路复用。显然，我们可以发现 go-plugin 的设计原理使得它没有 Go 原生插件系统的那些缺陷。<br><img src="/2025/03/23/Go-plugin/image.png"><br>go-plugin 设计之初的目标是实现良好的扩展性、易用性、方便安装和管理，同时插件进程不会影响到主程序的稳定性。在其官方的 README 中总结了其核心特性，其中有一些关键项：</p><ol><li>编写插件即实现 Go 接口。对于插件的开发者而言，他只需要实现特定接口，而针对插件调用方而言，可像调用本地方法一样调用插件预先声明的接口，go-plugin 会在中间处理本地调用转换为 RPC 调用的细节； </li><li>跨语言支持。插件可以基于任何主流语言编写和消费，因为插件和主程序是基于 RPC 通信； </li><li>支持复杂参数。支持将 interface、io.Reader&#x2F;Writer 等类型作为被调用接口的参数； </li><li>宿主进程独立升级。宿主进程可独立升级，而不影响插件进程，且在升级完毕后，插件进程可关联到新的宿主进程； </li><li>宿主进程稳定性。即插件进程奔溃不会影响宿主机进程； </li><li>同步 stdout 和 stderr：插件实际是以主程序的子进程在运行，这些子进程所使用标准输出&#x2F;错误会被自动同步到宿主进程，同时，宿主进程可以为同步的日志指定一个 io.Writer。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hashicorp</title>
      <link href="/2025/03/23/hashicorp/"/>
      <url>/2025/03/23/hashicorp/</url>
      
        <content type="html"><![CDATA[<p>HashiCorp提供了大量的DevOps 基础设施自动化工具，集开发、运营和安全性于一体，可以帮助开发者编写和部署应用程序，加速应用程序分发，助力企业提升开发效率。</p><h2 id="服务列表"><a href="#服务列表" class="headerlink" title="服务列表"></a>服务列表</h2><ol><li>Terraform：解决端到端的基础设施自动化问题，使企业在配置基础设施时能够轻松地进行编码； </li><li>go-plugin </li><li>Vault：通过基于可扩展的插件对用户和应用程序进行身份验证，提供适合现代零信任安全需求的基于身份的控件。 </li><li>boundary </li><li>vagrant </li><li>packer </li><li>serf </li><li>Consul：通过提供所有应用程序的中央实时视图，实现以应用为中心的网络，以便应用团队能够管理流量和安全策略。 </li><li>Nomad：允许开发人员使用自助式应用程序，在生命周期内更有效地交付工作负载。 </li><li>Waypoint</li></ol><h2 id="发展时间轴"><a href="#发展时间轴" class="headerlink" title="发展时间轴"></a>发展时间轴</h2><p><img src="/2025/03/23/hashicorp/image.png"><br>HashiCorp用户团体（HUGs）是用户自发组织的一个团体，专为 HashiCorp 的产品进行宣传。截至 2021 年 7 月 31 日，HUGs 在 50 多个国家的 140 多个分会中拥有 36000 多名成员。</p><h2 id="产品性质"><a href="#产品性质" class="headerlink" title="产品性质"></a>产品性质</h2><p><img src="/2025/03/23/hashicorp/image2.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> hashicorp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2PC</title>
      <link href="/2025/03/23/2PC/"/>
      <url>/2025/03/23/2PC/</url>
      
        <content type="html"><![CDATA[<h2 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h2><p>一个协调者<br>N 个执行者</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>参与者将操作成功&amp;失败 告诉协调者，协调者根据各个参与者反馈的情报决定是提交还是终止</p><h2 id="时序"><a href="#时序" class="headerlink" title="时序"></a>时序</h2><p>协调者节点从所有参与者节点获得的响应消息都为”同意”<br><img src="/2025/03/23/2PC/image.png"><br>任一参与者节点在第一阶段返回的响应消息为”中止”，或者协调者在第一阶段询问超时前无法获得所有参与者节点的响应。<br><img src="/2025/03/23/2PC/image2.png"></p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><h3 id="第一阶段：投票"><a href="#第一阶段：投票" class="headerlink" title="第一阶段：投票"></a>第一阶段：投票</h3><p>协调者向全部参与者发送事务执行请求，等待结果<br>参与者收到事务后执行事务，但是不提交，记录事务日志<br>参与者将执行情况反馈给协调者，阻塞等待协调者下一步命令</p><h3 id="第二阶段：提交"><a href="#第二阶段：提交" class="headerlink" title="第二阶段：提交"></a>第二阶段：提交</h3><p>存在 3 个可能性</p><ul><li>所有参与者都返回成功<br>a. 协调者对各个参与者发送提交通知<br>b. 参与者收到请求后，执行 commit，然后释放资源<br>c. 参与者向协调者返回 commit 的结果</li><li>部分参与者返回失败<br>a. 协调者对各个参与者发送 rollback 通知<br>b. 参与者收到请求后执行 rollback，释放占有资源<br>c. 参与者返回 rollback 结果</li><li>等待超时<br>a. 协调者对各个参与者发送 rollback 通知<br>b. 参与者收到请求后执行 rollback，释放占有资源<br>c. 参与者返回 rollback 结果</li></ul><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>在各节点都正常情况下，解决了强一致性，发起到协调者的事务，在调用视角是原子性的</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>同步阻塞：当参与者占用了额外资源时，会让这个资源无法被其他人使用<br>单点故障：协调者一旦故障，参与者可能永远阻塞：在提交阶段，还没给部分参与者发送提交请求，协调者就挂掉，导致参与者永远不释放资源<br>数据不一致：第二阶段协调者发起 commit 后，假如因网络原因有一部分参与者接受到请求，一部分没接受到，则会导致没接受的参与者不 commit，结果就是提交过和没提交过的不同参与者数据不一致<br>协调者 commit 后宕机，参与者也紧跟着宕机，即使协调者从新选举了，也没人知道这条事务是提交还是没提交了</p>]]></content>
      
      
      
        <tags>
            
            <tag> 2PC </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cloud init</title>
      <link href="/2025/03/22/cloud-init/"/>
      <url>/2025/03/22/cloud-init/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们不光是大数据开发者，更是云计算开发者。了解云计算的工具很有必要。</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Cloud-init 是虚拟机初始化的开源工具，在 AWS 中与之对应的是 EC2Config。<br>cloud-init是一款用于初始化云服务器的工具，它拥有丰富的模块，能够为云服务器提供的能力有：初始化密码、扩容根分区、设置主机名、注入公钥、执行自定义脚本等等，功能十分强大。<br>目前为止cloud-init是云服务器初始化工具中的事实标准，它几乎适用于所有主流的Linux发行版，也是各大云厂商正在使用的默认工具，社区活跃。基于Python语言使得它能够轻易跨平台、跨架构运行，良好的语法抽象使得它适配新模块、新发行版十分容易。<br>通过学习 cloud-init 的概念，我们可以知道一个虚机从开始创建到运行中，需要哪些信息，经历了哪些步骤，进而对虚机有更深入的理解。</p><h3 id="实例数据"><a href="#实例数据" class="headerlink" title="实例数据"></a>实例数据</h3><p>是 cloud-init 用来处理并配置实例的数据集合。分为三类：</p><ol><li>metadata：主机名、密码、网络配置信息和SSH密钥</li><li>userdata：命令、脚本、文件和自定义数据等</li><li>vendordata：云基座传入的数据</li></ol><p>在 Openstack 中，metadata userdata 均在用户创建实例时通过参数传入，而 vendordata 通过 nova-api-metadata 服务启动时指定。<br>PS：<br>在 BCC 中，cloud-init 的配置文件目录是 &#x2F;etc&#x2F;cloud，在这里的 cloud.cfg 可以看到基本配置，templates 目录是一些 jinja2 的模板文件，应该会使用这些模板初始化一些配置文件。<br>metadata 配置文件在：&#x2F;var&#x2F;lib&#x2F;cloud&#x2F;instance&#x2F;cloud-config.txt<br>userdata 配置文件在：&#x2F;var&#x2F;lib&#x2F;cloud&#x2F;instance&#x2F;user-data.txt<br>vendordata 配置文件在：&#x2F;var&#x2F;lib&#x2F;cloud&#x2F;instance&#x2F;vendor-data.txt<br>在经过上面这些配置文件初始化后，实例数据也有一个汇总了所有数据的文件，这个文件是存在 &#x2F;run&#x2F;cloud-init&#x2F;instance-data.json 下的，这个数据是我们可以利用的。<br>数据源<br>上面三类数据来源于许多地方，数据源代表实例数据的具体来源。<br>内置的数据源包括：Openstack、ConfigDrive、Amazon EC2(EC2Config)、Azure 等等，不同数据源也表明了不同实例数据的搜索方式。<br>cloud-init 在实例内部启动时并不知道从那里才能找到实例数据，它会根据预设的数据源列表一个一个查找实例数据，首个找到的源就成为这次启动的数据源。<br><img src="/2025/03/22/cloud-init/arch.png" alt="架构"></p><p>使用 openstack 作为数据源，那么实例数据将通过 HTTP API 获取：</p><ol><li>metadata：<a href="http://169.254.169.254/openstack/latest/meta_data.json">http://169.254.169.254/openstack/latest/meta_data.json</a></li><li>userdata：<a href="http://169.254.169.254/openstack/latest/user_data">http://169.254.169.254/openstack/latest/user_data</a></li><li>vendordata：<a href="http://169.254.169.254/openstack/latest/vendor_data.json%E3%80%81http://169.254.169.254/openstack/latest/network_data.json">http://169.254.169.254/openstack/latest/vendor_data.json、http://169.254.169.254/openstack/latest/network_data.json</a></li></ol><p>使用 configdrive 作为数据源，则会直接从文件中获取，cloud-init 会搜索标记有 CONFIG-2标签的分区，然后将该分区挂载到临时目录中，并读取这个目录中的文件：</p><ol><li>metadata：file:&#x2F;&#x2F;TMPDIR&#x2F;openstack&#x2F;latest&#x2F;meta_data.json</li><li>userdata：file:&#x2F;&#x2F;TMPDIR&#x2F;openstack&#x2F;latest&#x2F;user_data</li><li>vendordata：file:&#x2F;&#x2F;TMPDIR&#x2F;openstack&#x2F;latest&#x2F;vendor_data.json、file:&#x2F;&#x2F;TMPDIR&#x2F;openstack&#x2F;latest&#x2F;network_data.json</li></ol><h3 id="启动过程"><a href="#启动过程" class="headerlink" title="启动过程"></a>启动过程</h3><p>在整个系统启动的过程中，cloud-init的执行包括5个阶段，执行阶段从前到后分别为：Generator、Local、Network、Config、Final。<br><img src="/2025/03/22/cloud-init/process.png"></p><h4 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h4><p>systemd服务：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system-generators&#x2F;cloud-init-generator<br>运行于：系统刚启动时<br>generator是最先运行的阶段，它的功能包括：</p><ol><li>判断是否需要禁止运行cloud-init。generator会根据如下条件判断：<br>&#x2F;etc&#x2F;cloud&#x2F;cloud-init.disabled文件是否存在。<br>内核参数中是否包括有cloud-init&#x3D;disabled配置项。</li><li>筛选可用的数据源。generator为每个数据源都写了判断函数，运行判断函数后返回可用数据源的列表，存放于datasource_list配置项并写入&#x2F;run&#x2F;cloud-init&#x2F;cloud.cfg中。</li></ol><h4 id="Local"><a href="#Local" class="headerlink" title="Local"></a>Local</h4><p>systemd服务：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cloud-init-local.service<br>运行于：根目录挂载并可读写后<br>Local阶段的主要功能为：<br>搜索数据源。在datasource_list配置项中搜索第一个可用的数据源，作为本次启动的数据源。数据源搜索细节如下：<br>a. 尝试从缓存恢复。若存在obj.pkl缓存，为trust模式或ds.check_instance_id()返回true，则从缓存恢复。<br>b. 搜索数据源，遍历datasource_list配置项中的数据源，找出第一个可用的数据源，并返回。<br>应用网络配置（不拉起网络）。网络配置的来源如下：<br>a. 数据源，使用从数据源获取的网络配置，渲染并写入网络配置至磁盘中。<br>b. 回退，如果无数据源，则写入一个默认的dhcp网络配置。<br>c. 不应用，如果cloud-init配置文件中有如下配置项：network: {config: disabled}，或者存在&#x2F;var&#x2F;lib&#x2F;cloud&#x2F;data&#x2F;upgraded-network文件，则不应用网络配置。<br>PS：BCC 中的 &#x2F;etc&#x2F;cloud&#x2F;cloud.cfg 中配置了 network: {config: disabled}</p><h4 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h4><p>systemd服务：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cloud-init.service<br>运行于：网络服务启动之后<br>Network阶段的主要功能为：<br>self.datasource.setup()，在uesr-data和vendor-data处理之前调用，用于网络启动后再次更新数据源，网上看到azure cloud 利用这一步获取fabric数据并填充进fabric_data。<br>存储与渲染userdata和vendordata。<br>self.datasource.activate()，该方法在user-data和vendor-data渲染后，init_modules执行前调用。<br>运行cloud_init_modules中配置的模块。</p><h4 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h4><p>systemd服务：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cloud-config.service<br>运行于：Network阶段之后<br>Config阶段的主要功能是运行cloud_config_modules中配置的模块。</p><h4 id="Final"><a href="#Final" class="headerlink" title="Final"></a>Final</h4><p>systemd服务：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cloud-final.service<br>运行于：Config阶段之后<br>Config阶段的主要功能是运行cloud_final_modules中配置的模块。<br>Cloud-config<br>cloud-config是cloud-init的配置文件，它用于控制cloud-init的行为，比如说该运行哪些功能，以及每个功能如何运行等等。和其他软件的配置文件相比，cloud-config具有高度定制化的特点，除了云服务器本身的cloud-config以外，cloud-init还能够从vendordata、userdata甚至内核参数中获取cloud-config，从而使得用户能够方便地利用cloud-init定制自己的云服务器。<br><img src="/2025/03/22/cloud-init/level.png"></p><h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><p>cloud-init 实际运行的程序<br>以 set_hostname 模块为例，该模块的功能是设置主机名，当运行该模块时，它会读取cloud-config中的hostname参数，并将其中值设置为云实例的主机名。<br><img src="/2025/03/22/cloud-init/module.png"><br>每个模块都有名称、运行频率、配置参数这三大要素。<br>名称和配置很容易理解。<br>运行频率表示一个模块该在什么时候运行，通常有两种运行频率：</p><ol><li>once-per-instance，表示仅在实例首次启动时运行</li><li>always，表示实例每次启动都运行<br>是否运行某个模块、何时运行模块、怎么运行模块，这些都可以在cloud-config中配置<br>我们看一个虚机的例子</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">disable_root: 0</span><br><span class="line">ssh_pwauth: 1</span><br><span class="line"></span><br><span class="line">locale_configfile: /etc/sysconfig/i18n</span><br><span class="line">mount_default_fields: [~, ~, &#x27;auto&#x27;, &#x27;defaults,nofail,x-systemd.requires=cloud-init.service&#x27;, &#x27;0&#x27;, &#x27;2&#x27;]</span><br><span class="line">resize_rootfs_tmp: /dev</span><br><span class="line">ssh_deletekeys:   0</span><br><span class="line">ssh_genkeytypes:  ~</span><br><span class="line">syslog_fix_perms: ~</span><br><span class="line">disable_vmware_customization: false</span><br><span class="line">datasource_list: [ Ec2, ConfigDrive ]</span><br><span class="line">datasource:</span><br><span class="line">  Ec2:</span><br><span class="line">    strict_id: false</span><br><span class="line"></span><br><span class="line">network: &#123;config: disabled&#125;</span><br><span class="line">## network 将运行的 modules</span><br><span class="line">cloud_init_modules: </span><br><span class="line"> - disk_setup</span><br><span class="line"> - migrator</span><br><span class="line"> - bootcmd</span><br><span class="line"> - write-files</span><br><span class="line"> - growpart</span><br><span class="line"> - resizefs</span><br><span class="line"> - set_hostname</span><br><span class="line"># - update_hostname</span><br><span class="line"> - update_etc_hosts</span><br><span class="line"> - rsyslog</span><br><span class="line"> - users-groups</span><br><span class="line"> - ssh</span><br><span class="line"> </span><br><span class="line">## config 阶段运行的 modules</span><br><span class="line">cloud_config_modules:</span><br><span class="line"> - mounts</span><br><span class="line"> - locale</span><br><span class="line"> - set-passwords</span><br><span class="line"> - rh_subscription</span><br><span class="line"> - yum-add-repo</span><br><span class="line"> - package-update-upgrade-install</span><br><span class="line"> - timezone</span><br><span class="line"> - puppet</span><br><span class="line"> - chef</span><br><span class="line"> - salt-minion</span><br><span class="line"> - mcollective</span><br><span class="line"> - disable-ec2-metadata</span><br><span class="line"> - runcmd</span><br><span class="line"></span><br><span class="line">## fianl 阶段运行的 modules</span><br><span class="line">cloud_final_modules:</span><br><span class="line"> - rightscale_userdata</span><br><span class="line"> - scripts-per-once</span><br><span class="line"> - scripts-per-boot</span><br><span class="line"> - scripts-per-instance</span><br><span class="line"> - scripts-user</span><br><span class="line"> - ssh-authkey-fingerprints</span><br><span class="line"> - keys-to-console</span><br><span class="line"> - phone-home</span><br><span class="line"> - final-message</span><br><span class="line"> ## 每个模块自己定义默认的频率，如果说想设置一个 bmz 模块在每次启动实例都运行，可以写成下面这样</span><br><span class="line"> ## - [bmz, always]</span><br><span class="line"></span><br><span class="line">system_info:</span><br><span class="line"> distro: centos</span><br><span class="line"> ssh_svcname: sshd</span><br><span class="line"></span><br><span class="line"># vim:syntax=yaml</span><br></pre></td></tr></table></figure><h3 id="发行版"><a href="#发行版" class="headerlink" title="发行版"></a>发行版</h3><p>cloud-init 设计支持绝大多数 linux 发行版，比如 centos ubuntu arch fedora 等等。<br>对于每个发行版在使用上的差异，cloud-init 是有一套自己的抽象来适配的。所以也就有了一些只在某些发行版中存在的 module，比如 apt_configure 模块只在 ubuntu 和 debian 中使用，centos 等等是不用这个的。</p><h2 id="基础用法"><a href="#基础用法" class="headerlink" title="基础用法"></a>基础用法</h2><p>我们在使用cloud-init时一般不会特别地去执行cloud-init相关的命令，在云实例的启动过程中操作系统会按正常流程去执行cloud-init，不过当需要开发&#x2F;调试cloud-init的时候，这些命令会带来很大的帮助。</p><ol><li>执行四个阶段</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># local阶段</span><br><span class="line">cloud-init init --local</span><br><span class="line"># network阶段</span><br><span class="line">cloud-init init</span><br><span class="line"># config阶段</span><br><span class="line">cloud-init modules --mode=config</span><br><span class="line"># final阶段</span><br><span class="line">cloud-init modules --mode=final</span><br></pre></td></tr></table></figure><ol start="2"><li>查询</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 查询cloud-id</span><br><span class="line">cloud-id</span><br><span class="line"># 查询cloud-init执行状态</span><br><span class="line">cloud-init status -l</span><br><span class="line"># 查询metadata</span><br><span class="line">cloud-init query &lt;variable&gt;</span><br><span class="line">cloud-init query -l</span><br></pre></td></tr></table></figure><ol start="3"><li>清缓存</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cloud-init clean</span><br><span class="line">## 磁盘上等于执行下面的命令</span><br><span class="line">rm -rf /var/run/cloud-init/</span><br><span class="line">rm -rf /var/lib/cloud/</span><br><span class="line">rm -rf /var/log/cloud-init.log</span><br><span class="line">rm -rf /etc/sysconfig/network-scripts/ifcfg-*</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>aws-instance-controller</title>
      <link href="/2025/03/22/aws-instance-controller/"/>
      <url>/2025/03/22/aws-instance-controller/</url>
      
        <content type="html"><![CDATA[<p>反编译过 aws-emr 在虚机内的控制进程 instance-controller<br><img src="/2025/03/22/aws-instance-controller/image1.png"></p><h2 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line">private static Logger log = LoggerFactory.getLogger(InstanceController.class);</span><br><span class="line">private int internalInterfaceServicePort = 8444;</span><br><span class="line">private int externalInterfaceServicePort = 8443;</span><br><span class="line">private final HeartbeatFileCreator heartbeatFileCreator;</span><br><span class="line">private final Ec2Metadata ec2Metadata;</span><br><span class="line">private ExtraInstanceData extraInstanceData;</span><br><span class="line">private volatile HibernateConnector hibernateConnector;</span><br><span class="line">private volatile InstanceConfigurator instanceConfigurator;</span><br><span class="line">private volatile BootstrapActionLog bootstrapActionLog = null;</span><br><span class="line">private volatile Updater localInstanceStateUpdater;</span><br><span class="line">private final SslConfigurer sslConfigurer;</span><br><span class="line">private volatile MasterProtoBufServer masterExternalInterfaceServer;</span><br><span class="line">private volatile MasterProtoBufServer masterInternalInterfaceServer;</span><br><span class="line">private volatile StepGarbageCollector stepGarbageCollector;</span><br><span class="line">private volatile DiskSpaceManager diskSpaceManager;</span><br><span class="line">private volatile Poller poller;</span><br><span class="line">private volatile DeleteKerberosPrincipalExecutor deleteKerberosPrincipalExecutor;</span><br><span class="line">private volatile JobFlowStateUpdater jobFlowStateUpdater;</span><br><span class="line">private volatile RemoteInstanceConfigurator slaveConfigurator;</span><br><span class="line">private volatile RemoteInstanceStateUpdater slaveStateUpdater;</span><br><span class="line">private volatile StepExecutionManager masterStepExecutionManager;</span><br><span class="line">private volatile KerberosTicketManager kerberosTicketManager;</span><br><span class="line">private volatile MetricsCollectorManager metricsCollectorManager;</span><br><span class="line">private volatile ConcreteRpcServer concreteRpcServer;</span><br><span class="line">private volatile MetricConnector metricConnector;</span><br><span class="line">private ShutdownActionRunner shutdownActionRunner = null;</span><br><span class="line">private AppShutDownActioner appShutDownActioner = null;</span><br><span class="line">private LakeFormationLifecycle lakeFormationLifecycle = null;</span><br><span class="line">private final Context context;</span><br><span class="line">private final String instanceId;</span><br><span class="line">private final ResourceManagerWebService resourceManagerWebService;</span><br><span class="line">private final HistoryServerWebService historyServerWebService;</span><br><span class="line">private final MapReduceApplicationMasterWebService mapReduceApplicationMasterWebService;</span><br><span class="line">private volatile InstanceMetricsCollector instanceMetricsCollector;</span><br><span class="line">private volatile MetricsCollectorClientProvider metricsCollectorClientProvider;</span><br><span class="line">private volatile MetricsCollectorCoreTaskManager metricsCollectorCoreTaskManager;</span><br><span class="line">private final boolean isMaster;</span><br><span class="line">private final boolean isSlave;</span><br><span class="line">public static final Object dbUpdateLock = new Object();</span><br><span class="line">HibernateDb hdb;</span><br><span class="line"></span><br><span class="line">public InstanceController(Context context) throws IOException &#123;</span><br><span class="line">    this.context = context;</span><br><span class="line"> this.ec2Metadata = context.getEc2Metadata();</span><br><span class="line"> this.extraInstanceData = context.getExtraInstanceData();</span><br><span class="line"> String icDbDir = context.getApplicationProperties().getICDbDir(); // 通过 &quot;ic.db.dir&quot; ，默认&quot;/emr/instance-controller/db&quot;</span><br><span class="line"> this.hdb = new HibernateDb(icDbDir, true); //使用 hsqldb dialect + hibernate 做数据持久化；</span><br><span class="line"> this.isMaster = UserDataProvider.getUserData().isMaster;</span><br><span class="line"> this.isSlave = UserDataProvider.getUserData().isSlave;</span><br><span class="line"> this.instanceId = this.ec2Metadata.getInstanceId();</span><br><span class="line"> this.sslConfigurer = new SslConfigurer(UserDataProvider.getUserData());</span><br><span class="line"></span><br><span class="line"> try &#123;</span><br><span class="line">        this.sslConfigurer.configure();</span><br><span class="line"> &#125; catch (NoSuchAlgorithmException | KeyStoreException | CertificateException | InvalidKeySpecException var5) &#123;</span><br><span class="line">        log.error(var5.getClass().getName(), var5);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    this.heartbeatFileCreator = new HeartbeatFileCreator(context.getApplicationProperties().getHeartbeatDir());</span><br><span class="line"> this.hibernateConnector = this.hdb.getHibernateConnector();</span><br><span class="line"> this.stepGarbageCollector = new StepGarbageCollector(context, this.hibernateConnector);</span><br><span class="line"> this.kerberosTicketManager = new KerberosTicketManager(context);</span><br><span class="line"> context.setKerberosTicketManager(this.kerberosTicketManager);</span><br><span class="line"> ApplicationUtil.initializeS3Policies(this.hibernateConnector);</span><br><span class="line"> ApplicationUtil.initializeS3DebuggingPolicies(this.hibernateConnector);</span><br><span class="line"> if (this.isMaster || this.isSlave &amp;&amp; UserDataProvider.getUserData().isPrivateSubnetCluster) &#123;</span><br><span class="line">        this.startExternalProtoBufServer();</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    if (context.getExtraInstanceData() == null) &#123;</span><br><span class="line">        log.info(&quot;ExtraInstanceData is null, will wait for call from clustermanager&quot;);</span><br><span class="line"> this.extraInstanceData = ApplicationUtil.waitForExtraInstanceDataAndLoad(context);</span><br><span class="line"> context.setExtraInstanceData(this.extraInstanceData);</span><br><span class="line"> &#125; else &#123;</span><br><span class="line">        this.extraInstanceData = context.getExtraInstanceData();</span><br><span class="line"> log.info(&quot;ExtraInstanceData is already initialized: &#123;&#125;&quot;, this.extraInstanceData.writeToJsonString());</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    if (ApplicationUtil.isV2FrameworkEnabled(context.getApplicationProperties(), context.getExtraInstanceData())) &#123;</span><br><span class="line">        log.info(&quot;v2 framework enabled, restarting&quot;);</span><br><span class="line"> System.exit(0);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    this.resourceManagerWebService = new ResourceManagerClient(context);</span><br><span class="line"> this.historyServerWebService = new HistoryServerClient(context);</span><br><span class="line"> this.mapReduceApplicationMasterWebService = new MapReduceApplicationMasterClient(context);</span><br><span class="line"> this.metricConnector = new MetricConnectorImpl(context, this.resourceManagerWebService, this.historyServerWebService, this.mapReduceApplicationMasterWebService);</span><br><span class="line"> this.localInstanceStateUpdater = new Updater(this.hibernateConnector, this.extraInstanceData, new Callback() &#123;</span><br><span class="line">        public void onUpdate(CommonInstanceRecord before, CommonInstanceRecord after) &#123;</span><br><span class="line">            if (InstanceController.this.bootstrapActionLog != null) &#123;</span><br><span class="line">                InstanceController.this.bootstrapActionLog.onInstanceRecordUpdated(InstanceController.this.instanceId, before, after);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"> this.instanceConfigurator = new InstanceConfigurator(context, this.hibernateConnector, this.localInstanceStateUpdater, this.resourceManagerWebService, this);</span><br><span class="line"> if (this.isMaster) &#123;</span><br><span class="line">        log.info(&quot;Starting poller...&quot;);</span><br><span class="line"> AppMonitorRegistry appMonitorRegistry = new AppMonitorRegistry(context);</span><br><span class="line"> InstanceJointStatusMap instanceJointStatusMap = new InstanceJointStatusMap(context.getApplicationProperties().getNoCheckInThresholdToConsiderTerminatedInMin());</span><br><span class="line"> this.poller = (new Builder()).withHibernateConnector(this.hibernateConnector).withContext(context).withAppMonitorRegistry(appMonitorRegistry).withJointStatusMap(instanceJointStatusMap).build();</span><br><span class="line"> this.poller.start();</span><br><span class="line"> log.info(&quot;Starting delete kerberos principals executor&quot;);</span><br><span class="line"> this.deleteKerberosPrincipalExecutor = (new aws157.instancecontroller.common.DeleteKerberosPrincipalExecutor.Builder()).withHibernateConnector(this.hibernateConnector).withContext(context).withJointStatusMap(instanceJointStatusMap).build();</span><br><span class="line"> this.deleteKerberosPrincipalExecutor.start(DeleteKerberosPrincipalExecutor.DEFAULT_INITIAL_DELAY_IN_MIN, DeleteKerberosPrincipalExecutor.DEFAULT_PERIOD_IN_MIN);</span><br><span class="line"> this.metricsCollectorManager = new MetricsCollectorManager(context, true);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    this.metricsCollectorClientProvider = new MetricsCollectorClientProvider();</span><br><span class="line"> if (this.isSlave) &#123;</span><br><span class="line">        this.metricsCollectorManager = new MetricsCollectorManager(context, false);</span><br><span class="line"> this.metricsCollectorCoreTaskManager = new MetricsCollectorCoreTaskManager(context, this.metricsCollectorManager, this.createInternalClient());</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">    InstanceControllerExternalServiceImpl.completeInitialization(this.instanceConfigurator, this.metricConnector, this.poller);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="userdata"><a href="#userdata" class="headerlink" title="userdata"></a>userdata</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean isMaster;</span><br><span class="line">public boolean isSlave;</span><br><span class="line">public Boolean appsRepoProvisionedByNodeProvisioner;</span><br><span class="line">public String publicKey;</span><br><span class="line">public List&lt;String&gt; extraInstanceDataPresignedUrls;</span><br><span class="line">public List&lt;String&gt; serializedKeyStoreContainerPresigneUrl;</span><br><span class="line">public String systemLogSignedPolicy;</span><br><span class="line">public String clusterId;</span><br><span class="line">public EmrNodeTlsContext nodeTlsContext;</span><br><span class="line">public RpcConfiguration rpcConfiguration;</span><br><span class="line">public boolean isPrivateSubnetCluster = false;</span><br><span class="line">public boolean multiMasterEnabled = false;</span><br><span class="line">public KeyStoreContainer instanceKeyStoreContainer;</span><br><span class="line">public DiskEncryptionConfiguration diskEncryptionConfiguration;</span><br><span class="line">public AwsClientConfiguration instanceAwsClientConfiguration;</span><br></pre></td></tr></table></figure><p>从&#x2F;var&#x2F;aws&#x2F;emr&#x2F;userData.json直接gson转化</p><ol><li>userData.json不存在时使用 com.amazonaws.util.EC2MetadataUtils.getUserData() 能够获取ec2MetaData,从而获取到 json 中类似的内容，这块是 aws 另外一个 jar 包的能力，暂时看不到无法知道细节。</li><li>extraInstanceData<br>context 没有 ：通过&#x2F;emr&#x2F;instance-controller&#x2F;lib&#x2F;info&#x2F;extraInstanceData.json文件中获取，如果文件不存在，则从 ec2MetaData 中获取，如果还没有就sleep(10s)轮训从文件或ec2MetaData 中获取直到拿到内容，拿到后写入到&#x2F;emr&#x2F;instance-controller&#x2F;lib&#x2F;info&#x2F;extraInstanceData.json。<br>context 有：直接从 context 中拿<br>拿到后会去根据 extraInstanceData 是否启动了 v2 frame 来重启 instanceController，也就是说 v1 v2 framework 一个是从 default 配置来，一个是从 extraInstanceData 来；</li><li>master &amp; slave<br>通过&#x2F;var&#x2F;aws&#x2F;emr&#x2F;userData.json 或 com.amazonaws.util.EC2MetadataUtils.getUserData() 里确定，猜测在启动 ec2 的时候置入到文件。</li><li>hibernate<br>通过icDbDir配置的路径配合 hsql 进行持久化，配置如下<br><img src="/2025/03/22/aws-instance-controller/icdbdir.png"><br>各种地方都加入了 hibernate 进行辅助，比如 stepGarbageCollector</li><li>ssl configurer<br><img src="/2025/03/22/aws-instance-controller/ssl.png"></li><li>heartbeatFileCreator<br>通过这个类创建 heartBeatWatcher ，里面创建了一个本地文件，一种是 $baseDir&#x2F;logpusher 一种是 $baseDir&#x2F;uplink，还有一种可能是测试用的 $baseDir&#x2F;null。<br>心跳的最后时间在这个文件里更新，通过文件的更新时间来确定心跳是否 outdated。写死 heart beat delay 1800000 millis。</li><li>stepGarbageCollector</li><li>kerberosTicketManager<br>PS:有一个选项是可以配置外部 KDC，根据 context 中的传参可以确定使用那里的 kdc，外部 kdc 不记录 kerberos 相关状态。 </li><li>externalProtobufServer<br>InstanceControllerExternalServiceImpl<br>initialize<br>completeInitialization<br>configure<br>addSteps &#x2F;&#x2F; 增加 step<br>getStatus<br>setSignedPolicy<br>setDebuggingSignedPolicy<br>getMetricsAndEvents<br>setManagedResizeConfiguration<br>configureMaster<br>modifyConfiguration<br>ping<br>shutdown<br>cleanupSteps<br>getEvents<br>cancelSteps<br>setAdditionalConfig<br>getStepsStatus<br>仅master 和 userData.privateSubNetCluster 的 slave 启动，最大线程数10个。</li><li>internalProtobufServer<br>master slave 均启动，最大线程数100个。</li><li>rm client</li><li>history server client</li><li>am client</li><li>metrics collector</li><li>localInstanceStateUpdater<br>本地实例的状态会记录到 hsql 中，上来就把 bootstrapactionlog 的状态更新，估计是为了启动虚机失败的时候立刻能从 hsql 中查到状态等；</li><li>instanceConfigurator ps:能看出来这块代码的风格已经变化了。<br>new InstanceConfigurator(context, this.hibernateConnector, this.localInstanceStateUpdater, this.resourceManagerWebService, this)</li></ol><ul><li>pid file : &#x2F;var&#x2F;run&#x2F;node-provisioner.pid</li><li>hadoopConnector &#x2F;&#x2F; 稍微有点僵硬，按理说应该放在 task 的概念里，应该是从早起hadoop 1.x 慢慢迭代过来的<br>State JobStatus DataNodeState NameNodeState等<br>有一些过时的命令，全部操作都是通过 bash -l -c xxx 的形式。操作挺全的，decommission datanode 、 hdfs report（非常多）、 job status 、kill job、namenode format 、bootstrapStandby、zkfc format、newEditsOnly<br>每次执行完还会 saveCommandOutputToFiles ，记录在 &#x2F;emr&#x2F;instance-controller&#x2F;log&#x2F;hadoop-commands&#x2F; 下面按时间戳分为执行 stdout 和 stderr 两个文件</li><li>singleThreadExecutor 单线程的线程池来 submit task；<br>doConfigure(configFiles) 就是其中的一类 task<br>doReconfiguration</li><li>doInitConfiguration<br>用到了concreteRPCServer,后面详细介绍<br><img src="/2025/03/22/aws-instance-controller/doinit.png"></li></ul><ol start="17"><li>master 上启动 poller<br>Poller 使用 builder 模式初始化，包含</li></ol><ul><li>hibernateConnector</li><li>appMonitorRegistry<br>有一个名为AppPoller-Bg-Thread的定时线程池，运行每个 appMonitor；<br>appMonitor 里默认包括 hdfs 、yarn、 presto 的appMonitor，hbase 的monitor 是 null，且只有 hbase-client。本身还有一个抽象方法，是后续扩展其他组件用的。</li><li>gracefulShrink</li><li>context</li><li>instanceJointStatusMap</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">private static final long LOST_CUTOFF_MILLIS = TimeUnit.MINUTES.toMillis(10L); / / 默认10微妙</span><br><span class="line">private static final int AGE_THRESHOLD_TO_CONSIDER_NODE_STATE_IS_STABLE_IN_SEC = (int)TimeUnit.MINUTES.toSeconds(10L); / / 默认10秒</span><br><span class="line">private final long timeThresholdToConsiderTerminatedInSec; / / 默认max(ic.no-checkin-threshold-to-consider-terminated-in-min, 30) 后转化成秒， 如果不传就是3600秒</span><br></pre></td></tr></table></figure><ol start="18"><li>每台虚机的信息映射<br>ConcurrentSkipListMap&lt;String, InstanceJointStatus&gt; instances &#x3D; new ConcurrentSkipListMap&lt;&gt;();</li><li>虚机 id 和 dnsName 映射<br>HashMap&lt;String, String&gt; privateDNSNameToInstanceId &#x3D; new HashMap&lt;&gt;();</li><li>虚机 id 和 privateIp 映射<br>HashMap&lt;String, String&gt; privateIpToInstanceId &#x3D; new HashMap&lt;&gt;();<br>InstanceJointStatus包含<br>id, hostname, remoteInstanceState, datanodeStatus, yarnNode, prestoNode, hdfsDrainTime, yarnDrainTime, hdfsActive, yarnActive, prestoActive<br>InstanceJointState 代表各个服务的状态，使用枚举类描述<br>RUNNING(0, 0),<br>IDLE(1, 1),<br>STARTING(2, 2),<br>DECOMMISSIONING(3, 3),<br>DECOMMISSIONED(4, 4),<br>FAILED(5, 5),<br>LOST(6, 6);<br>有一个比较重要的概念是 remoteInstanceState，这个最终是通过 DAO 获取的，应该是各个 instance 的状态都实时存储在 同一个 hsql 里。</li><li>gracefulShrink<br>暂未细致研究，缩容时重要服务的 decommision ，然后下线等等。</li><li>循环renew kerberos ticket<br>&#x2F;&#x2F; todo 细研究poller，主要是拉取各种信息和状态存库，然后有一些上传<br>master 上 do Short Poll jobs ：<br>pollEmrInstanceState<br>pollEmrStepsDbState<br>updateJointStates<br>updateLocalNodeProvisionerState<br>master 上 do Long Poll jobs ：<br>pollEmrStepsDbState();<br>pollMasterInstanceReactions();<br>pollEmrInstanceState();<br>pollAppStatus();<br>pollInstanceGroups();<br>doRollingReconfiguration();<br>KerberosUtils.renewKerberosTicketIfExpired(this.context);<br>doGracefulShrink();<br>updateJointStates();<br>pollLogPusherState();<br>healthMonitor.checkReactions();</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apache hbase</title>
      <link href="/2025/03/22/apache-hbase/"/>
      <url>/2025/03/22/apache-hbase/</url>
      
        <content type="html"><![CDATA[<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="/2025/03/22/apache-hbase/arch1.png" alt="架构图"></p><h3 id="hmaster"><a href="#hmaster" class="headerlink" title="hmaster"></a>hmaster</h3><ol><li>处理dml ddl 请求</li><li>region 分配和迁移 </li><li>管理 rs, 宕机恢复 </li><li>清理过期文件(hlog hfile)</li></ol><h3 id="region-server"><a href="#region-server" class="headerlink" title="region server"></a>region server</h3><ol><li>响应 IO 请求</li><li>写 WAL(hlog)</li><li>实际数据先写入缓存,后落盘,所以 hlog 有两个作用:</li></ol><ul><li>为了保证数据可用性,写缓存之前先顺序写 hlog</li><li>hbase 主从复制</li></ul><ol start="4"><li>block cache<br>读缓存: LRU 或 Bucket</li><li>Region<br>数据表分片,一个表的各个 region 放到不同的 rs 上;<br>region 由很多个 store 组成,每个 store 对应一个列簇;</li><li>Store<br>store 由 1 个 memstore 和 N 个 hfile 构成;<br>当落盘策略触发时,memstore 会异步 flush 数据 到 hfile 中,当 hfile 大小超过阈值,则会执行 compact</li></ol><h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><p>大数据生态的一致性协调组件,不过多赘述<br>在 hbase 架构里有下面作用:</p><ol><li>监测 master 宕机事件<br>选举 master</li><li>管理核心元数据<br>记录 hbase:meta 所在的 rs 地址</li><li>监测 rs 宕机<br>让 hmaster 知道并恢复宕机 rs 上的 region</li><li>表级别分布式锁(在2版本不知道还用不用)</li><li>region 状态变更<br>可能在 process v2 优化过</li></ol><h3 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h3><p>各种 hbase 文件的存储服务.<br>hfile hlog tmp数据 损坏的数据 和 archive 数据</p><h2 id="数据结构-LSM"><a href="#数据结构-LSM" class="headerlink" title="数据结构 LSM"></a>数据结构 LSM</h2><p>由内存的跳表+磁盘上的有序文件组成,额外还有布隆过滤器来判断 key 是否存储在某个块上</p><h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>跳表<br>特点就是 分层 有序 无穷首尾 上层链表是下层链表的子集<br>查询复杂度是 O(logn)<br>非常直接的空间换时间的检索方式</p><h3 id="kv-存储格式"><a href="#kv-存储格式" class="headerlink" title="kv 存储格式"></a>kv 存储格式</h3><p><img src="/2025/03/22/apache-hbase/kv.png"><br>因为key 是有序的,<br>排序的优先级为: 1.rowkey 2.cf 3.column 4.timestamp<br>越大约靠前</p><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>从 LSM 的结构和特点上,引出三个问题</p><ol><li>效率怎样?<br>写性能好,读性能差<br>写入是基于 MVCC 的,所以写 LSM 时都是 append 操作,在之前的时代磁盘顺序写就是比随机写快很多的</li><li>memstore 怎么转化为 hfile?<br>memstore flush 时先创建一个快照,再生产一个新的 memstore 给新的写入,然后把快照异步写成 hfile</li><li>hfile 过多怎么办?<br>汇总多个 hfile 时需要选出需要的数据版本,这会占用大量的磁盘 IO.<br>compact 使用多路归并的方式合并 hfile</li></ol><h3 id="Why-HDFS"><a href="#Why-HDFS" class="headerlink" title="Why HDFS"></a>Why HDFS</h3><p>LSM 所有操作都是顺序写 -&gt; 和 hdfs 完全契合<br>文件最终是由 compact 各个小的 hfile 到一个大的 hfile -&gt; hdfs 适合存储大文件</p><h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>hbase get 时利用 bloom 过滤大量无效的块,节省磁盘 io</p><h2 id="写过程"><a href="#写过程" class="headerlink" title="写过程"></a>写过程</h2><p><img src="/2025/03/22/apache-hbase/write.png"></p><ol><li>客户端</li></ol><ul><li>请求zk,拿到hbase:meta所在regionserver </li><li>请求定位到meta表所在的region server,拿到实际要写入的region server </li><li>将数据序列化后发送写请求给存数据的 region server</li></ul><ol start="2"><li>RS 视角</li></ol><ul><li>拿到客户端请求,反序列化put对象,进行一些必要的检查(region是否只读,memstore是否超限等)</li><li>拿到行锁acquire locks </li><li>内存中构建wal对象,一次写入操作中所有kv构建一条walEdits,并顺序写入到Hlog </li><li>写入memstore </li><li>释放行锁 </li><li>同步hlog对象到hdfs中,如果同步失败,memstore中会执行回滚. </li><li>结束写事务,回复client<br>此时 client 认为此次写入完成了;<br>后续 rs 会异步 flush memstore 到 hfile</li></ul><h2 id="什么时候-flush-成-hfile"><a href="#什么时候-flush-成-hfile" class="headerlink" title="什么时候 flush 成 hfile"></a>什么时候 flush 成 hfile</h2><p>默认有4个触发条件,额外还有一些配置或运维人员手动命令会影响</p><ol><li>Memstore级别<br>单个memstore达到flush.size</li><li>Region级别<br>一个Region中所有memstore大小总和超过 multiplier * flush.size</li><li>Regionserver级别<br>Regionserver中所有memstore大小总和超过低水位阈值 lower.limit * global.memstore.size,此时先flush 最大的memstore,依次执行,如果此时吞吐量高导致memstore大小又超过阈值,rs会阻塞写入,直到flush小于阈值.</li><li>额外配置级别</li></ol><ul><li>hlog数达到上限 rs.maxlogs,此时会选择最早的hlog进行flush </li><li>定期flush,默认一小时,但是有一定的随机延时,保证不是同一时间一起flush </li><li>运维手动执行 flush ‘tb_name’或者 flush ‘region’</li></ul><h2 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h2><p>读比写复杂,没有特别详细研究过.</p><blockquote><p>从面试时知道 hbase 自己实现过一个 hdfs client:FanOutOneBlockAsyncDFSOutput<br>原理应该是允许多线程写入多个 datanode,而不是通过 pipeline,而且异步的的,加速写入.<br>简单介绍一下流程</p></blockquote><ol><li>客户端视角</li></ol><ul><li>请求zk,拿到hbase:meta所在regionserver </li><li>请求定位到meta表所在的region server,拿到实际要的数据在哪些region server上哪些region </li><li>将大scan拆分成多个rpc,发送读请求给实际region server.</li></ul><ol start="2"><li>rs 视角</li></ol><ul><li>接受到用户请求,构建三层scanner. </li><li>条件过滤,淘汰不满足条件的scanner,每个有效的scanner seek到startKey </li><li>合并构建最小堆.按照scanner排序规则kv由小到大排序,不断pop这个优先级队列来获取kv有序集合.</li></ul><p><img src="/2025/03/22/apache-hbase/read.png"></p><blockquote><p>前两种 scanner多是调度作用,实际的查找还是通过 storefilescanner 和 memstorescanner<br>过滤策略有几种,先前介绍的布隆过滤器是其中一种<br>前面介绍的lsm数据存储结构存储的 key 是有序的</p></blockquote><h2 id="Region-和-RIT"><a href="#Region-和-RIT" class="headerlink" title="Region 和 RIT"></a>Region 和 RIT</h2><p>hbase 1.2 中 region 有如下13种类型<br><img src="/2025/03/22/apache-hbase/region-state.png"></p><h3 id="unassign-命令"><a href="#unassign-命令" class="headerlink" title="unassign 命令"></a>unassign 命令</h3><p>unassign 会让某个(些) region 下线.</p><p>Hbase 1.X 流程</p><ol><li>Master改zk状态为closing,自己内存状态pending_close</li><li>master发送close的rpc给rs</li><li>Rs先改zk,master监听到zk状态改变后,更新master状态closing</li><li>Rs执行真正的操作,如果region正在clush或者compact等待操作完成,否则将该region下所有memstore强制flush然后关闭.</li><li>关闭成功后zk更新状态zk_region_closed,master监听后将自己的region状态改成closed</li></ol><h3 id="assign"><a href="#assign" class="headerlink" title="assign"></a>assign</h3><p>hbase 1.X 流程<br>会让某个 region 上线</p><ol><li>Master改zk状态offline,自己内存状态pending_open.</li><li>master发送open的rpc给rs</li><li>Rs先改zk状态为<br>zk_region_opening,master监听到zk状态改变后,更新master状态opening.</li><li>Rs执行打开操作,初始化相关的服务.</li><li>打开成功后zk更新状态zk_region_opened,master监听后将自己的region状态改成open</li></ol><h3 id="RIT"><a href="#RIT" class="headerlink" title="RIT"></a>RIT</h3><p>说 RIT 之前,先要知道 hbase 的状态都存到哪些地方<br>在 HBASE 1.X 中,状态存储在三个地方:</p><ol><li>Meta表: 存储region所在rs,不存在中间状态</li><li>Master: 集群所有region信息,都是由rs通过zk通知给master的,所以master的状态是比实际状态滞后的.(web ui上的状态都是master内存的信息)</li><li>Zk中: 临时的信息,作为master和rs信息的媒介.<br>总结下来, HBASE 1.X 的集群,当这三个地方存储的 region 状态出现不一致,则称之为 RIT</li></ol><h3 id="举一个-RIT-的例子"><a href="#举一个-RIT-的例子" class="headerlink" title="举一个 RIT 的例子"></a>举一个 RIT 的例子</h3><p>Rs成功打开了一个region,但是远程更新hbase:meta时没成功;<br>此时master维护的region状态是opening<br>zk上是zk_region_opening<br>而hbase:meta存储的这个region所在rs是null,但是region已经在rs上打开了.</p><blockquote><p>上面写了很多在 HBASE 1.X,实际上 HBASE 2.X 借助 procedure v2 实现了 assignManager V2,彻底改变这些状态的流转过程<br>也是因为这个改造, RIT 在 HBASE 2.X 没有特别容易触发.<br>当然我没有详细研究过 hbase 2.x 里 procedure v2 的源码.只使用过 hbck2 工具运维过 HBASE 集群,处理大量 RIT 过</p></blockquote><h3 id="HBASE-2-X-的改造简要介绍"><a href="#HBASE-2-X-的改造简要介绍" class="headerlink" title="HBASE 2.X 的改造简要介绍"></a>HBASE 2.X 的改造简要介绍</h3><ol><li>region 状态改动全部需要经过 master, rs 自己不能修改 region 中的状态</li><li>依靠 procedure v2 的锁机制,专门实现了 assignProcedure</li><li>状态流转完全不依赖 ZK,全部以 master 的为准</li><li>状态展示提供到 hbase web ui 里 procedure&#x2F;locks 的页面</li></ol><p>这样做之后,彻底改变了 HBASE 1.X 容易触发 RIT,经常需要人手工运维<br>当然这么做也有缺点,就是在 procedure WAL 损坏时,会发生灾难性的 region 无法恢复,很可能丢数.</p><h2 id="SNAPSHOT"><a href="#SNAPSHOT" class="headerlink" title="SNAPSHOT"></a>SNAPSHOT</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>Hbase 数据备份恢复&#x2F;迁移发展</p><ol><li>Distcp + 关机备份. </li><li>copyTable,通过mr任务备份. </li><li>Snapshot 在线备份.<br>涉及的场景:</li></ol><ul><li>每天备份一次snapshot,定期清理过期快照,方便业务发生严重失误时能够回滚到前一个快照点.</li><li>对集群进行升级,确保升级异常可以不影响数据.</li><li>在线迁移数据,结合snapshot和复制技术.</li><li>导出离线数据,可以进行olap分析</li></ul><h3 id="如何生成和使用快照恢复数据"><a href="#如何生成和使用快照恢复数据" class="headerlink" title="如何生成和使用快照恢复数据"></a>如何生成和使用快照恢复数据</h3><ol><li>hbase shell</li></ol><ul><li>snapshot $表名 $快照名 </li><li>restore_snapshot $快照名 </li><li>clone_snapshot $快照名 $新表名</li></ul><ol start="2"><li>exportSnapshot<br>将生成好的 snapshot 从 hdfsA 集群迁移到 hdfs B 集群<br>这个步骤是借助 mr 任务进行的.如果没有 mr 环境,则本地启动一个 mr 串行任务迁移</li></ol><h3 id="理念"><a href="#理念" class="headerlink" title="理念"></a>理念</h3><p>Snapshot本质上不会复制数据,而是生成元数据的引用<br>Snapshot生成时,先flush memstore,再对hfile建立指针.</p><h3 id="snapshot-实现过程"><a href="#snapshot-实现过程" class="headerlink" title="snapshot 实现过程"></a>snapshot 实现过程</h3><ol><li>表的各个region进行memsotre flush -&gt; 还记得memstore是什么级别的吗?</li><li>region info 元数据记录在每个region下的snapshot中</li><li>Region的所有hfile记录到snapshot中<br>hdfs上tmp目录有如下新文件<br>&#x2F;$hbase-dir&#x2F;.hbase-snapshot&#x2F;.tmp&#x2F;$snapshotname&#x2F;.snapshotinfo<br>&#x2F;$hbase-dir&#x2F;.hbase-snapshot&#x2F;.tmp&#x2F;$snapshotname&#x2F;.data.manifest</li><li>Master汇总region snapshot结果<br>hdfs上新增了下面几个文件<br>&#x2F;$hbase-dir&#x2F;.hbase-snapshot&#x2F;$snapshotname&#x2F;data.manifest<br>&#x2F;$hbase-dir&#x2F;.hbase-snapshot&#x2F;$snapshotname&#x2F;.snapshotinfo<br>&#x2F;$hbase-dir&#x2F;.hbase-snapshot&#x2F;$snapshotname&#x2F;.inprogress</li></ol><h3 id="为什么-clone-snapshot-命令是秒级完成的"><a href="#为什么-clone-snapshot-命令是秒级完成的" class="headerlink" title="为什么 clone_snapshot 命令是秒级完成的"></a>为什么 clone_snapshot 命令是秒级完成的</h3><p>先说他的作用:复制快照到一个新的表<br>再说他的过程:</p><ol><li>预检查</li><li>在tmp目录下生成.tabledesc</li><li>在tmp目录中,根据manifest新建region目录以及关联hfile</li><li>将表目录从tmp移动到实际数据位置</li><li>修改hbase:meta,添加新region信息</li><li>region assign到各个rs,在zk中将新表znode状态改为enabled.</li></ol><h3 id="运维小技巧"><a href="#运维小技巧" class="headerlink" title="运维小技巧"></a>运维小技巧</h3><h4 id="重启-rs-会触发-serverCrashProcedure-重新分配-region-需要时间-而且容易触发-RIT"><a href="#重启-rs-会触发-serverCrashProcedure-重新分配-region-需要时间-而且容易触发-RIT" class="headerlink" title="重启 rs 会触发 serverCrashProcedure,重新分配 region 需要时间,而且容易触发 RIT"></a>重启 rs 会触发 serverCrashProcedure,重新分配 region 需要时间,而且容易触发 RIT</h4><h4 id="出现-RIT-时不要无脑重启服务-先使用-hback-或-hbck2-工具排查原因"><a href="#出现-RIT-时不要无脑重启服务-先使用-hback-或-hbck2-工具排查原因" class="headerlink" title="出现 RIT 时不要无脑重启服务,先使用 hback 或 hbck2 工具排查原因"></a>出现 RIT 时不要无脑重启服务,先使用 hback 或 hbck2 工具排查原因</h4><h4 id="hbck2-只在-HBASE-2-0-6-版本以上可用"><a href="#hbck2-只在-HBASE-2-0-6-版本以上可用" class="headerlink" title="hbck2 只在 HBASE 2.0.6 版本以上可用"></a>hbck2 只在 HBASE 2.0.6 版本以上可用</h4><h4 id="RIT-有一个停服的恢复步骤"><a href="#RIT-有一个停服的恢复步骤" class="headerlink" title="RIT 有一个停服的恢复步骤"></a>RIT 有一个停服的恢复步骤</h4><ol><li>先 hbase hbck &gt; hbck.log 查看情况.会看到哪些 region 有问题,处于什么状态</li><li>提取 hbck.log 中 region 的 encode name<br>grep “&#x3D;&gt;” hbck.log | awk -F”.” ‘{print $2}’ &gt; ~&#x2F;zx.1<br>grep “&#x3D;&gt;” hbck.log | awk -F”.” ‘{print $2” CLOSED”}’ &gt; ~&#x2F;zx.2</li><li>zx.1 文件能看出多少 region 不一致<br>cat zx.1 |wc -l</li><li>zx.1 中是纯粹的 region encode name. zx.2 是有 CLOSED 后缀的 encode name.当 hbck2 的版本大于 1.3 时,可以批量手动改变 region 状态<br>但是我之前运维使用 hbck2 1.1 版本,不支持批量,可以手动替换挨个 region 执行<br>hbase hbck -j hbase-hbck2-1.1.0.jar setRegionState 2bb110fca1ef1c4c24213ab87c9262bd CLOSED<br>由于每个 hbase hbck 命令会启动一个 jvm,200个 jvm 串行可能耗费很久(小时级别),我的建议是多个机器并行执行不同的批次<br>执行完成后,所有有问题的 REGION 已经手动进入 CLOSED 状态</li><li>将 STANDBY HMASTER(master-1)停机,避免重启后切主导致 hmaster 内存信息不一致</li><li>使用 hbck2 清除当前所以 procedure 的流程,避免锁导致后续操作阻塞<br>procedure id 可以在 hmaster web ui 上看到,bypass 是强行消除<br>hbase hbck -j &#x2F;opt&#x2F;bmr&#x2F;hbase&#x2F;hbase-operator-tools&#x2F;hbase-hbck2-1.1.0.jar bypass PROCEDURE ID</li><li>重启 active master 刷新内存中 region 的真实状态</li><li>重启成功后会加载小段时间,我们带 procedure 都执行完成后,使用 hbck2 的批量 assigns 命令将 zx.1 中这些 CLOSED region 上线<br>hbase hbck -j hbase-hbck2-1.1.0.jar assigns -i .&#x2F;zx.1</li><li>再次执行 hbase hbck 查看集群 region 状态</li></ol><h4 id="当-rowkey-设计不够散列时-容易在某几个-region-server-上堆积大量的-region"><a href="#当-rowkey-设计不够散列时-容易在某几个-region-server-上堆积大量的-region" class="headerlink" title="当 rowkey 设计不够散列时,容易在某几个 region server 上堆积大量的 region"></a>当 rowkey 设计不够散列时,容易在某几个 region server 上堆积大量的 region</h4><p>一般这时候要看 hdfs 本地性.<br>可以先分散 datanode 数据,然后再让 hbase 自动根据 compaction 分散</p><h4 id="compression"><a href="#compression" class="headerlink" title="compression"></a>compression</h4><p>设置表级别的压缩,减少传输带宽</p><h4 id="rs-服务的-region-数"><a href="#rs-服务的-region-数" class="headerlink" title="rs 服务的 region 数"></a>rs 服务的 region 数</h4><p>CDH 还是官方有过介绍,在追求性能的情况下,每个 rs 管理的 region 数在100-200是最优的,不要超过300,超过应该扩容后做 region balance<br>不然很容易造成 rs 级别的 memstore flush,导致 某个 rs 写请求处理慢.<br>粗略配置 region 个数的计算公式为:<br>((RS Xmx) * hbase.regionserver.global.memstore.size) &#x2F; (hbase.hregion.memstore.flush.size)<br>基于这个公式部署你对 hbase 的预期,并在 region 数目超限时及时扩容,保持集群稳定</p>]]></content>
      
      
      
        <tags>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apache ambari</title>
      <link href="/2025/03/21/apache-ambari/"/>
      <url>/2025/03/21/apache-ambari/</url>
      
        <content type="html"><![CDATA[<h2 id="官方定义"><a href="#官方定义" class="headerlink" title="官方定义"></a>官方定义</h2><p><a href="https://cwiki.apache.org/confluence/display/AMBARI/Ambari+Design">https://cwiki.apache.org/confluence/display/AMBARI/Ambari+Design</a><br>主要看这里的 ambari architecture 就好,官方的才是权威的,网上很多一知半解,实践之后完全不对</p><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><ol><li>平台适配 ubuntu 、windows… -&gt; rpm yum…</li><li>插拔组件 启动、关闭、管理配置</li><li>升级&#x2F;版本控制 hadoop发行版 -&gt; cdh&#x2F;hdp…</li><li>扩展性 扩（缩）容集群机器、增加（减少）新服务</li><li>恢复 保证宕机或服务挂后的恢复机制</li><li>安全 kerberos&#x2F;authentication&#x2F;authorization</li><li>监控 error trace 告警、日志</li></ol><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><ol><li>Stack -&gt; 发行版</li><li>Service -&gt; yarn&#x2F;hdfs&#x2F;hive&#x2F;custom</li><li>Component -&gt; nm&#x2F;rm&#x2F;nn&#x2F;hivemetastore&#x2F;custom-serviceA customB</li></ol><h2 id="基本组件"><a href="#基本组件" class="headerlink" title="基本组件"></a>基本组件</h2><p>Ambari-server: 巨石管控,管控各种状态<br>Ambari-web: 嵌入在 ambari-server 里的 httpserver,基于 web socket;<br>Ambari-agent: slave 节点,无状态<br>Ambari-metrics-collector: 监控采集,上报<br>Ambari-metrics-monitor: 监控汇总聚合<br><img src="/2025/03/21/apache-ambari/arch1.png" alt="架构"></p><h2 id="ambari-server"><a href="#ambari-server" class="headerlink" title="ambari-server"></a>ambari-server</h2><p><img src="/2025/03/21/apache-ambari/as-arch.png" alt="as-arch"></p><h3 id="HeartBeatHandler"><a href="#HeartBeatHandler" class="headerlink" title="HeartBeatHandler"></a>HeartBeatHandler</h3><p>处理 Agent 的 Heartbeat 请求（节点状态信息和Agent的操作结果）</p><h3 id="Coordinator"><a href="#Coordinator" class="headerlink" title="Coordinator"></a>Coordinator</h3><p>主要在接收用户操作请求后，检查是否符合要求，通过stageplanner分解成一组操作，最后提供给ActionManager去完成执行操作。</p><h3 id="FSM"><a href="#FSM" class="headerlink" title="FSM"></a>FSM</h3><p>维护组件状态的有限状态机。</p><ol><li>Live Cluster State：集群现有状态</li><li>Desired State：用户希望该节点所处状态，还没有在节点生效</li><li>Action State：操作状态</li></ol><h2 id="ambari-agent"><a href="#ambari-agent" class="headerlink" title="ambari-agent"></a>ambari-agent</h2><p>采集所在节点的信息并且汇总发送心跳发送汇报给ambari-server。<br>处理ambari-server的执行请求。<br><img src="/2025/03/21/apache-ambari/aa-arch.png" alt="aa-arch"></p><h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><p>messageQueue<br>包括节点状态信息（包括注册信息）和执行结果信息，并且汇总后通过心跳发送给ambari-server</p><h3 id="ActionQueue"><a href="#ActionQueue" class="headerlink" title="ActionQueue"></a>ActionQueue</h3><p>用于接收ambari-server发送过来的状态操作，然后交给执行器调用puppet或Python脚本等模块执行任务</p><h2 id="ambari-metrics"><a href="#ambari-metrics" class="headerlink" title="ambari-metrics"></a>ambari-metrics</h2><p>又称AMS（Ambari-Metrics-System），是Ambari中负责监控集群状态的功能组件。内含ambari-xxx-sink(java)、ambari-metrics-collector(java)、ambari-metrics-monitor(java)等；<br>AMS 也是一个 Master-Slave 结构的框架。Master 模块便是 Metrics Collector，Slave 则是 Metrics Monitor 和 Hadoop Sinks。Salve 模块负责收集信息，并发送给 Collector。<br>Ambari收集两类信息放到Collector上</p><ol><li>各节点“系统级”的指标<br>通过安装在每个节点上的Metrics Monitor来收集的；</li><li>Hadoop各组件的指标<br>通过面向特定Hadoop组件的Sink来收集的。</li></ol><h2 id="服务交互"><a href="#服务交互" class="headerlink" title="服务交互"></a>服务交互</h2><p><img src="/2025/03/21/apache-ambari/interact.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apache dolphinscheduler</title>
      <link href="/2025/03/21/apache-dolphinscheduler/"/>
      <url>/2025/03/21/apache-dolphinscheduler/</url>
      
        <content type="html"><![CDATA[<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><h3 id="简单易用"><a href="#简单易用" class="headerlink" title="简单易用"></a>简单易用</h3><p>可视化 DAG: 用户友好的，通过拖拽定义工作流的，运行时控制工具<br>模块化操作: 模块化有助于轻松定制和维护。</p><h3 id="丰富的使用场景"><a href="#丰富的使用场景" class="headerlink" title="丰富的使用场景"></a>丰富的使用场景</h3><p>支持多种任务类型: 支持Shell、MR、Spark、SQL等10余种任务类型，支持跨语言，易于扩展<br>丰富的工作流操作: 工作流程可以定时、暂停、恢复和停止，便于维护和控制全局和本地参数。</p><h3 id="High-Reliability"><a href="#High-Reliability" class="headerlink" title="High Reliability"></a>High Reliability</h3><p>高可靠性: 去中心化设计，确保稳定性。 原生 HA 任务队列支持，提供过载容错能力。 DolphinScheduler 能提供高度稳健的环境。</p><h3 id="High-Scalability"><a href="#High-Scalability" class="headerlink" title="High Scalability"></a>High Scalability</h3><p>高扩展性: 支持多租户和在线资源管理。支持每天10万个数据任务的稳定运行。</p><h2 id="配置要求"><a href="#配置要求" class="headerlink" title="配置要求"></a>配置要求</h2><h3 id="Linux-操作系统版本要求"><a href="#Linux-操作系统版本要求" class="headerlink" title="Linux 操作系统版本要求"></a>Linux 操作系统版本要求</h3><p>Red Hat Enterprise Linux: 7.0 及以上<br>CentOS: 7.0 及以上<br>Oracle Enterprise Linux: 7.0 及以上<br>Ubuntu LTS: 16.04 及以上</p><blockquote><p>注意： 以上 Linux 操作系统可运行在物理服务器以及 VMware、KVM、XEN 主流虚拟化环境上</p></blockquote><h3 id="服务器建议配置"><a href="#服务器建议配置" class="headerlink" title="服务器建议配置"></a>服务器建议配置</h3><p>DolphinScheduler 支持运行在 Intel x86-64 架构的 64 位通用硬件服务器平台。对生产环境的服务器硬件配置有以下建议：<br>CPU: 4C+<br>内存: 8G+<br>硬盘类型: SAS<br>网络: 千兆<br>实例数量:1+</p><h3 id="网络要求"><a href="#网络要求" class="headerlink" title="网络要求"></a>网络要求</h3><p>DolphinScheduler正常运行提供如下的网络端口配置：<br>组件 默认端口 说明<br>MasterServer 5678 非通信端口，只需本机端口不冲突即可<br>WorkerServer 1234 非通信端口，只需本机端口不冲突即可<br>ApiApplicationServer 12345 提供后端通信端口</p><blockquote><p>注意：<br>MasterServer 和 WorkerServer 不需要开启网络间通信，只需本机端口不冲突即可<br>管理员可根据实际环境中 DolphinScheduler 组件部署方案，在网络侧和主机侧开放相关端口</p></blockquote><h3 id="客户端-Web-浏览器要求"><a href="#客户端-Web-浏览器要求" class="headerlink" title="客户端 Web 浏览器要求"></a>客户端 Web 浏览器要求</h3><p>DolphinScheduler 推荐 Chrome 以及使用 Chromium 内核的较新版本浏览器访问前端可视化操作界面</p><h3 id="时钟同步"><a href="#时钟同步" class="headerlink" title="时钟同步"></a>时钟同步</h3><p>为避免可能影响任务执行的内部集群通信问题，请确保所有集群节点上的时钟与公共时钟源同步，例如使用 Chrony 和&#x2F;或 NTP。 同步时间确保集群中的每个节点都有相同的时间</p><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p>DAG： 全称 Directed Acyclic Graph，简称 DAG。工作流中的 Task 任务以有向无环图的形式组装起来，从入度为零的节点进行拓扑遍历，直到无后继节点为止。举例如下图：<br><img src="/2025/03/21/apache-dolphinscheduler/dag.png" alt="dag"></p><ol><li>流程定义：通过拖拽任务节点并建立任务节点的关联所形成的可视化DAG</li><li>流程实例：流程实例是流程定义的实例化，可以通过手动启动或定时调度生成。每运行一次流程定义，产生一个流程实例</li><li>任务实例：任务实例是流程定义中任务节点的实例化，标识着某个具体的任务</li><li>任务类型：目前支持有 SHELL、SQL、SUB_PROCESS(子流程)、PROCEDURE、MR、SPARK、PYTHON、DEPENDENT(依赖)，同时计划支持动态插件扩展，注意：其中 SUB_PROCESS类型的任务需要关联另外一个流程定义，被关联的流程定义是可以单独启动执行的</li><li>调度方式：系统支持基于 cron 表达式的定时调度和手动调度。命令类型支持：启动工作流、从当前节点开始执行、恢复被容错的工作流、恢复暂停流程、从失败节点开始执行、补数、定时、重跑、暂停、停止、恢复等待线程。 其中 恢复被容错的工作流 和 恢复等待线程 两种命令类型是由调度内部控制使用，外部无法调用</li><li>定时调度：系统采用 quartz 分布式调度器，并同时支持cron表达式可视化的生成</li><li>依赖：系统不单单支持 DAG 简单的前驱和后继节点之间的依赖，同时还提供任务依赖节点，支持流程间的自定义任务依赖</li><li>优先级 ：支持流程实例和任务实例的优先级，如果流程实例和任务实例的优先级不设置，则默认是先进先出</li><li>邮件告警：支持 SQL任务 查询结果邮件发送，流程实例运行结果邮件告警及容错告警通知</li><li>失败策略：对于并行运行的任务，如果有任务失败，提供两种失败策略处理方式，继续是指不管并行运行任务的状态，直到流程失败结束。结束是指一旦发现失败任务，则同时Kill掉正在运行的并行任务，流程失败结束</li><li>补数：补历史数据，支持区间并行和串行两种补数方式，其日期选择方式包括日期范围和日期枚举两种</li></ol><h2 id="模块介绍"><a href="#模块介绍" class="headerlink" title="模块介绍"></a>模块介绍</h2><ul><li>dolphinscheduler-master master模块，提供工作流管理和编排服务。 </li><li>dolphinscheduler-worker worker模块，提供任务执行管理服务。 </li><li>dolphinscheduler-alert 告警模块，提供 AlertServer 服务。 </li><li>dolphinscheduler-api web应用模块，提供 ApiServer 服务。 </li><li>dolphinscheduler-common 通用的常量枚举、工具类、数据结构或者基类 </li><li>dolphinscheduler-dao 提供数据库访问等操作。 </li><li>dolphinscheduler-extract extract模块，包含master&#x2F;worker&#x2F;alert的sdk </li><li>dolphinscheduler-service service模块，包含Quartz、Zookeeper、日志客户端访问服务，便于server模块和api模块调用 </li><li>dolphinscheduler-ui 前端模块</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apache sqoop2</title>
      <link href="/2025/03/20/apache-sqoop2/"/>
      <url>/2025/03/20/apache-sqoop2/</url>
      
        <content type="html"><![CDATA[<h2 id="SQOOP1"><a href="#SQOOP1" class="headerlink" title="SQOOP1"></a>SQOOP1</h2><p><img src="/2025/03/20/apache-sqoop2/1arch.png" alt="sqoop1 架构"></p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>使用纯客户端,每次运行就是一个 YARN 上的 APP.</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>命令行，对于 hive 这种亲身体会过字段过多时很吐血，而且没法覆盖全部数据类型，需要自己二开才能满足很多需求</p><h2 id="SQOOP2"><a href="#SQOOP2" class="headerlink" title="SQOOP2"></a>SQOOP2</h2><h3 id="架构-1"><a href="#架构-1" class="headerlink" title="架构"></a>架构</h3><p>使用 sqoop-server 集中管理 connector，web ui, restapi，并有安全机制</p><h3 id="使用-1"><a href="#使用-1" class="headerlink" title="使用"></a>使用</h3><p>命令行，webUI，rest api， connector 集中管理，所有安全链接安装在 sqoop server；<br>权限比较完善，connector 规范，只负责数据读写<br><img src="/2025/03/20/apache-sqoop2/2arch.png" alt="sqoop2 架构"></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>安装目录使用 &#x2F;opt&#x2F;sqoop2, 配置软链 &#x2F;etc&#x2F;sqoop2&#x2F;conf, 日志目录 &#x2F;opt&#x2F;sqoop2&#x2F;logs</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/sqoop2</span><br><span class="line">mkdir -p /etc/sqoop2/conf</span><br><span class="line">mkdir -p /var/run/sqoop2</span><br><span class="line">cd /opt/sqoop2 </span><br><span class="line">tar zxf sqoop-1.99.7-bin-hadoop200.tar.gz </span><br><span class="line">mv sqoop-1.99.7-bin-hadoop200/* .</span><br><span class="line">rm -rf sqoop-1.99.7-bin-hadoop200</span><br><span class="line">rm sqoop-1.99.7-bin-hadoop200.tar.gz</span><br><span class="line">mkdir /opt/sqoop2/logs</span><br><span class="line"></span><br><span class="line">## 增加用户、目录赋权</span><br><span class="line">useradd sqoop2 -G hadoop</span><br><span class="line">chown sqoop2:hadoop -R /opt/sqoop2</span><br><span class="line">chown sqoop2:hadoop -R /etc/sqoop2</span><br><span class="line"></span><br><span class="line">## 设置环境变量</span><br><span class="line">echo &quot;export SQOOP2_HOME=/opt/sqoop2&quot; &gt;&gt; /etc/profile</span><br><span class="line">echo &quot;export CATALINA_BASE=\$SQOOP2_HOME/server&quot; &gt;&gt; /etc/profile</span><br><span class="line">## 这一行是为了 mysql 到 hdfs demo 准备而添加了 mysql 的驱动，实际使用时按用户需要添加数据源的驱动包</span><br><span class="line">echo &quot;export SQOOP_SERVER_EXTRA_LIB=/opt/hive/lib/mysql-connector-java.jar:\$SQOOP2_HOME/server/lib&quot; &gt;&gt; /etc/profile</span><br><span class="line">## 拷贝 mysql 驱动到 sqoop2 环境变量中</span><br><span class="line">cp /opt/hive/lib/mysql-connector-java.jar ./server/lib/</span><br><span class="line">cp /opt/hive/lib/mysql-connector-java.jar ./shell/lib/</span><br><span class="line">echo &quot;export PATH=\$PATH:\$SQOOP2_HOME/bin&quot; &gt;&gt; /etc/profile</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>sqoop.properties</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line">org.apache.sqoop.log4j.debug=false</span><br><span class="line">org.apache.sqoop.log4j.rootLogger=INFO, file</span><br><span class="line">org.apache.sqoop.log4j.category.org.apache.sqoop=INFO</span><br><span class="line">org.apache.sqoop.log4j.appender.file=org.apache.log4j.RollingFileAppender</span><br><span class="line">org.apache.sqoop.log4j.appender.file.File=/opt/sqoop2/logs/sqoop.log</span><br><span class="line">org.apache.sqoop.log4j.appender.file.MaxFileSize=25MB</span><br><span class="line">org.apache.sqoop.log4j.appender.file.MaxBackupIndex=5</span><br><span class="line">org.apache.sqoop.log4j.appender.file.layout=org.apache.log4j.PatternLayout</span><br><span class="line">org.apache.sqoop.log4j.appender.file.layout.ConversionPattern=%d&#123;ISO8601&#125; %-5p [%l] %m%n</span><br><span class="line"># Audit logger for default configuration of FileAuditLogger</span><br><span class="line">org.apache.sqoop.log4j.logger.audit=INFO, audit</span><br><span class="line">org.apache.sqoop.log4j.appender.audit=org.apache.log4j.RollingFileAppender</span><br><span class="line">org.apache.sqoop.log4j.appender.audit.File=/opt/sqoop2/logs/audit.log</span><br><span class="line">org.apache.sqoop.log4j.appender.audit.MaxFileSize=25MB</span><br><span class="line">org.apache.sqoop.log4j.appender.audit.MaxBackupIndex=5</span><br><span class="line">org.apache.sqoop.log4j.appender.audit.layout=org.apache.log4j.PatternLayout</span><br><span class="line">org.apache.sqoop.log4j.appender.audit.layout.ConversionPattern=%d&#123;ISO8601&#125; %-5p [%l] %m%n</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Audit Loggers Configuration</span><br><span class="line"># Multiple audit loggers could be given here. To specify an</span><br><span class="line"># audit logger, you should at least add org.apache.sqoop.</span><br><span class="line"># auditlogger.[LoggerName].class. You could also provide</span><br><span class="line"># more configuration options by using org.apache.sqoop.</span><br><span class="line"># auditlogger.[LoggerName] prefix, then all these options</span><br><span class="line"># are parsed to the logger class.</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.auditlogger.default.class=org.apache.sqoop.audit.FileAuditLogger</span><br><span class="line">org.apache.sqoop.auditlogger.default.logger=audit</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Repository configuration</span><br><span class="line"># The Repository subsystem provides the special prefix which</span><br><span class="line"># is &quot;org.apache.sqoop.repository.sysprop&quot;. Any property that</span><br><span class="line"># is specified with this prefix is parsed out and set as a</span><br><span class="line"># system property. For example, if the built in Derby repository</span><br><span class="line"># is being used, the sysprop prefixed properties can be used</span><br><span class="line"># to affect Derby configuration at startup time by setting</span><br><span class="line"># the appropriate system properties.</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># Repository provider</span><br><span class="line">org.apache.sqoop.repository.provider=org.apache.sqoop.repository.JdbcRepositoryProvider</span><br><span class="line"></span><br><span class="line"># Repository upgrade</span><br><span class="line"># If set to true, it will not upgrade the sqoop respository schema, by default it will iniate the upgrade on server start-up</span><br><span class="line">org.apache.sqoop.repository.schema.immutable=false</span><br><span class="line"></span><br><span class="line"># JDBC repository provider configuration</span><br><span class="line">org.apache.sqoop.repository.jdbc.handler=org.apache.sqoop.repository.derby.DerbyRepositoryHandler</span><br><span class="line">org.apache.sqoop.repository.jdbc.transaction.isolation=READ_COMMITTED</span><br><span class="line">org.apache.sqoop.repository.jdbc.maximum.connections=10</span><br><span class="line">org.apache.sqoop.repository.jdbc.url=jdbc:derby:/opt/sqoop2/repository/db;create=true</span><br><span class="line">org.apache.sqoop.repository.jdbc.driver=org.apache.derby.jdbc.EmbeddedDriver</span><br><span class="line">org.apache.sqoop.repository.jdbc.user=sa</span><br><span class="line">org.apache.sqoop.repository.jdbc.password=</span><br><span class="line"></span><br><span class="line"># System properties for embedded Derby configuration</span><br><span class="line">org.apache.sqoop.repository.sysprop.derby.stream.error.file=/opt/sqoop2/logs/derbyrepo.log</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Sqoop Connector configuration</span><br><span class="line"># If set to true will initiate Connectors config upgrade during server startup</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.connector.autoupgrade=false</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Sqoop Driver configuration</span><br><span class="line"># If set to true will initiate the Driver config upgrade during server startup</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.driver.autoupgrade=false</span><br><span class="line"></span><br><span class="line"># Sleeping period for reloading configuration file (once a minute)</span><br><span class="line">org.apache.sqoop.core.configuration.provider.properties.sleep=60000</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Submission engine configuration</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># Submission engine class</span><br><span class="line">org.apache.sqoop.submission.engine=org.apache.sqoop.submission.mapreduce.MapreduceSubmissionEngine</span><br><span class="line"></span><br><span class="line"># Number of milliseconds, submissions created before this limit will be removed, default is one day</span><br><span class="line">#org.apache.sqoop.submission.purge.threshold=</span><br><span class="line"></span><br><span class="line"># Number of milliseconds for purge thread to sleep, by default one day</span><br><span class="line">#org.apache.sqoop.submission.purge.sleep=</span><br><span class="line"></span><br><span class="line"># Number of milliseconds for update thread to sleep, by default 5 minutes</span><br><span class="line">#org.apache.sqoop.submission.update.sleep=</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Configuration for Mapreduce submission engine (applicable if it&#x27;s configured)</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># Hadoop configuration directory</span><br><span class="line">org.apache.sqoop.submission.engine.mapreduce.configuration.directory=/etc/hadoop/conf/</span><br><span class="line"></span><br><span class="line"># Log level for Sqoop Mapper/Reducer</span><br><span class="line">org.apache.sqoop.submission.engine.mapreduce.configuration.loglevel=INFO</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Execution engine configuration</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.execution.engine=org.apache.sqoop.execution.mapreduce.MapreduceExecutionEngine</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Authentication configuration</span><br><span class="line">#</span><br><span class="line">#org.apache.sqoop.security.authentication.type=SIMPLE</span><br><span class="line">#org.apache.sqoop.security.authentication.handler=org.apache.sqoop.security.authentication.SimpleAuthenticationHandler</span><br><span class="line">#org.apache.sqoop.security.authentication.anonymous=true</span><br><span class="line">#org.apache.sqoop.security.authentication.type=KERBEROS</span><br><span class="line">#org.apache.sqoop.security.authentication.handler=org.apache.sqoop.security.authentication.KerberosAuthenticationHandler</span><br><span class="line">#org.apache.sqoop.security.authentication.kerberos.principal=sqoop/_HOST@NOVALOCAL</span><br><span class="line">#org.apache.sqoop.security.authentication.kerberos.keytab=/home/kerberos/sqoop.keytab</span><br><span class="line">#org.apache.sqoop.security.authentication.kerberos.http.principal=HTTP/_HOST@NOVALOCAL</span><br><span class="line">#org.apache.sqoop.security.authentication.kerberos.http.keytab=/home/kerberos/sqoop.keytab</span><br><span class="line">#org.apache.sqoop.security.authentication.enable.doAs=true</span><br><span class="line">#org.apache.sqoop.security.authentication.proxyuser.#USER#.users=*</span><br><span class="line">#org.apache.sqoop.security.authentication.proxyuser.#USER#.groups=*</span><br><span class="line">#org.apache.sqoop.security.authentication.proxyuser.#USER#.hosts=*</span><br><span class="line"></span><br><span class="line"># Default user, default value is &quot;sqoop.anonymous.user&quot;</span><br><span class="line">#org.apache.sqoop.security.authentication.default.user=</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Authorization configuration</span><br><span class="line">#</span><br><span class="line">#org.apache.sqoop.security.authorization.handler=org.apache.sqoop.security.authorization.DefaultAuthorizationHandler</span><br><span class="line">#org.apache.sqoop.security.authorization.access_controller=org.apache.sqoop.security.authorization.DefaultAuthorizationAccessController</span><br><span class="line">#org.apache.sqoop.security.authorization.validator=org.apache.sqoop.security.authorization.DefaultAuthorizationValidator</span><br><span class="line">#org.apache.sqoop.security.authorization.authentication_provider=org.apache.sqoop.security.authorization.DefaultAuthenticationProvider</span><br><span class="line">#org.apache.sqoop.security.authorization.server_name=SqoopServer1</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># SSL/TLS configuration</span><br><span class="line">#</span><br><span class="line">#org.apache.sqoop.security.tls.enabled=false</span><br><span class="line">#org.apache.sqoop.security.tls.protocol=&quot;TLSv1.2&quot;</span><br><span class="line">#org.apache.sqoop.security.tls.keystore=</span><br><span class="line">#org.apache.sqoop.security.tls.keystore_password=</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Repository Encryption</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">#org.apache.sqoop.security.repo_encryption.enabled=true</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.password=</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.password_generator=</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.hmac_algorithm=HmacSHA256</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.cipher_algorithm=AES</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.cipher_key_size=16</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.cipher_spec=AES/CBC/PKCS5Padding</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.initialization_vector_size=16</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.pbkdf2_algorithm=PBKDF2WithHmacSHA1</span><br><span class="line">#org.apache.sqoop.security.repo_encryption.pbkdf2_rounds=4000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># External connectors load path</span><br><span class="line"># &quot;/path/to/external/connectors/&quot;: Add all the connector JARs in the specified folder</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.connector.external.loadpath=</span><br><span class="line"></span><br><span class="line"># Sqoop application classpath</span><br><span class="line"># &quot;:&quot; separated list of jars to be included in sqoop.</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.classpath.extra=</span><br><span class="line"></span><br><span class="line"># Sqoop extra classpath to be included with all jobs</span><br><span class="line"># &quot;:&quot; separated list of jars to be included in map job classpath.</span><br><span class="line">#</span><br><span class="line">org.apache.sqoop.classpath.job=</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Jetty Server configuration</span><br><span class="line">#</span><br><span class="line">#org.apache.sqoop.jetty.thread.pool.worker.max=500</span><br><span class="line">#org.apache.sqoop.jetty.thread.pool.worker.min=5</span><br><span class="line">#org.apache.sqoop.jetty.thread.pool.worker.alive.time=60</span><br><span class="line">#org.apache.sqoop.jetty.port=12000</span><br><span class="line"></span><br><span class="line"># Blacklisted Connectors</span><br><span class="line"># &quot;:&quot; separated list of connector names as specified in their</span><br><span class="line"># sqoopconnector.properties file</span><br><span class="line">org.apache.sqoop.connector.blacklist=</span><br></pre></td></tr></table></figure><p>sqoop_bootstrap.properties<br><code>sqoop.config.provider=org.apache.sqoop.core.PropertiesConfigurationProvider</code><br>sqoop2-env.sh</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"></span><br><span class="line">SQOOP_USER=sqoop2</span><br><span class="line">SQOOP_CONF_DIR=/etc/sqoop2/conf</span><br><span class="line">SQOOP_LOG=/opt/sqoop2/logs</span><br><span class="line">SQOOP_TEMP=/var/tmp/sqoop2</span><br><span class="line">SQOOP_PID_DIR=/var/run/sqoop2</span><br><span class="line">sqoop_pidfile=/var/run/sqoop2/sqoop-sqoop2-jetty-server.pid</span><br><span class="line">export SQOOP_SERVER_EXTRA_LIB=/opt/hive/lib/mysql-connector-java.jar</span><br></pre></td></tr></table></figure><p>hadoop 的 core-site<br>配置 yarn 代理sqoop2 的 proxyuser，否则启动任务后会出现 yarn is not allowed to impersonate sqoop2<br>在集群全部机器的 core-site 增加下面两条记录，重启全部 hdfs 和 yarn 服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.yarn.groups&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.proxyuser.yarn.hosts&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p><code>/opt/sqoop2/bin/sqoop2-server start</code></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>我写的一个简单的 mysql 到 hdfs 某个路径的示例 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><span class="line"># 创建 hdfs 目录</span><br><span class="line">su sqoop2</span><br><span class="line">hdfs dfs -mkdir /bmzout</span><br><span class="line"># 登录 mysql 创建库表和数据，密码找值班获取</span><br><span class="line">mysql -u root -p***********</span><br><span class="line">create database bmz;</span><br><span class="line">use bmz;</span><br><span class="line">create table bmz2 (id int primary key,name text);</span><br><span class="line">insert into bmz2 values(1,&quot;bmz&quot;);</span><br><span class="line"># 退出 mysql client</span><br><span class="line">ctrl+c</span><br><span class="line"></span><br><span class="line"># 进入 sqoop2-shell</span><br><span class="line">sqoop2-shell</span><br><span class="line"># 设置 sqoop server</span><br><span class="line">set server --host `sqoop2-server 所在机器` --port 12000 --webapp sqoop</span><br><span class="line"># 查看sqoop-server 管理的 connector</span><br><span class="line">show connector</span><br><span class="line"># 设置 hdfs link</span><br><span class="line">create link -connector hdfs-connector</span><br><span class="line">Creating link for connector with name hdfs-connector</span><br><span class="line">Please fill following values to create new link object</span><br><span class="line">Name: hdfs</span><br><span class="line"></span><br><span class="line">HDFS cluster</span><br><span class="line"></span><br><span class="line">URI: hdfs://my-cluster</span><br><span class="line">Conf directory: /etc/hadoop/conf</span><br><span class="line">Additional configs::</span><br><span class="line">There are currently 0 values in the map:</span><br><span class="line">entry#</span><br><span class="line">New link was successfully created with validation status OK and name hdfs</span><br><span class="line"># 设置 mysql link</span><br><span class="line">create link -connector generic-jdbc-connector</span><br><span class="line">Creating link for connector with name generic-jdbc-connector</span><br><span class="line">Please fill following values to create new link object</span><br><span class="line">Name: mysql</span><br><span class="line"></span><br><span class="line">Database connection</span><br><span class="line"></span><br><span class="line">Driver class: com.mysql.jdbc.Driver</span><br><span class="line">Connection String: jdbc:mysql://master-e9372c6-3:3306/bmz</span><br><span class="line">Username: root</span><br><span class="line">Password: *************</span><br><span class="line">Fetch Size:</span><br><span class="line">Connection Properties:</span><br><span class="line">There are currently 0 values in the map:</span><br><span class="line">entry#</span><br><span class="line"></span><br><span class="line">SQL Dialect</span><br><span class="line"></span><br><span class="line">Identifier enclose:</span><br><span class="line">New link was successfully created with validation status OK and name mysql</span><br><span class="line"># 设置 job</span><br><span class="line">create job -f &quot;mysql&quot; -t &quot;hdfs&quot;</span><br><span class="line">Creating job for links with from name mysql and to name hdfs</span><br><span class="line">Please fill following values to create new job object</span><br><span class="line">Name: mysql22hdfs</span><br><span class="line"></span><br><span class="line">Database source</span><br><span class="line"></span><br><span class="line">Schema name: bmz</span><br><span class="line">Table name: bmz2</span><br><span class="line">SQL statement:</span><br><span class="line">Column names:</span><br><span class="line">There are currently 0 values in the list:</span><br><span class="line">element#</span><br><span class="line">Partition column: id</span><br><span class="line">Partition column nullable:</span><br><span class="line">Boundary query:</span><br><span class="line"></span><br><span class="line">Incremental read</span><br><span class="line"></span><br><span class="line">Check column:</span><br><span class="line">Last value:</span><br><span class="line"></span><br><span class="line">Target configuration</span><br><span class="line"></span><br><span class="line">Override null value:</span><br><span class="line">Null value:</span><br><span class="line">File format:</span><br><span class="line">  0 : TEXT_FILE</span><br><span class="line">  1 : SEQUENCE_FILE</span><br><span class="line">  2 : PARQUET_FILE</span><br><span class="line">Choose: 0</span><br><span class="line">Compression codec:</span><br><span class="line">  0 : NONE</span><br><span class="line">  1 : DEFAULT</span><br><span class="line">  2 : DEFLATE</span><br><span class="line">  3 : GZIP</span><br><span class="line">  4 : BZIP2</span><br><span class="line">  5 : LZO</span><br><span class="line">  6 : LZ4</span><br><span class="line">  7 : SNAPPY</span><br><span class="line">  8 : CUSTOM</span><br><span class="line">Choose: 0</span><br><span class="line">Custom codec:</span><br><span class="line">Output directory: /tmp/sqoop2test</span><br><span class="line">Append mode:</span><br><span class="line"></span><br><span class="line">Throttling resources</span><br><span class="line"></span><br><span class="line">Extractors:</span><br><span class="line">Loaders:</span><br><span class="line"></span><br><span class="line">Classpath configuration</span><br><span class="line"></span><br><span class="line">Extra mapper jars:</span><br><span class="line">There are currently 0 values in the list:</span><br><span class="line">element#</span><br><span class="line">New job was successfully created with validation status OK  and name mysql22hdfs</span><br><span class="line"># 启动任务</span><br><span class="line">start job -name mysql22hdfs</span><br><span class="line">Submission details</span><br><span class="line">Job Name: mysql22hdfs</span><br><span class="line">Server URL: http://localhost:12000/sqoop/</span><br><span class="line">Created by: sqoop2</span><br><span class="line">Creation date: 2024-02-26 15:41:59 CST</span><br><span class="line">Lastly updated by: sqoop2</span><br><span class="line">External ID: job_1708916992686_0004</span><br><span class="line">http://master-e9372c6-1:8088/proxy/application_1708916992686_0004/</span><br><span class="line">2024-02-26 15:41:59 CST: BOOTING  - Progress is not available</span><br><span class="line"></span><br><span class="line"># 查看状态</span><br><span class="line">status job -n mysql22hdfs</span><br><span class="line">Submission details</span><br><span class="line">Job Name: mysql22hdfs</span><br><span class="line">Server URL: http://localhost:12000/sqoop/</span><br><span class="line">Created by: sqoop2</span><br><span class="line">Creation date: 2024-02-26 15:41:59 CST</span><br><span class="line">Lastly updated by: sqoop2</span><br><span class="line">External ID: job_1708916992686_0004</span><br><span class="line">http://master-e9372c6-1:8088/proxy/application_1708916992686_0004/</span><br><span class="line">2024-02-26 15:42:19 CST: SUCCEEDED</span><br><span class="line">Counters:</span><br><span class="line">org.apache.hadoop.mapreduce.FileSystemCounter</span><br><span class="line">FILE_LARGE_READ_OPS: 0</span><br><span class="line">FILE_WRITE_OPS: 0</span><br><span class="line">HDFS_READ_OPS: 1</span><br><span class="line">HDFS_BYTES_READ: 142</span><br><span class="line">HDFS_LARGE_READ_OPS: 0</span><br><span class="line">FILE_READ_OPS: 0</span><br><span class="line">FILE_BYTES_WRITTEN: 548082</span><br><span class="line">FILE_BYTES_READ: 0</span><br><span class="line">HDFS_WRITE_OPS: 1</span><br><span class="line">HDFS_BYTES_WRITTEN: 8</span><br><span class="line">org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter</span><br><span class="line">BYTES_WRITTEN: 0</span><br><span class="line">org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter</span><br><span class="line">BYTES_READ: 0</span><br><span class="line">org.apache.hadoop.mapreduce.JobCounter</span><br><span class="line">TOTAL_LAUNCHED_MAPS: 1</span><br><span class="line">MB_MILLIS_MAPS: 9693184</span><br><span class="line">VCORES_MILLIS_MAPS: 4733</span><br><span class="line">SLOTS_MILLIS_MAPS: 302912</span><br><span class="line">OTHER_LOCAL_MAPS: 1</span><br><span class="line">MILLIS_MAPS: 4733</span><br><span class="line">org.apache.sqoop.submission.counter.SqoopCounters</span><br><span class="line">ROWS_READ: 1</span><br><span class="line">ROWS_WRITTEN: 1</span><br><span class="line">org.apache.hadoop.mapreduce.TaskCounter</span><br><span class="line">SPILLED_RECORDS: 0</span><br><span class="line">MERGED_MAP_OUTPUTS: 0</span><br><span class="line">VIRTUAL_MEMORY_BYTES: 3633766400</span><br><span class="line">MAP_INPUT_RECORDS: 0</span><br><span class="line">MAP_PHYSICAL_MEMORY_BYTES_MAX: 431300608</span><br><span class="line">SPLIT_RAW_BYTES: 142</span><br><span class="line">FAILED_SHUFFLE: 0</span><br><span class="line">PHYSICAL_MEMORY_BYTES: 431300608</span><br><span class="line">GC_TIME_MILLIS: 127</span><br><span class="line">MAP_VIRTUAL_MEMORY_BYTES_MAX: 3633766400</span><br><span class="line">MAP_OUTPUT_RECORDS: 1</span><br><span class="line">CPU_MILLISECONDS: 3940</span><br><span class="line">COMMITTED_HEAP_BYTES: 257425408</span><br><span class="line">Job executed successfully</span><br><span class="line"></span><br><span class="line">## hdfs 检查是否导入成功</span><br><span class="line">hdfs dfs -ls /tmp/sqoop2test</span><br><span class="line"></span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 sqoop2 hadoop          8 2024-02-26 15:42 /tmp/sqoop2test/2404d32a-8925-4dc9-add9-b09c51980def.txt</span><br><span class="line">## 查看上面文件的内容是否一致</span><br><span class="line">hdfs dfs -cat /tmp/sqoop2test/2404d32a-8925-4dc9-add9-b09c51980def.txt</span><br><span class="line">1,&#x27;bmz&#x27;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apache flume</title>
      <link href="/2025/03/19/apache-flume/"/>
      <url>/2025/03/19/apache-flume/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。<br>可以采集文件，socket数据包、文件、文件夹、kafka等各种形式源数据，又可以将采集到的数据(下沉sink)输出到HDFS、hbase、hive、kafka等众多外部存储系统中</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Flume分布式系统中最核心的角色是agent，flume采集系统就是由一个个agent所连接起来形成<br>每一个agent相当于一个数据传递员，内部有三个组件：</p><ol><li>Source：采集组件，用于跟数据源对接，以获取数据</li><li>Sink：下沉组件，用于往下一级agent传递数据或者往最终存储系统传递数据</li><li>Channel：传输通道组件，用于从source将数据传递到sink</li></ol><p><img src="/2025/03/19/apache-flume/arch.png" alt="架构"></p><p><img src="/2025/03/19/apache-flume/arch-multi.png" alt="agent串联架构"></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="采用版本"><a href="#采用版本" class="headerlink" title="采用版本"></a>采用版本</h3><p>源码地址:<a href="https://github.com/apache/logging-flume,%E6%88%91%E8%BF%99%E9%87%8C%E7%94%A8%E7%9A%84">https://github.com/apache/logging-flume,我这里用的</a> v1.6.0<br>安装目录使用 &#x2F;opt&#x2F;flume, 配置目录软链到 &#x2F;etc&#x2F;flume&#x2F;conf, 日志目录使用 &#x2F;opt&#x2F;flume&#x2F;logs</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/flume/conf</span><br><span class="line">mkdir -p /opt/flume</span><br><span class="line">mkdir -p /opt/flume/logs</span><br><span class="line">cd /opt/flume</span><br><span class="line">## rpm2cpio flume.rpm |cpio -div</span><br><span class="line">mv usr/bdp/1.0.0-1/etc/flume/conf.empty/* /etc/flume/conf/</span><br><span class="line">mv usr/bdp/1.0.0-1/flume/* .</span><br><span class="line">## 配置环境变量</span><br><span class="line">echo &quot;export FLUME_HOME=/opt/flume&quot; &gt;&gt; /etc/profile</span><br><span class="line">echo &quot;export FLUME_CONF_DIR=/etc/flume/conf&quot; &gt;&gt; /etc/profile</span><br><span class="line">## 日志实际使用时最好指定到 /opt/flume</span><br><span class="line">echo &quot;export FLUME_LOG_DIR=/opt/flume/logs&quot; &gt;&gt; /etc/profile</span><br><span class="line">echo &quot;export PATH=\$PATH:\$FLUME_HOME/bin&quot; &gt;&gt; /etc/profile</span><br><span class="line">## 删除 hdp 特定脚本</span><br><span class="line">useradd flume -G hadoop</span><br><span class="line">chown flume:hadoop -R /opt/flume</span><br><span class="line">chown flume:hadoop -R /etc/flume</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>flume-ng 的 flume.conf 文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"># Describe/configure the source</span><br><span class="line">##注意：不能往监控目中重复丢同名文件</span><br><span class="line">a1.sources.r1.type = spooldir</span><br><span class="line">a1.sources.r1.spoolDir = /tmp/bmz</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://my-cluster:8020/flume-task/%y-%m-%d-%H%M/</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = bmzevents-</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 10</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 3</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 20</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 5</span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 1</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line">#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>flume-env.sh<br><code>HADOOP_HOME=$&#123;HADOOP_HOME:-/opt/hadoop&#125;</code></p><h2 id="启动-agent"><a href="#启动-agent" class="headerlink" title="启动 agent"></a>启动 agent</h2><p>这里例子是 后台启动 flume 从机器本地 &#x2F;tmp&#x2F;bmz 下文件到 hdfs 上 &#x2F;flume-task&#x2F;日期&#x2F;bmzevent-前缀<br><code>nohup bin/flume-ng agent -Dflume.root.logger=INFO,console --conf /etc/flume/conf/ -n a1 --conf-file /etc/flume/conf/flume.conf &amp;</code><br>编辑 &#x2F;tmp&#x2F;bmz&#x2F;bmz1 ，写入内容1234<br>查看 hdfs 对应目录(&#x2F;flume-task&#x2F;24-02-21-2000&#x2F;bmzevents-.1708517275552 结果,文件也有内容<br><code>hdfs dfs -cat /flume-task/24-02-21-2000/bmzevents-.1708517275552</code></p>]]></content>
      
      
      
        <tags>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go analyze call chain</title>
      <link href="/2025/03/18/Go-analyze-call-chain/"/>
      <url>/2025/03/18/Go-analyze-call-chain/</url>
      
        <content type="html"><![CDATA[<p>使用 go-callvis 对 go 项目分析调用关系，可以看到每个包下每个函数（以及 receiver 方法）调用了哪些其他包，或者被哪些包调用<br><a href="https://github.com/ondrajz/go-callvis">https://github.com/ondrajz/go-callvis</a></p><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>go &gt; 1.19+<br>安装 graphgiz</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ol><li><p>下载 go-callvis<br>Latest release<br>go install github.com&#x2F;ofabry&#x2F;go-callvis@latest<br>Development version<br>go install github.com&#x2F;ofabry&#x2F;go-callvis@master<br>我在 Linux 开发机里直接下载使用了 latest 版本</p><blockquote><p>PS：如果你要在 MACBOOK m123 系列的芯片的机器上使用，目前来讲是不行的，会 panic。原因见<a href="https://github.com/ondrajz/go-callvis/issues/170">https://github.com/ondrajz/go-callvis/issues/170</a><br>我也尝试过GOOS&#x3D;darwin GOARCH&#x3D;amd64 直接使用源码 make install，同样没法使用，当然现在有一个PR<a href="https://github.com/ondrajz/go-callvis/pull/177%E7%9C%8B%E8%B5%B7%E6%9D%A5%E8%83%BD%E5%9C%A8go1.22%E4%B8%AD%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E5%A6%82%E6%9E%9C%E4%BD%A0%E5%BC%BA%E7%83%88%E9%9C%80%E8%A6%81%E5%88%86%E6%9E%90%EF%BC%8C%E9%82%A3%E4%B9%88%E6%94%B9%E5%8A%A8%E8%BF%99%E9%87%8C%E7%9A%84%E4%BB%A3%E7%A0%81%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91%E8%AF%95%E8%AF%95%E5%90%A7">https://github.com/ondrajz/go-callvis/pull/177看起来能在go1.22中解决这个问题，如果你强烈需要分析，那么改动这里的代码本地编译试试吧</a></p></blockquote></li><li><p>查看版本<br>下载后的二进制将放到 Linux 机器上的 GOPATH&#x2F;bin 目录下<br>$GOPATH&#x2F;bin&#x2F;go-callvis -version</p></li><li><p>分析项目</p></li></ol><ul><li>分析整个项目，那就要从 main.go 开始，以我的项目为例<br>&#x2F;mnt&#x2F;gopath&#x2F;bin&#x2F;go-callvis -algo static -http :8778 $项目 main.go 所在目录</li><li>待分析完毕后，将启动 8778 开启一个 httpserver，点击即可查看 main.go 开始的调用链，但是浏览器打开之后会发现无法缩放，在调用过多的包里基本很难看出所以然</li><li>如果想单独分析某个包，可以使用 -focus 参数<br>&#x2F;mnt&#x2F;gopath&#x2F;bin&#x2F;go-callvis -debug -algo static -format&#x3D;png -file .&#x2F;bmz-somepkg-callvis -focus xxx .&#x2F;internal&#x2F;xxx&#x2F;xxxxx<br>这个命令会分析 .&#x2F;internal&#x2F;xxx&#x2F;xxxxx 这一个包下的调用，同时将结果生成到当前目录的 bmz-somepkg-callvis.png 文件，后续可以拿出这个文件详细查看，但无法像 httpserver 那样点击其他的包进一步查看了</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>apache storm</title>
      <link href="/2025/03/18/apache-storm/"/>
      <url>/2025/03/18/apache-storm/</url>
      
        <content type="html"><![CDATA[<p>旧时代的流式计算框架，独立于 hadoop， 组件上依赖 zk，现在被 flink 完爆<br><img src="/2025/03/18/apache-storm/arch.png" alt="架构"></p><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="nimbus"><a href="#nimbus" class="headerlink" title="nimbus"></a>nimbus</h3><p>通过与Zookeeper的交互，管理Storm集群中的所有组件，包括Supervisor和Worker。</p><h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><p>维护着Storm集群的状态和元数据，包括Topology的元数据、Worker的状态、Supervisor的信息等。</p><h3 id="Supervisor"><a href="#Supervisor" class="headerlink" title="Supervisor"></a>Supervisor</h3><p>负责管理Worker进程，监控和维护Worker的状态和资源使用情况。</p><h3 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h3><p>运行在Supervisor中，处理Tuple并将处理后的数据发送给下游的Bolt或者输出到外部存储系统。<br><img src="/2025/03/18/apache-storm/comp-relation.png" alt="调用关系"></p><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><p><img src="/2025/03/18/apache-storm/flow.png" alt="数据处理流程"></p><h3 id="topology"><a href="#topology" class="headerlink" title="topology"></a>topology</h3><p>表示一个实时数据处理流程，由 spout 和 bolt 组词，可以看做是一个 DAG，一个 topology 可以类比一个 yarn 上的 mr、spark 任务</p><h3 id="spout"><a href="#spout" class="headerlink" title="spout"></a>spout</h3><p>从数据源中读取实时数据流，同时将数据流发送给下游的 bolt 节点；<br>数据源可以是文件，数据库，mq，网络等不同的源</p><h3 id="bolt"><a href="#bolt" class="headerlink" title="bolt"></a>bolt</h3><p>逻辑处理单元，spout 将数据传递给 bolt 并产生新的输出流。<br>可以执行过滤、聚合、连接、与数据库或数据源交互等操作，Bolt 的输出是</p><ul><li>一个或多个下游 bolt</li><li>外部存储系统</li></ul><h3 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h3><p>是一个抽象概念，表示一组有序的数据记录。stream 包含多个字段，每个字段可以是不同的数据类型。stream 是topo 中 spout 和bolt 之间的通信载体，传递数据流和元数据信息</p><h3 id="tuple"><a href="#tuple" class="headerlink" title="tuple"></a>tuple</h3><p>基本数据单元，每个 tuple 都可以看做是 stream 中的一个数据元素，每个 tuple 由多个字段组词，字段可以是不同的数据类型，也是 storm 中数据处理和传递的基本单位</p><h3 id="task"><a href="#task" class="headerlink" title="task"></a>task</h3><p>bolt 或者 spout 在集群中的实例，负责具体的数据处理和传递工作。topology 中每个 Bolt 或者 spout 都会被分配成若干个 task，每个 task 处理一部分的数据流</p><h3 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h3><p>进程，负责启动和运行 task，分布在各个机器上<br><img src="/2025/03/18/apache-storm/flow-example.png" alt="flow 示例"></p><h2 id="工作流程的时序"><a href="#工作流程的时序" class="headerlink" title="工作流程的时序"></a>工作流程的时序</h2><p><img src="/2025/03/18/apache-storm/sequence.png" alt="时序图"></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>编译,产出省略,解压到指定目录后,比如 &#x2F;opt&#x2F;storm 修改权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/storm</span><br><span class="line">## 解压到这个目录</span><br><span class="line">mkdir /etc/storm/conf</span><br><span class="line">ln -s /etc/storm/conf /opt/storm/conf</span><br><span class="line">useradd storm -G hadoop</span><br><span class="line">chown storm:hadoop -R /opt/storm</span><br><span class="line">chown storm:hadoop -R /etc/storm</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>storm.yaml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">########### These MUST be filled in for a storm configuration</span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line"> - &quot;master-3&quot;</span><br><span class="line"> - &quot;master-2&quot;</span><br><span class="line"> - &quot;master-1&quot;</span><br><span class="line"></span><br><span class="line">storm.zookeeper.port: 2181</span><br><span class="line">nimbus.host: master-3</span><br><span class="line">storm.local.dir: &quot;/mnt/storm&quot;</span><br><span class="line">supervisor.slots.ports:</span><br><span class="line"> - 6700</span><br><span class="line"> - 6701</span><br><span class="line"></span><br><span class="line">nimbus.seeds: [&quot;master-3&quot;]</span><br><span class="line"></span><br><span class="line">ui.port: 8070</span><br></pre></td></tr></table></figure><p>storm-env.sh</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">export STORM_CONF_DIR=&quot;/etc/storm/conf&quot;</span><br></pre></td></tr></table></figure><h2 id="启动进程"><a href="#启动进程" class="headerlink" title="启动进程"></a>启动进程</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">su - storm</span><br><span class="line">cd /opt/storm</span><br><span class="line">## nimbus</span><br><span class="line">bin/storm nimbus &amp;</span><br><span class="line">## supervisor</span><br><span class="line">bin/storm supervisor &amp;</span><br><span class="line">## ui</span><br><span class="line">bin/storm ui &amp;</span><br><span class="line"></span><br><span class="line">## 停服只需要执行 bin/storm-stop xxx</span><br><span class="line">## example: bin/storm-stop nimbus</span><br></pre></td></tr></table></figure><p>启动后可以看访问 web server,比如 master-3:8070,可以看到 ui 界面</p><h2 id="启动-wordcount-example"><a href="#启动-wordcount-example" class="headerlink" title="启动 wordcount example"></a>启动 wordcount example</h2><p>我这里用的1.1.2版本,注意 jar 包路径<br>storm jar &#x2F;opt&#x2F;storm&#x2F;examples&#x2F;storm-starter&#x2F;storm-starter-1.1.2.jar org.apache.storm.starter.WordCountTopology wordcount<br>之后再界面可以看到任务已启动<br><img src="/2025/03/18/apache-storm/wordcount.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go project module arch principle</title>
      <link href="/2025/03/17/Go-project-module-arch-principle/"/>
      <url>/2025/03/17/Go-project-module-arch-principle/</url>
      
        <content type="html"><![CDATA[<h2 id="模块拆分"><a href="#模块拆分" class="headerlink" title="模块拆分"></a>模块拆分</h2><p>Go语言的顶层设计特性，使得它在模块划分上与其他编程语言存在显著差异，很多其他语言的 Web 框架都采用 MVC 的架构模式，例如 Rails 和 Spring MVC，Go 语言对模块划分的方法就与 Ruby 和 Java 完全不同。</p><h2 id="按层级拆分"><a href="#按层级拆分" class="headerlink" title="按层级拆分"></a>按层级拆分</h2><p>无论是 Java 还是 Ruby，它们最著名的框架都深受 MVC 架构模式 的影响，我们从 Spring MVC 的名字中就能体会到 MVC 对它的影响，而 Ruby 社区的 Rails 框架也与 MVC 的关系非常紧密，这是一种 Web 框架的最常见架构方式，将服务中的不同组件分成了 Model、View 和 Controller 三层。<br><img src="/2025/03/17/Go-project-module-arch-principle/image.png"><br>这种模块拆分的方式其实就是按照层级进行拆分，Rails 脚手架默认生成的代码会自动将三层不同的源文件分别放置在它们对应的目录下：models、views 和 controllers，我们通过 rails new example 生成一个新的 Rails 项目后可以看到其中的目录结构</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">app</span><br><span class="line">├── controllers</span><br><span class="line">│   ├── application_controller.rb</span><br><span class="line">│   └── concerns</span><br><span class="line">├── models</span><br><span class="line">│   ├── application_record.rb</span><br><span class="line">│   └── concerns</span><br><span class="line">└── views</span><br><span class="line">    └── layouts</span><br></pre></td></tr></table></figure><p>而很多 Spring MVC 的项目中也会出现类似 model、dao、view 的目录，这种按层拆分模块的设计其实有以下的几方面原因：</p><ol><li>MVC 架构模式 — MVC 本身就强调了按层划分职责的设计，所以遵循该模式设计的框架自然有着一脉相承的思路；</li><li>扁平的命名空间 — 无论是 Spring MVC 还是 Rails，同一个项目中命名空间非常扁平，跨文件夹使用其他文件夹中定义的类或者方法不需要引入新的包，使用其他文件定义的类时也不需要增加额外的前缀，多个文件定义的类被『合并』到了同一个命名空间中；</li><li>单体服务的场景 — Spring MVC 和 Rails 刚出现时，SOA 和微服务架构还不像今天这么普遍，绝大多数的场景也不需要通过拆分服务；</li></ol><p>Spring MVC 和 Rails 中出现的 models、views 和 controllers 目录结构，以及它们按层级拆分模块的方式，均是由上述几个原因共同决定的。</p><h2 id="按职责拆分"><a href="#按职责拆分" class="headerlink" title="按职责拆分"></a>按职责拆分</h2><p>Go 语言在拆分模块时就使用了完全不同的思路，虽然 MVC 架构模式是在我们写 Web 服务时无法避开的，但是相比于横向地切分不同的层级，Go 语言的项目往往都按照职责对模块进行拆分<br><img src="/2025/03/17/Go-project-module-arch-principle/image2.png"><br>对于一个比较常见的博客系统，在 Go 语言项目中，通常会基于不同职责纵向拆分为 post、user、comment 三个独立模块，每一个模块都对外提供相应的功能，在post模块中，我们定义了相关的模型和视图，以及一个用于处理API请求的控制器（或称为服务）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pkg</span><br><span class="line">├── comment</span><br><span class="line">├── post</span><br><span class="line">│   ├── handler.go</span><br><span class="line">│   └── post.go</span><br><span class="line">└── user</span><br></pre></td></tr></table></figure><ol><li>Go语言的命名空间与包管理</li></ol><ul><li>Go 语言项目中的每一个文件目录都代表着一个独立的命名空间，也就是一个单独的包。</li><li>当我们想要引用其他文件夹的目录时，首先需要使用 import 关键字引入相应的文件目录。</li><li>再通过 pkg.xxx 的形式引用其他目录定义的结构体、函数或者常量。</li></ul><ol start="2"><li>层级划分与冗余问题</li></ol><ul><li>如果我们在 Go 语言中使用 model、view 和 controller 来划分层级，你会在其他的模块中看到非常多的 model.Post、model.Comment 和 view.PostView。</li><li>因为 go 开发团队要求把 package 名称写的有实际业务意义，导致这种划分层级方式让引用代码完全违背这个规则。</li></ul><ol start="3"><li>包管理与引用循环问题</li></ol><ul><li>并且如果对项目依赖包的管理不够谨慎时，很容易发生引用循环。</li><li>出现这些问题的最根本原因其实也非常简单。</li></ul><ul><li>Go 语言对同一个项目中不同目录的命名空间做了隔离，整个项目中定义的类和方法并不是在同一个命名空间下的，这也就需要工程师自己维护不同包之间的依赖关系；</li><li>当单体服务遇到瓶颈时，采用职责垂直拆分的方式可以非常方便地对微服务进行拆分，我们可以直接将一个负责独立功能的 package 拆出去，对这部分性能热点单独进行扩容；</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>项目的模块拆分，无论是按照层级还是职责进行，都没有绝对的优劣之分，在项目和代码的组织方式上，最终由语言和框架层面的设计决定我们应采取的策略。</li><li>在框架中，Java和Ruby等语言常采用水平拆分的方式来明确不同层级的职责划分，而 Go 语言项目的最佳实践就是按照职责对模块进行垂直拆分，将代码按照功能的方式分到多个 package 中。</li><li>这并不是说 Go 语言中不存在模块的水平拆分，Java 引用的最小粒度是 class，而 go 引用的最小粒度是 package，我们应该遵循顶层的设计使用这种方式构建高内聚的模块。</li><li>我的经验是配合 DDD 来编写项目的目录, 后续可以继续探究一下最佳实践.划分领域不只是微服务的专场，在Go项目内使用这个思想，会让代码超级可读，可维护性变强</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go generate existed repo uml graph</title>
      <link href="/2025/03/14/Go-generate-existed-repo-uml-graph/"/>
      <url>/2025/03/14/Go-generate-existed-repo-uml-graph/</url>
      
        <content type="html"><![CDATA[<h2 id="前提环境"><a href="#前提环境" class="headerlink" title="前提环境"></a>前提环境</h2><p>java 1.8+<br>go 1.17+<br>graphviz</p><h2 id="下载-puml-文件转换成图片工具"><a href="#下载-puml-文件转换成图片工具" class="headerlink" title="下载 puml 文件转换成图片工具"></a>下载 puml 文件转换成图片工具</h2><p>wget <a href="https://github.com/plantuml/plantuml/releases/download/v1.2022.8/plantuml-1.2022.8.jar">https://github.com/plantuml/plantuml/releases/download/v1.2022.8/plantuml-1.2022.8.jar</a></p><h2 id="工具下载"><a href="#工具下载" class="headerlink" title="工具下载"></a>工具下载</h2><p>go get github.com&#x2F;jfeliu007&#x2F;goplantuml&#x2F;parser<br>go install github.com&#x2F;jfeliu007&#x2F;goplantuml&#x2F;cmd&#x2F;goplantuml@latest</p><h2 id="工具使用说明"><a href="#工具使用说明" class="headerlink" title="工具使用说明"></a>工具使用说明</h2><ul><li><p>生成 puml 文件<br>goplantuml .&#x2F; &gt; .&#x2F;classdiag.puml</p></li><li><p>转图片<br>java -jar .&#x2F;plantuml-1.2022.8.jar &#x2F;mnt&#x2F;opensource&#x2F;terraform&#x2F;internal&#x2F;dag&#x2F;classdiag.puml<br>会在&#x2F;mnt&#x2F;opensource&#x2F;terraform&#x2F;internal&#x2F;dag&#x2F; 增加一个 classdiag.png</p></li><li><p>转 svg 图片<br>java -jar .&#x2F;plantuml-1.2022.8.jar &#x2F;mnt&#x2F;opensource&#x2F;terraform&#x2F;internal&#x2F;dag&#x2F;classdiag.puml -tsvg</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go mutex and rwmutex</title>
      <link href="/2025/03/13/Go-mutex-and-rwmutex/"/>
      <url>/2025/03/13/Go-mutex-and-rwmutex/</url>
      
        <content type="html"><![CDATA[<h2 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h2><p>就普通的锁</p><h2 id="如何保持公平"><a href="#如何保持公平" class="headerlink" title="如何保持公平"></a>如何保持公平</h2><p>引用 mutex 的注释来解释</p><blockquote><p>互斥锁有两种状态：正常状态和饥饿状态。<br>在正常状态下，所有等待锁的 goroutine 按照FIFO顺序等待。唤醒的 goroutine 不会直接拥有锁，而是会和新请求锁的 goroutine 竞争锁的拥有。新请求锁的 goroutine 具有优势：它正在 CPU 上执行，而且可能有好几个，所以刚刚唤醒的 goroutine 有很大可能在锁竞争中失败。在这种情况下，这个被唤醒的 goroutine 会加入到等待队列的前面。 如果一个等待的 goroutine 超过 1ms 没有获取锁，那么它将会把锁转变为饥饿模式。<br>在饥饿模式下，锁的所有权将从 unlock 的 goroutine 直接交给交给等待队列中的第一个。新来的 goroutine 将不会尝试去获得锁，即使锁看起来是 unlock 状态, 也不会去尝试自旋操作，而是放在等待队列的尾部。<br>如果一个等待的 goroutine 获取了锁，并且满足一以下其中的任何一个条件：(1)它是队列中的最后一个；(2)它等待的时候小于1ms。它会将锁的状态转换为正常状态。<br>正常状态有很好的性能表现，饥饿模式也是非常重要的，因为它能阻止尾部延迟的现象。</p></blockquote><h2 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h2><p>简单来讲就是多读单写的锁</p><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>读锁之间不互斥，没有写锁的情况下，读锁是无阻塞的，多个协程可以同时获得读锁。<br>写锁之间是互斥的，存在写锁，其他写锁阻塞。<br>写锁与读锁是互斥的，如果存在读锁，写锁阻塞，如果存在写锁，读锁阻塞。</p><h2 id="性能差别"><a href="#性能差别" class="headerlink" title="性能差别"></a>性能差别</h2><p>在每个 goroutine 获取锁后执行 1ms 的事情后释放，这种CASE下，性能如下：</p><ul><li>读写比为 9:1 时，读写锁的性能约为互斥锁的 8 倍</li><li>读写比为 1:9 时，读写锁性能相当</li><li>读写比为 5:5 时，读写锁的性能约为互斥锁的 2 倍<br>实际上假如做的事情越小，那么差距也会越小</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>goroutine 获取了 mutex 之后,其他 goroutine 必须等待,除非持有的协程释放了 Mutex.<br>RWMutex 在读锁占用时会阻止写,但不会阻止读.<br>写锁占用时会组织任何其他读写进来.<br>读多写少的情况用 RWMutex<br>读操作用 rwMutex.RLOCK()<br>写操作用 RLOCK()</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go channel</title>
      <link href="/2025/03/13/Go-channel/"/>
      <url>/2025/03/13/Go-channel/</url>
      
        <content type="html"><![CDATA[<h2 id="底层实现"><a href="#底层实现" class="headerlink" title="底层实现"></a>底层实现</h2><p>hchan struct 记录了 chan 的底层结构,里面每个成员含义如下<br><img src="/2025/03/13/Go-channel/image.png"></p><h2 id="本身特性"><a href="#本身特性" class="headerlink" title="本身特性"></a>本身特性</h2><p>针对根据 channel 是否为空和是否关闭，可以分成以下三类来讨论：<br>空 channel (nil channel)<br>非空已关闭 channel<br>非空未关闭 channel</p><h3 id="close"><a href="#close" class="headerlink" title="close"></a>close</h3><p>nil channel: panic<br>已经关闭 channel: panic<br>没关闭的 chennel: 成功</p><h3 id="写"><a href="#写" class="headerlink" title="写"></a>写</h3><p>nil channel: 永久阻塞<br>已经关闭 chennel: panic<br>没关闭的 chennel: 正常写入或阻塞</p><h3 id="读"><a href="#读" class="headerlink" title="读"></a>读</h3><p>nil channel: 永久阻塞<br>已经关闭 chennel: 永不阻塞,但没数据会读到0值<br>非空未关闭:正常读取或阻塞<br>要理解这几种现象，就要看下 channel 的内部结构了，可以认为 channel 内部有三个 FIFO 队列：<br>接收数据的 goroutine 队列，是一个无限长的链表，这个队列里的 goroutine 都处于阻塞状态，等待数据从 channel 写入<br>发送数据的 goroutine 队列，也是一个无限长的链表，这个队列里的 goroutine 都处于阻塞状态，等待数据向 channel 写入。每个 goroutine 尝试发送的值也和 goroutine 一起存在这个队列里<br>值 buffer 队列，是一个环形队列（ringbuffer），它的大小跟 channel 的容量相同。存在这个 buffer 队列里的值跟 channel 元素的类型相同。如果当前 buffer 队列里储存的值的数量达到了 channel 的容量，这个 channel 就「满了」，对于 unbuffered channel 而言，它总是既在「空」状态，又在「满」状态。</p><h2 id="Close-时机"><a href="#Close-时机" class="headerlink" title="Close 时机"></a>Close 时机</h2><p>无论什么场景 close(chan) 这个关键的操作都是在写入完毕后执行。<br>任何场景都可以归纳为下面几类，找到自己业务需要的场景：</p><ol><li>一写一读<br>最简单的场景，close操作在写完的地方调用即可</li><li>一写多读<br>同上，最简单场景</li><li>多写一读</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">recursiveErrStr := make([]string, 0)</span><br><span class="line">// 递归</span><br><span class="line">if dirs != nil &amp;&amp; len(dirs) &gt; 0 &#123;</span><br><span class="line">    var childWg sync.WaitGroup</span><br><span class="line">    recursiveDone := make(chan error, len(dirs))</span><br><span class="line">   /**</span><br><span class="line">   defer 执行顺序是在 return 之后，但是返回给调用者之前，也就是说这里 panic 的原因是：</span><br><span class="line">   wg.Done 先调用了，导致 childWg.Wait() 通过，在 return 发送到 chan 之前，goroutine 启动者已经先执行了 close(chan)</span><br><span class="line">    **/</span><br><span class="line">    for _, dir := range dirs &#123;</span><br><span class="line">        childWg.Add(1)</span><br><span class="line">        go func(加密变量) &#123;</span><br><span class="line">            defer func() &#123;</span><br><span class="line">                childWg.Done()</span><br><span class="line">            &#125;()</span><br><span class="line">            recursiveDone &lt;- b.recursiveDo(加密变量.Next)</span><br><span class="line">    </span><br><span class="line">        &#125;(dir)</span><br><span class="line">    &#125;</span><br><span class="line">    childWg.Wait()</span><br><span class="line">    close(recursiveDone)</span><br><span class="line">    for v := range recursiveDone &#123;</span><br><span class="line">        if v != nil &#123;</span><br><span class="line">            recursiveErrStr = append(recursiveErrStr, v.Error())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是一个样例,关键的代码就是遍历 dirs 时，在写入完之后执行 wg.Done()。<br>在这一版实现之前，会将 wg 作为传参传入函数，在函数最上调用 defer wg.Done，这样看起来似乎没问题，实际上由于 defer 的执行顺序是在 return 之后，返回给接受者之前进行。导致上面18行在写入 channel 之前就执行了 wg.Done,这样就会导致最后一个 goroutine 先执行了 wg.Done ，后返回到 recursiveDone ，但是返回之前主 routine 已经执行了 close(chan)，导致 panic: send msg to close chan。<br>4. 多写多读<br>   最复杂的场景。我脑海里的第一个设计是设定一个 watch goroutine 去监听所有写 routine，这时就变成了多写一读的场景，此时 watch 利用 wg.Wait 来保证所有写 goroutine 完成后 close(真正的写 channel)，进而达到控制 close 时机的目标。<br>   同时读 channel 的 goroutine 在读取时使用 v, ok :&#x3D; &lt;- chan 的方式，利用 Ok 去判断防止 close 后读出一堆零值的情况</p><h2 id="正确理解-nil-channel-和使用方法"><a href="#正确理解-nil-channel-和使用方法" class="headerlink" title="正确理解 nil channel 和使用方法"></a>正确理解 nil channel 和使用方法</h2><p>很多小伙伴看到上面的结论,”对 nil channel 无论读写都会永久阻塞”，那么 go 的 dev team 为什么这么设计，以及怎么用呢?<br>答案可看 <a href="https://cloud.tencent.com/developer/article/2211920">https://cloud.tencent.com/developer/article/2211920</a><br>上面的回答中，最后一个方案展示了 nil chan 的使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">func merge(ch1, ch2 &lt;-chan int) &lt;-chan int &#123;</span><br><span class="line">    ch := make(chan int, 1)</span><br><span class="line"> </span><br><span class="line">    go func() &#123;</span><br><span class="line">     for ch1 != nil || ch2 != nil &#123; </span><br><span class="line">                select &#123;</span><br><span class="line">                case v, open := &lt;-ch1:</span><br><span class="line">                    if !open &#123;</span><br><span class="line">                        ch1 = nil </span><br><span class="line">                    &#125;else &#123;</span><br><span class="line">                        ch &lt;- v</span><br><span class="line">                    &#125;</span><br><span class="line">     </span><br><span class="line">                case v, open := &lt;-ch2:</span><br><span class="line">                    if !open &#123;</span><br><span class="line">                        ch2 = nil</span><br><span class="line">             &#125;else &#123;</span><br><span class="line">                        ch &lt;- v</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">     &#125;</span><br><span class="line">         </span><br><span class="line">    close(ch)</span><br><span class="line">    &#125;()</span><br><span class="line"> </span><br><span class="line">    return ch</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是会出现一个问题，就是假如 ch1 close 了，但是里面还有数据没读出来，此时接受到 ch1 时立马就将 ch1 转化为 nil 了，会造成丢数的情况，正确的做法应该是 判断!open 后，for range 读取一下 ch1 合并到 ch，然后在将 ch1 &#x3D; nil，for range 只会读取存在的数据，不会误判空值。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go context</title>
      <link href="/2025/03/12/Go-context/"/>
      <url>/2025/03/12/Go-context/</url>
      
        <content type="html"><![CDATA[<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>一个 goroutine 启动后，我们没办法控制他，只能等他自己结束。<br>通过轮询一个全局变量的方式可以检测这个 goroutine 的状态，一般这个全局变量我们用一个 chan 来表示。<br>笨蛋方法：chan + select</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">stop := make(chan bool)</span><br><span class="line"></span><br><span class="line">go func() &#123;</span><br><span class="line">for &#123;</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-stop:    // 收到了停滞信号</span><br><span class="line">fmt.Println(&quot;监控退出，停止了...&quot;)</span><br><span class="line">return</span><br><span class="line">default:</span><br><span class="line">fmt.Println(&quot;goroutine监控中...&quot;)</span><br><span class="line">time.Sleep(2 * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">time.Sleep(10 * time.Second)</span><br><span class="line">fmt.Println(&quot;可以了，通知监控停止&quot;)</span><br><span class="line">stop&lt;- true</span><br><span class="line"></span><br><span class="line">//为了检测监控过是否停止，如果没有监控输出，就表示停止了</span><br><span class="line">time.Sleep(5 * time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>额外小知识： chan 的接收是分为阻塞和非阻塞的，这里 select 中 case 是非阻塞的。非阻塞接受通道数据 CPU 消耗较高，但可以获取是否 chan 中有数据的状态。<br>当 case 上读取一个 chan 时，如果这个 chan &#x3D;&#x3D; nil，那么 case 将会永远阻塞！<br>这个好处是非常简单，谁都能理解。但缺点很严重，就是当 goroutine 比较多的时候，同时 goroutine 还会再启动 goroutine，这里就需要定义超级多的 chan 。</p></blockquote><h2 id="正常方法：Context-with-cancel"><a href="#正常方法：Context-with-cancel" class="headerlink" title="正常方法：Context with cancel"></a>正常方法：Context with cancel</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line">go watch(ctx,&quot;【监控1】&quot;)</span><br><span class="line">go watch(ctx,&quot;【监控2】&quot;)</span><br><span class="line">go watch(ctx,&quot;【监控3】&quot;)</span><br><span class="line"></span><br><span class="line">time.Sleep(10 * time.Second)</span><br><span class="line">fmt.Println(&quot;可以了，通知监控停止&quot;)</span><br><span class="line">cancel()</span><br><span class="line">//为了检测监控过是否停止，如果没有监控输出，就表示停止了</span><br><span class="line">time.Sleep(5 * time.Second)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func watch(ctx context.Context, name string) &#123;</span><br><span class="line">for &#123;</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-ctx.Done():</span><br><span class="line">fmt.Println(name,&quot;监控退出，停止了...&quot;)</span><br><span class="line">return</span><br><span class="line">default:</span><br><span class="line">fmt.Println(name,&quot;goroutine监控中...&quot;)</span><br><span class="line">time.Sleep(2 * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个例子用一个 ctx 控制了三个 goroutine 的启停。</p><h2 id="Context-接口"><a href="#Context-接口" class="headerlink" title="Context 接口"></a>Context 接口</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">type Context interface &#123;</span><br><span class="line">Deadline() (deadline time.Time, ok bool)</span><br><span class="line"></span><br><span class="line">Done() &lt;-chan struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">Err() error</span><br><span class="line"></span><br><span class="line">Value(key interface&#123;&#125;) interface&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>deadline 获取截止时间，第一个返回是截止时间，到了这个时间 context 就会自己 cancel；第二个 ok 代表是否设置了截止时间，如果 false，当需要取消的时候需要显示调用 cancel。<br>done 返回一个只读 chan，在 goroutine 中如果这个返回的 chan 可以读取了，则证明 parent context 已经发起了 cancel，我们通过 done 方法接收信号后就应该清理自己 goroutine 的东西并退出了。<br>Err 返回取消的原因<br>Value 是一个 ctx 上绑定的一些值，kv 存储，这个值一般是线程安全的。</p><h2 id="两个官方类型"><a href="#两个官方类型" class="headerlink" title="两个官方类型"></a>两个官方类型</h2><p>bkg 和 todo 本质上都是 emptyCtx 结构体类型：不可取消，没设置截止时间，没携带任何值的 context。</p><h3 id="background"><a href="#background" class="headerlink" title="background"></a>background</h3><p>主要用于 main 函数、初始化以及测试代码</p><h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><p>当你不确定用什么 context 的时候用这个</p><h2 id="衍生"><a href="#衍生" class="headerlink" title="衍生"></a>衍生</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">func WithCancel(parent Context) (ctx Context, cancel CancelFunc)</span><br><span class="line">func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)</span><br><span class="line">func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)</span><br><span class="line">func WithValue(parent Context, key, val interface&#123;&#125;) Context</span><br></pre></td></tr></table></figure><p>利用这四个方法，将获取 parent ctx 的子 ctx。逐渐可以创建一个 CTX 树，树的每个节点都有任意多个子节点，层级有任意多个，每个父节点都可以控制自己下面所有的子节点。</p><h2 id="总结使用原则"><a href="#总结使用原则" class="headerlink" title="总结使用原则"></a>总结使用原则</h2><ol><li>不要把 Context 放在结构体中，要以参数的方式传递。</li><li>以 Context 作为参数的函数方法，应该把 Context 作为第一个参数，放在第一位。</li><li>给一个函数方法传递 Context 的时候，不要传递 nil，如果不知道传递什么，就使用 context.TODO。</li><li>Context 的 Value 应该传递不可变的数据，而且不要什么数据都使用这个传递，尽可能传递有指示意义的值而不是被操作的值（获取值的地方会根据这个值来决定业务逻辑，而不是业务逻辑会决定这个值是什么）</li><li>Context 是线程安全的，可以放心地在多个 goroutine 中传递。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Goroutine</title>
      <link href="/2025/03/11/Goroutine/"/>
      <url>/2025/03/11/Goroutine/</url>
      
        <content type="html"><![CDATA[<p>goroutine 是 go runtime 管理用户层轻量级线程，比 OS 上的线程资源占用和使用代价都小的多。</p><h2 id="什么是Goroutine-调度器"><a href="#什么是Goroutine-调度器" class="headerlink" title="什么是Goroutine 调度器"></a>什么是Goroutine 调度器</h2><p>将多个 goroutine 按照一定算法放到 CPU 上执行的程序。一个 Go 程序对于操作系统来说只是一个用户层程序，操作系统眼里只有线程，goroutine 调度全要靠 Go 自己完成</p><h2 id="演变"><a href="#演变" class="headerlink" title="演变"></a>演变</h2><ol><li>G-M 模型<br>Go1.0发布的调度器，比较简单。每个 goroutine 对应运行时的 G（goroutine），实际的操作系统线程被抽象成 M（machine）。<br>这个模型对于高吞吐和并行计算的服务伸缩性不够好，缺点有以下几个：<br>单一全局互斥锁；<br>goroutine 传递问题：经常在 M 直接传递可运行的 goroutine 会导致调度延迟增大，有额外性能损耗；<br>每个 M 都要做缓存，内存占用高，数据局部性差；<br>syscall 而形成的频繁的工作线程阻塞和解除阻塞会带来额外的性能损耗</li><li>G-P-M 模型<br>dmitry Vyukov 在 GO 1.1版本实现了 GPM 模型和 work stealing 算法，这个模型沿用至今。<br>计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决<br>P 是逻辑处理器，每个 G 想要运行，首先被分配进入一个 P 的本地运行队列。 G 认为 P 就是运行他的 CPU。但从 goroutine 调度器角度来说，真正的 CPU 是 M，将 P 和 M 绑定才能让 P 中的 G 运行起来。现在 P 和 M 的关系就像 linux 的用户线程和内核线程一样（N:M 多对多）<br>P 的数量在开发者眼里就是 GOMAXPROCS 的数量</li><li>抢占式调度<br>GPM 还有一个问题，就是没有抢占。<br>GO1.2中 Dmitry 又提出了 Go Preemptive Scheduler Design，实现了抢占调度。</li><li>NUMA<br>Go 1.2之后，Go 的重点放在了 GC 低延迟优化上，调度器也就维持现状了。2014.9，Dmitry 又提出了 NUMA - aware scheduler for Go 作为调度器未来的演进方向，但没有被列入开发计划。</li><li>其他优化<br>Go 运行时已经有了 netpoller，这使得 G 发起网络 IO 也不会导致 M 被阻塞（只阻塞 G），因此不会导致大量线程（M）被创建。<br>而对文件 IO却没法做到这样。M 会进入挂起状态等待文件 IO 返回后唤醒，此时 P 会与挂起的 M 分离，再选一个空闲的 M，如果此时没有空闲的 M，则会新建一个 M，这就是文件 IO 会导致大量线程被创建的原因。<br>GO 1.9 有一个优化，针对文件 IO 的 Poller，可以做到类似 netpoller 的功能。在 G 操作一些支持监听的 fd 时，仅仅阻塞 G，但是对于常规的文件（不支持监听）无效，还是会用空闲 M 或新建 M。</li></ol><h2 id="深入理解"><a href="#深入理解" class="headerlink" title="深入理解"></a>深入理解</h2><h3 id="G"><a href="#G" class="headerlink" title="G"></a>G</h3><p>goroutine，存储了 goroutine 的执行栈信息、状态以及任务函数，除此之外，G对象是可重用的</p><h3 id="P"><a href="#P" class="headerlink" title="P"></a>P</h3><p>逻辑 processor，P 数量决定了系统内最大并行 G 的数量（前提：系统 CPU 核数 &gt;&#x3D;P 数量）P 中存放了 G 的队列、链表、缓存和状态</p><h3 id="M"><a href="#M" class="headerlink" title="M"></a>M</h3><p>真正的执行资源，在绑定了 P 之后会进入调度循环（从各种队列、P 的本地队列中获取 G，切换到 G 的执行栈上执行 G 函数，调用 goexit 做清理工作并回到 M，如此反复）。M 并不保存 G 状态，只无脑执行。</p><h3 id="抢占式调度"><a href="#抢占式调度" class="headerlink" title="抢占式调度"></a>抢占式调度</h3><p>简单来说就是 M 如何让 G 停下来并调度其他可运行的 G。<br>在 Go 程序启动的时候，会启动一个名为 sysmon 的 M，这个 M 的特殊之处在于无需绑定 P 就能运行（以 g0 的形式）<br>sysmon 每间隔20us-10ms 启动一次：</p><ol><li>释放闲置超过5min 的 span 物理内存</li><li>如果超过 2min 没有垃圾回收，强制执行</li><li>将长时间未处理的 netpoll 结果添加到任务队列</li><li>向长时间运行的 G 任务发出抢占调度</li><li>回收因 syscall 长时间阻塞的 P<br>sysmon 向长时间运行 G 任务发出抢占调度（通过 retake 函数）：如果一个 G 任务运行超过10ms，sysmon 就认为这个任务运行了太久，从而发起抢占。一旦 G 的抢占标识设置为 true，这个 G 下一次调用函数或方法时，runtime 就能将 G 抢占并移出运行状态，放入 P 的本地运行队列里（如果 P 的本地运行队列已满，就将放到全局运行队列中），等待下一次被调度。</li></ol><h3 id="channel-阻塞或者网络-I-O-时的调度"><a href="#channel-阻塞或者网络-I-O-时的调度" class="headerlink" title="channel 阻塞或者网络 I&#x2F;O 时的调度"></a>channel 阻塞或者网络 I&#x2F;O 时的调度</h3><p>如果 G 被阻塞在某个 channel 操作或者网络 I&#x2F;O 操作上，那么 G 会被放置到某个等待队列中，而 M 会尝试运行 P 的下一个可运行的 G。如果此时 P 没有可运行的 G 供 M 运行，M 将解绑 P 并进入挂起状态。当 I&#x2F;O 或者 channel 操作完成后，等待队列中的 G 会被唤醒，标记为 runnable，并放入某个 P 的队列中，绑定一个 M 执行。</p><h3 id="系统调用阻塞情况下的调度"><a href="#系统调用阻塞情况下的调度" class="headerlink" title="系统调用阻塞情况下的调度"></a>系统调用阻塞情况下的调度</h3><p>如果 G 在某个系统调用阻塞了，不仅 G 会阻塞，执行这个 G 的 M 也会解绑 P（实际上是 P 被 sysmon 回收了），与 G 一同进入阻塞状态。<br>此时如果有空闲的 M，则 P 会绑定到新的 M 并继续执行其他 G；<br>没有空闲的 M，但仍有其他 G 需要运行，会创建一个新的 M。<br>当系统调用返回了，阻塞在这个上的 G 会尝试获取一个可用的 P，如果获取到了，则之前运行这个 G 的 M 将绑定这个 P 继续运行 G；如果没获取到，G 和 M 之间的关联会被解除，G 会被标记成 runnable 并放到全局运行队列等待调度器调度。</p><h2 id="调度器状态查看方法"><a href="#调度器状态查看方法" class="headerlink" title="调度器状态查看方法"></a>调度器状态查看方法</h2><p>使用环境变量 GODEBUG</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GODEBUG=schedtrace=1000 godoc -http=:6000</span><br><span class="line">// schedtrace=1000 含义：每 1000ms 打印输出一次 goroutine 调度状态，godoc 是一个 go 的 web 服务器，用于展示 go 库的，等于启动了一个 go 进程，</span><br><span class="line">//结果</span><br><span class="line">SCHED 0ms: gomaxprocs=8 idleprocs=5 threads=6 spinningthreads=1 idlethreads=0 runqueue=0 [1 0 0 0 0 0 0 0]</span><br><span class="line">using GOPATH mode</span><br><span class="line">SCHED 1005ms: gomaxprocs=8 idleprocs=8 threads=22 spinningthreads=0 idlethreads=18 runqueue=0 [0 0 0 0 0 0 0 0]</span><br><span class="line">SCHED 2011ms: gomaxprocs=8 idleprocs=8 threads=22 spinningthreads=0 idlethreads=18 runqueue=0 [0 0 0 0 0 0 0 0]</span><br><span class="line">SCHED 3011ms: gomaxprocs=8 idleprocs=8 threads=22 spinningthreads=0 idlethreads=18 runqueue=0 [0 0 0 0 0 0 0 0]</span><br><span class="line">SCHED 4014ms: gomaxprocs=8 idleprocs=6 threads=22 spinningthreads=1 idlethreads=17 runqueue=1 [0 0 0 0 0 0 0 0]</span><br><span class="line">SCHED 5020ms: gomaxprocs=8 idleprocs=6 threads=22 spinningthreads=1 idlethreads=17 runqueue=0 [0 0 0 0 0 0 0 0]</span><br><span class="line">SCHED 6022ms: gomaxprocs=8 idleprocs=8 threads=22 spinningthreads=0 idlethreads=18 runqueue=0 [0 0 0 0 0 0 0 0]</span><br><span class="line">SCHED 7032ms: gomaxprocs=8 idleprocs=8 threads=22 spinningthreads=0 idlethreads=18 runqueue=0 [0 0 0 0 0 0 0 0]</span><br></pre></td></tr></table></figure><p>结果解析</p><ol><li>SCHED<br>调试信息输出标志，代表本行是 goroutine 调度器相关输出</li><li>1005ms<br>程序启动到输出这行日志经过的时间</li><li>gomaxprocs<br>P 数量</li><li>idleprocs<br>空闲的 P 数量，当前执行的 P 数量&#x3D;gomaxprocs-idleprocs</li><li>threads<br>OS 线程数，既包括调度器使用的 M 数量，也包括运行时自用的线程（sysmon等）</li><li>spinningthreads<br>自旋状态的 OS 数量</li><li>idlethread<br>空闲的操作系统线程数量</li><li>runqueue<br>全局运行队列中 G 的数量</li><li>[1 0 0 0 0 0 0 0]<br>8 个 P 各自本地运行队列中 G 数量<br>除此之外，还可以输出每个 goroutine、M、P 的详细调度信息：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GODEBUG=schedtrace=1000,scheddetail=1 godoc -http=:6060</span><br><span class="line">// 结果</span><br><span class="line">SCHED 0ms: gomaxprocs=8 idleprocs=7 threads=3 spinningthreads=0 idlethreads=0 runqueue=0 gcwaiting=0 nmidlelocked=0 stopwait=0 sysmonwait=0</span><br><span class="line">  P0: status=1 schedtick=0 syscalltick=0 m=0 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P1: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P2: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P3: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P4: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P5: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P6: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br><span class="line">  P7: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0</span><br></pre></td></tr></table></figure><blockquote><p>PS：Dmitry Vyukov 大神有一个文章叫 Debugging Performance Issues in Go Programs，是每个 gopher 必读文章。</p></blockquote><h2 id="调度实例简要分析"><a href="#调度实例简要分析" class="headerlink" title="调度实例简要分析"></a>调度实例简要分析</h2><h3 id="为什么存在死循环的情况下，多个-goroutine-依旧会被调度并轮流执行"><a href="#为什么存在死循环的情况下，多个-goroutine-依旧会被调度并轮流执行" class="headerlink" title="为什么存在死循环的情况下，多个 goroutine 依旧会被调度并轮流执行"></a>为什么存在死循环的情况下，多个 goroutine 依旧会被调度并轮流执行</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">func deadloop()&#123;</span><br><span class="line">    for&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main()&#123;</span><br><span class="line">    go deadloop()</span><br><span class="line">    for &#123;</span><br><span class="line">        time.Sleep(time.Second*1)</span><br><span class="line">        fmt.Println(&quot;giao&quot;)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">//结果</span><br><span class="line">giao</span><br><span class="line">giao</span><br><span class="line">giao</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>尽管运行了死循环的 deadloop goroutine，main goroutine 也依旧得到了调度。根本原因在于机器是多核多线程的（硬件线程，而不是 OS 线程）。Go 从1.5开始将 P 的默认数量从1改到 CPU 核数（实际上还乘了每个核上的硬件线程数量）。这样上述例子在启动时创建了不止一个 P。<br>假设 dp goroutine 被调度到 P1上，P1在 M1上运行（M1在 OS 线程A 上）；而 main goroutine 被调度到 P2，P2在 M2上运行（M2对应另一个 OS 线程 B）。而线程在 OS 层面被调度到物理 CPU 核上运行。有多个 CPU 核时，即使 dp 占满一个核，我们还可以在另一个 CPU 核上运行 P2上的 main goroutine。</p><h3 id="如何让-deadloop-goroutine-以外的-goroutine-无法得到调度"><a href="#如何让-deadloop-goroutine-以外的-goroutine-无法得到调度" class="headerlink" title="如何让 deadloop goroutine 以外的 goroutine 无法得到调度"></a>如何让 deadloop goroutine 以外的 goroutine 无法得到调度</h3><p>让 GO 运行时不启动那么多 P，让所有用户级 goroutine 都在一个 P 上调度。<br>三种办法达到上面的效果：</p><ol><li>main 函数最开头处调用 runtime.GOMAXPROCS(1)</li><li>设置环境变量 export GOMAXPROCS&#x3D;1 后再启动程序</li><li>找一台单核单线程机器<br>使用这三个方法之一后，原来的服务启动后不会输出 giao 了。<br>流程：<br>deadloop 在 P1上调度，但这个 deadloop 没有给调度器抢占的机会，所以即便 sysmon 给 deadloop 抢占标识设置为 true，由于 deadloop 内部没有任何进入调度器代码的机会，始终无法重新调度 goroutine。所以 main 一直都躺在 P1的本地队列中等待<br>PS:go 1.14 加入了抢占式调度，这个例子将不适用。</li></ol><h3 id="如何在-GOMAXPROCS-1的情况下让-main-goroutine-调度"><a href="#如何在-GOMAXPROCS-1的情况下让-main-goroutine-调度" class="headerlink" title="如何在 GOMAXPROCS&#x3D;1的情况下让 main goroutine 调度"></a>如何在 GOMAXPROCS&#x3D;1的情况下让 main goroutine 调度</h3><p>执行函数会执行 runtime.morestack_noctxt。<br>runtime.morestack_noctxt：这个函数会检查是否需要扩容连续栈，并进入抢占调度逻辑。一旦所在 goroutine 被设置为可抢占，抢占调度代码就会剥夺原来 goroutine 的制宪权，将其让给其他 goroutine。<br>但即使在 deadloop 中加入一个函数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func deadloop()&#123;</span><br><span class="line">    for &#123;</span><br><span class="line">        add(3,5)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">func add(a,b int) int &#123;</span><br><span class="line">    return a + b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之前的程序也不会打印 giao，原因就是 go 编译器在生成代码时执行了内联（inline）优化，因为 add 的调用对 deadloop 行为结果没有影响。<br>*问：去掉 inline 优化启动会调度吗？让我们在编译的时候关闭内联优化再试试<br><code>go build -gcflags &#39;-N -l&#39; -o program main.go</code><br>*答：再运行之后发现还是不会调度，因为在 main.add 的代码中，没有发现 morestack 函数踪迹，也就是即便调用了 add，dp 也没有机会进入 GO 运行时的 goroutine 调度逻辑中。<br>*问：那为什么 go 编译器没有在 main.add 函数中加入 morestack 呢？<br>*答：因为 add 函数位于调用数的 leaf 位置，编译器可以确保其不再有新栈帧生成，不会导致栈分裂或超出现有栈边界，于是就不再插入 morestack 了。</p><blockquote><p>PS：在 for 循环中 leaf function 是否应该插入 morestack 还有争议：<a href="https://github.com/golang/go/issues/10958%EF%BC%8C%E8%BF%99%E4%B8%AA%E7%9B%AE%E5%89%8D%E5%B7%B2%E7%BB%8F">https://github.com/golang/go/issues/10958，这个目前已经</a> close 了，后面看看</p></blockquote><ul><li>问：那么怎么让 add 可以插入 morestack 呢？</li><li>答：不直接调用 add，在 add 之上包装一个 dummp() ，这样即使 add 本身不会调用 morestack，但是 dummy 中会调用，因为 dummy 不是 leaf：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">func dummy () &#123;</span><br><span class="line">    add(3,5)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func deadloop() &#123;</span><br><span class="line">    for &#123;</span><br><span class="line">         dummy()   </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这时会发现 giao 又来了<br>汇编中为何 runtime.morestack_noctxt(SB) 放到 RET 后面<br>一般我们都认为 runtime.morestack_noctxt 调用是在函数入口处的，但实际编译出来的汇编代码中是在 RET 后的。<br>这个太深奥了，按 go 开发团队的解释：是为了更好的利用现代 CPU 的 “静态分支预测” 功能，以提升执行性能。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go atomic</title>
      <link href="/2025/03/10/Go-atomic/"/>
      <url>/2025/03/10/Go-atomic/</url>
      
        <content type="html"><![CDATA[<h2 id="Go-提供的原子操作都是非侵入式的，对应标准库-sync-atomic"><a href="#Go-提供的原子操作都是非侵入式的，对应标准库-sync-atomic" class="headerlink" title="Go 提供的原子操作都是非侵入式的，对应标准库 sync&#x2F;atomic"></a>Go 提供的原子操作都是非侵入式的，对应标准库 sync&#x2F;atomic</h2><p>支持的类型包括6个：<br>int32 int64 uint32 uint64 uintptr unsafe.Pointer<br>这些函数支持的原子操作共5种：增减(Add)、CAS(compare and swap)、Load、Store、Swap</p><h2 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h2><p>atomic.AddUint32(*obj, uint32(n)) &#x2F;&#x2F; 在原来的基础上增加 n</p><h2 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h2><p>假设被操作的值未被改变，并一旦确定这个假设的真实性就立即进行值替换<br>想要安全的并发一些类型值，总是应该先使用 CAS<br>atomic.CompareAndSwap(&amp;addr, old ,new) 当 addr 与 old 相同，就用 new 替换 addr 的值</p><h2 id="载入"><a href="#载入" class="headerlink" title="载入"></a>载入</h2><p>一个写操作没有完成，但有一个读操作已经发生，这样就会读错数据了。<br>为原子的读取某个值，atomic 提供了 LoadXXX(addr *类型)的方法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for &#123;</span><br><span class="line">    v := atomic.LoadInt32(&amp;addr)</span><br><span class="line">    if atomic.CompareAndSwapInt32(&amp;v, addr, (addr + v))&#123;</span><br><span class="line">        break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>写入操作,函数名 atomic.StoreXXX<br>在原子的存储某个值的过程中，任何cpu都不会进行针对进行同一个值的读或写操作。如果我们把所有针对此值的写操作都改为原子操作，那么就不会出现针对此值的读操作读操作因被并发的进行而读到修改了一半的情况。<br><code>atomic.StoreInt32(&amp;addr, newaddr)</code></p><h2 id="交换"><a href="#交换" class="headerlink" title="交换"></a>交换</h2><p>CAS 会看旧值是否改变了，而交换直接交换并返回旧值。<br><code>oldvalue := atomic.SwapInt32(&amp;value, newaddr)</code></p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go concurrent coding recipe</title>
      <link href="/2025/03/10/Go-concurrent-coding-recipe/"/>
      <url>/2025/03/10/Go-concurrent-coding-recipe/</url>
      
        <content type="html"><![CDATA[<h2 id="并行"><a href="#并行" class="headerlink" title="并行"></a>并行</h2><p>处理核数充足的情况下启动多个单线程应用实例，每个实例运行在一个核上。<br>典型：docker</p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>将应用分解为多个模块。传统语言（C++ JAVA）中，基于多线程模型的应用设计就是并发程序设计。<br>GO 语言的设计哲学——原生并发，轻量高效<br>Go 语言利用 goroutine（Go runtime 负责调度的用户层轻量级线程）来实现。<br>相比传统语言的并发，优点如下：</p><ol><li>占用资源小，每个 goroutine 初始栈只有2KB</li><li>不由 OS 调度，上下文切换代价小</li><li>开发爽，go 关键字作为通信原语</li><li>内置 channel 作为 goroutine 之间通信原语，为并发设计提供支撑</li></ol><p>综上所述，Go 程序设计思路的惯例是优先考虑并发设计。<br>并发的核心就是用 channel 作为传参调用在 goroutine 执行的函数上</p><h2 id="Go-常见的并发模式"><a href="#Go-常见的并发模式" class="headerlink" title="Go 常见的并发模式"></a>Go 常见的并发模式</h2><h3 id="创建模式"><a href="#创建模式" class="headerlink" title="创建模式"></a>创建模式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">func TestBmz(t *testing.T) &#123;</span><br><span class="line">c := spawn(func() &#123;&#125;)</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-c:</span><br><span class="line">fmt.Println(&quot;giao&quot;)</span><br><span class="line">default:</span><br><span class="line">fmt.Println(&quot;giao2&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type T struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">func spawn(f func()) chan T &#123;</span><br><span class="line">c := make(chan T)</span><br><span class="line">go func() &#123;</span><br><span class="line">// do many things</span><br><span class="line">f()</span><br><span class="line">&#125;()</span><br><span class="line">return c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>spawn 函数在内部创建一个 goroutine 并返回一个 channel 类型变量的函数。<br>调用 spawn 的函数和 spawn 内部通过 channel 通信。例子里只返回了一个 channel，实际上可以返回多个供业务代码使用</p><h3 id="退出模式"><a href="#退出模式" class="headerlink" title="退出模式"></a>退出模式</h3><p>goroutine 执行函数执行到 return 就代表 goroutine 退出。<br>一些常驻的后台服务程序对 goroutine 优雅退出有要求，于是有了下面的几个类型</p><h4 id="分离模式（detached）"><a href="#分离模式（detached）" class="headerlink" title="分离模式（detached）"></a>分离模式（detached）</h4><p>对于分离的 goroutine，创建它的 goroutine 不需要关心它的退出，这类 goroutine 在启动后即与其创造者彻底分离，生命周期与执行的主函数相关，函数返回 goroutine 就结束了。</p><ul><li>一次性任务</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">func (d *Dialer) DialContext(ctx context.Context, network, address string) (Conn, error) &#123;</span><br><span class="line">    // ...</span><br><span class="line">    if oldCancel := d.Cancel; oldCancel != nil &#123;</span><br><span class="line">subCtx, cancel := context.WithCancel(ctx)</span><br><span class="line">defer cancel()</span><br><span class="line">go func() &#123;</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-oldCancel:</span><br><span class="line">cancel()</span><br><span class="line">case &lt;-subCtx.Done():</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line">ctx = subCtx</span><br><span class="line">&#125;</span><br><span class="line">    // ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>DialContext 中创建了一个 goroutine ，用来监听两个 channel 是否有数据返回，一旦有数据就立马处理并退出</p><ul><li>常驻后台进程模式（有时也会借助 for select 加上 time &amp; ticker 等事件驱动完成轮询）</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">func TestBmz(t *testing.T) &#123;</span><br><span class="line">c := make(chan string)</span><br><span class="line">go B(c)</span><br><span class="line">defer close(c)</span><br><span class="line">name := &quot;bmz&quot;</span><br><span class="line">for _, b := range name &#123;</span><br><span class="line">c &lt;- string(b)</span><br><span class="line">time.Sleep(1)</span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(time.Second * 10)</span><br><span class="line">fmt.Println(&quot;main over 了&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func B(c chan string) &#123;</span><br><span class="line">for &#123;</span><br><span class="line">// 模拟轮询处理事务</span><br><span class="line">select &#123;</span><br><span class="line">case st, ok := &lt;-c:</span><br><span class="line">if !ok &#123;</span><br><span class="line">fmt.Println(&quot;close channel 了，日&quot;)</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(st)</span><br><span class="line">case &lt;-time.After(time.Second * 1):</span><br><span class="line">fmt.Println(&quot;超时了都&quot;)</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">// result</span><br><span class="line">=== RUN   TestBmz</span><br><span class="line">b</span><br><span class="line">m</span><br><span class="line">z</span><br><span class="line">超时了都</span><br><span class="line">main over 了</span><br><span class="line">--- PASS: TestBmz (10.01s)</span><br></pre></td></tr></table></figure><h3 id="join-模式"><a href="#join-模式" class="headerlink" title="join 模式"></a>join 模式</h3><ul><li>goroutine 创建者等待 goroutine 结束</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">func TestJoin(t *testing.T) &#123;</span><br><span class="line">done := spawn(worker, 5)</span><br><span class="line">fmt.Println(&quot;spawn a worker goroutine&quot;)</span><br><span class="line">&lt;-done</span><br><span class="line">fmt.Println(&quot;worker done&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func worker(args ...interface&#123;&#125;) &#123;</span><br><span class="line">if len(args) == 0 &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">interval, ok := args[0].(int)</span><br><span class="line">if !ok &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(time.Second * time.Duration(interval))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func spawn(f func(args ...interface&#123;&#125;), args ...interface&#123;&#125;) chan struct&#123;&#125; &#123;</span><br><span class="line">c := make(chan struct&#123;&#125;)</span><br><span class="line">go func() &#123;</span><br><span class="line">f(args...)</span><br><span class="line">c &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;()</span><br><span class="line">return c</span><br><span class="line">&#125;</span><br><span class="line">// result</span><br><span class="line">=== RUN   TestJoin</span><br><span class="line">spawn a worker goroutine</span><br><span class="line">worker done</span><br><span class="line">--- PASS: TestJoin (5.00s)</span><br></pre></td></tr></table></figure><ul><li>获取 goroutine 退出状态<br>goroutine 创建者不仅要等待 goroutine 退出，还要精准获取结束状态，通过自定义类型的 channel 完成。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">func TestJoin(t *testing.T) &#123;</span><br><span class="line">done := spawn(worker, nil)</span><br><span class="line">fmt.Println(&quot;spawn a worker goroutine&quot;)</span><br><span class="line">res := &lt;-done</span><br><span class="line">fmt.Printf(&quot;worker done, %s&quot;, res.Error())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func worker(args ...interface&#123;&#125;) error &#123;</span><br><span class="line">if len(args) == 0 &#123;</span><br><span class="line">return errors.New(&quot;len 0&quot;)</span><br><span class="line">&#125;</span><br><span class="line">interval, ok := args[0].(int)</span><br><span class="line">if !ok &#123;</span><br><span class="line">return errors.New(&quot;no arg&quot;)</span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(time.Second * time.Duration(interval))</span><br><span class="line">return errors.New(&quot;ok&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func spawn(f func(args ...interface&#123;&#125;) error, args ...interface&#123;&#125;) chan error &#123;</span><br><span class="line">c := make(chan error)</span><br><span class="line">go func() &#123;</span><br><span class="line">c &lt;- f(args...)</span><br><span class="line">&#125;()</span><br><span class="line">return c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出将 channel 的数据类型改为自定义的 struct（例子里是 error），可以传递更多的信息了。</p><ul><li>等待多个 goroutine 退出<br>更常见的情况是 goroutine 创建者创建不止一个 goroutine，并且需要等待全部新 goroutine 退出。<br>通过 sync.WaitGroup 实现多个 goroutine 退出等待。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">func TestJoin(t *testing.T) &#123;</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">done := make(chan error, 5)</span><br><span class="line">wg.Add(5)</span><br><span class="line">for i := 1; i &lt;= 5; i++ &#123;</span><br><span class="line">        // 这里注意闭包对于变量 scope ，i 对于闭包来说是全局函数，而在 for 循环内的是局部变量。</span><br><span class="line">        // 所以不能直接在 worker 里传参 i，否则会全部认为是循环之后的数（也就是 i 在所有 goroutine 中都是6）</span><br><span class="line">        // 要么在 for 循环第一步写一个 j := i,传 j；要么通过匿名函数传参将 i 传入，如下</span><br><span class="line">go func(i int) &#123;</span><br><span class="line">done &lt;- worker(&amp;wg, i)</span><br><span class="line">&#125;(i)</span><br><span class="line">fmt.Printf(&quot;start %d goroutine\n&quot;, i)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(&quot;spawn 5 workers goroutine&quot;)</span><br><span class="line">go func() &#123;</span><br><span class="line">for i := range done &#123;</span><br><span class="line">fmt.Printf(&quot;res :=%s\n&quot;, i.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">    // 这里也可以在启动一个 goroutine 检测 wg，这样 main 还能并发做一些别的事，最后通过 &lt;-done 来看看是否完成，没完成再阻塞</span><br><span class="line">    //go func()&#123;</span><br><span class="line">//    wg.Wait()</span><br><span class="line">//    done &lt;- errors.New(&quot;完事儿咯&quot;)</span><br><span class="line">//  &#125;()</span><br><span class="line">wg.Wait()</span><br><span class="line">close(done)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func worker(wg *sync.WaitGroup, args ...interface&#123;&#125;) error &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">interval, ok := args[0].(int)</span><br><span class="line">if !ok &#123;</span><br><span class="line">return errors.New(&quot;no arg&quot;)</span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(time.Second * time.Duration(interval))</span><br><span class="line">if interval == 4 &#123;</span><br><span class="line">return errors.New(&quot;BMZ ERROR&quot;)</span><br><span class="line">&#125;</span><br><span class="line">return errors.New(fmt.Sprintf(&quot;%d ok&quot;, interval))</span><br><span class="line">&#125;</span><br><span class="line">// res</span><br><span class="line">start 1 goroutine</span><br><span class="line">start 2 goroutine</span><br><span class="line">start 3 goroutine</span><br><span class="line">start 4 goroutine</span><br><span class="line">start 5 goroutine</span><br><span class="line">spawn 5 workers goroutine</span><br><span class="line">res :=1 ok</span><br><span class="line">res :=2 ok</span><br><span class="line">res :=3 ok</span><br><span class="line">res :=BMZ ERROR</span><br><span class="line">res :=5 ok</span><br></pre></td></tr></table></figure><ul><li>支持超时机制的等待<br>大部分时候我们不能无限阻塞，而是有一个超时，通过 select timer 配合 channel 可以完成</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">func TestJoin(t *testing.T) &#123;</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">done := make(chan interface&#123;&#125;)</span><br><span class="line">res := make(chan error, 5)</span><br><span class="line">for i := 1; i &lt;= 5; i++ &#123;</span><br><span class="line">wg.Add(1)</span><br><span class="line">go func(i int) &#123;</span><br><span class="line">res &lt;- worker(&amp;wg, i)</span><br><span class="line">&#125;(i)</span><br><span class="line">fmt.Printf(&quot;start %d goroutine\n&quot;, i)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(&quot;spawn 5 workers goroutine&quot;)</span><br><span class="line">go func() &#123;</span><br><span class="line">for i := range res &#123;</span><br><span class="line">fmt.Printf(&quot;res :=%s\n&quot;, i.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">go func() &#123;</span><br><span class="line">wg.Wait()</span><br><span class="line">done &lt;- errors.New(&quot;完事儿咯&quot;)</span><br><span class="line">&#125;()</span><br><span class="line">timer := time.NewTimer(4 * time.Second)</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-timer.C:</span><br><span class="line">fmt.Println(&quot;timeout(10s),exit&quot;)</span><br><span class="line">close(done)</span><br><span class="line">close(res)</span><br><span class="line">return</span><br><span class="line">case &lt;-done:</span><br><span class="line">fmt.Println(&quot;all goroutine finished&quot;)</span><br><span class="line">close(done)</span><br><span class="line">close(res)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func worker(wg *sync.WaitGroup, args ...interface&#123;&#125;) error &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">interval, ok := args[0].(int)</span><br><span class="line">if !ok &#123;</span><br><span class="line">return errors.New(&quot;no arg&quot;)</span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(time.Second * time.Duration(interval))</span><br><span class="line">if interval == 4 &#123;</span><br><span class="line">return errors.New(&quot;BMZ ERROR&quot;)</span><br><span class="line">&#125;</span><br><span class="line">return errors.New(fmt.Sprintf(&quot;%d ok&quot;, interval))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Wait-Notify-模式"><a href="#Wait-Notify-模式" class="headerlink" title="Wait-Notify 模式"></a>Wait-Notify 模式</h3><p>之前的两种模式中，创建者总是被动的等待新 goroutine 退出。<br>有些时候需要创建者主动告诉那些新的 goroutine 退出，尤其当 main goroutine 作为创建者时。<br>main goroutine 退出意味着 go 进程终止，粗暴退出不管子协程会导致数据损坏、不完整、丢失。<br>通过 notify-and-wait 模式满足这个场景，虽然不一定完全避免损失，但最起码有一种渠道可以这么做了</p><h4 id="通知并等待一个-goroutine-退出"><a href="#通知并等待一个-goroutine-退出" class="headerlink" title="通知并等待一个 goroutine 退出"></a>通知并等待一个 goroutine 退出</h4><p>基本用法就是在 goroutine 中返回一个 quit 的 channel，同时 goroutine里有一个 for select 监听 quit 和任务输入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">func worker2(j int) &#123;</span><br><span class="line">// 模拟执行</span><br><span class="line">time.Sleep(time.Second * time.Duration(j))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func spawn2(f func(int)) chan string &#123;</span><br><span class="line">quit := make(chan string)</span><br><span class="line">go func() &#123;</span><br><span class="line">// 模拟有任务进来</span><br><span class="line">var job chan int</span><br><span class="line">for &#123;</span><br><span class="line">select &#123;</span><br><span class="line">case j := &lt;-job:</span><br><span class="line">f(j)</span><br><span class="line">case &lt;-quit:</span><br><span class="line">quit &lt;- &quot;ok&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line">return quit</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func TestBMZ2(t *testing.T) &#123;</span><br><span class="line">quit := spawn2(worker2)</span><br><span class="line">fmt.Println(&quot;spawn a worker goroutine&quot;)</span><br><span class="line">time.Sleep(5 * time.Second)</span><br><span class="line">fmt.Println(&quot;notify goroutine quit&quot;)</span><br><span class="line">quit &lt;- &quot;exit&quot;</span><br><span class="line">timer := time.NewTimer(10 * time.Second)</span><br><span class="line">defer timer.Stop()</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-timer.C:</span><br><span class="line">fmt.Println(&quot;timeout of 10s&quot;)</span><br><span class="line">return</span><br><span class="line">case status := &lt;-quit:</span><br><span class="line">fmt.Printf(&quot;quit with status: %s&quot;, status)</span><br><span class="line">// 这里就做退出之后的处理</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="通知并等待多个-goroutine-退出"><a href="#通知并等待多个-goroutine-退出" class="headerlink" title="通知并等待多个 goroutine 退出"></a>通知并等待多个 goroutine 退出</h4><p>利用 channel 的一个特性：close(channel)时，所有阻塞到这个 chennel 的 goroutine 都会得到通知。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">func worker2(j int) &#123;</span><br><span class="line">// 模拟执行</span><br><span class="line">time.Sleep(time.Second * time.Duration(j))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func spwan3(n int, f func(int)) chan struct&#123;&#125; &#123;</span><br><span class="line">quit := make(chan struct&#123;&#125;)</span><br><span class="line">job := make(chan int)</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">for i := 0; i &lt; n; i++ &#123;</span><br><span class="line">wg.Add(1)</span><br><span class="line">go func(i int) &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">name := fmt.Sprintf(&quot;woker-id: %d&quot;, i)</span><br><span class="line">fmt.Println(name, &quot; start&quot;)</span><br><span class="line">for &#123;</span><br><span class="line">j, ok := &lt;-job</span><br><span class="line">if !ok &#123;</span><br><span class="line">fmt.Println(name, &quot; notified to done&quot;)</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">worker2(j)</span><br><span class="line">&#125;</span><br><span class="line">&#125;(i)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">go func() &#123;</span><br><span class="line">&lt;-quit</span><br><span class="line">close(job) // 广播给所有</span><br><span class="line">wg.Wait()</span><br><span class="line">quit &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">return quit</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func TestBMZ2(t *testing.T) &#123;</span><br><span class="line">quit := spwan3(5, worker2)</span><br><span class="line">fmt.Println(&quot;spawn a group of workers&quot;)</span><br><span class="line"></span><br><span class="line">time.Sleep(5 * time.Second)</span><br><span class="line">fmt.Println(&quot;main notify to quit&quot;)</span><br><span class="line">quit &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line"></span><br><span class="line">timer := time.NewTimer(5 * time.Second)</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-timer.C:</span><br><span class="line">fmt.Println(&quot;timeout of 5s&quot;)</span><br><span class="line">return</span><br><span class="line">case &lt;-quit:</span><br><span class="line">fmt.Println(&quot;all goroutines quit&quot;)</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面例子中通过 close(job) 来广播给各个 goroutine，worker goroutine 监听 job channel，当创建者关闭 job channel 时，通过判断 &lt;-job 是否 ok 来接受通知</p><h3 id="退出模式具体应用"><a href="#退出模式具体应用" class="headerlink" title="退出模式具体应用"></a>退出模式具体应用</h3><p>很多时候程序中完成一个业务逻辑需要多个 goroutine</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">go producer.Start()</span><br><span class="line">go consumer.Start()</span><br><span class="line">go watch.Start()</span><br><span class="line">// ....</span><br></pre></td></tr></table></figure><p>这些 goroutine 职责不同，生命周期也不同，很难用统一的框架全面管理他们。我们尝试缩小问题的范围，聚焦在实现一个“超时等待退出”框架。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">type GracefullyShutdowner interface &#123;</span><br><span class="line">    Shutdown(timeout time.Duration) error</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 类似 http.HandlerFunc</span><br><span class="line">type ShutdownFunc func(time.Duration) error</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">    这样普通函数就能很容易的转化为 GracefullyShutdowner 类型的函数了</span><br><span class="line">**/</span><br><span class="line">func (f ShutdownFunc) Shutdown(timeout time.Duration) error &#123;</span><br><span class="line">    return f(timeout)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="并行退出"><a href="#并行退出" class="headerlink" title="并行退出"></a>并行退出</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">func ConcurrentShutdown(timeout time.Duration, funcs ...GracefullyShutdowner) error &#123;</span><br><span class="line">c := make(chan struct&#123;&#125;)</span><br><span class="line"></span><br><span class="line">go func() &#123;</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">for _, g := range funcs &#123;</span><br><span class="line">wg.Add(1)</span><br><span class="line">go func(shutdowner GracefullyShutdowner) &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">shutdowner.Shutdown(timeout)</span><br><span class="line">&#125;(g)</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br><span class="line">c &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">timer := time.NewTimer(timeout)</span><br><span class="line"></span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-timer.C:</span><br><span class="line">fmt.Println(&quot;timeout&quot;)</span><br><span class="line">return errors.New(&quot;shit timeout&quot;)</span><br><span class="line">case &lt;-c:</span><br><span class="line">fmt.Println(&quot;gracefully quit&quot;)</span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ShutdownMaker(processTm int) func(time.Duration) error &#123;</span><br><span class="line">return func(time.Duration) error &#123;</span><br><span class="line">time.Sleep(time.Second * time.Duration(processTm))</span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">func TestBMZ3(t *testing.T) &#123;</span><br><span class="line">f1 := ShutdownMaker(2)</span><br><span class="line">f2 := ShutdownMaker(6)</span><br><span class="line">err := ConcurrentShutdown(10*time.Second, ShutdownFunc(f1), ShutdownFunc(f2))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;error:%s\n&quot;, err.Error())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">err = ConcurrentShutdown(4*time.Second, ShutdownFunc(f1), ShutdownFunc(f2))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;error:%s\n&quot;, err.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过一个工具函数 shutdownMaker 制作出通过 ShutdownFunc 转型的 实现接口的实例</p><h4 id="串行退出"><a href="#串行退出" class="headerlink" title="串行退出"></a>串行退出</h4><p>比并行简单多了，只是把 select 放到每次循环里面。同时注意一下 timeout 的剩余时间传入到下一次循环中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">func SequentialShutdown(timeout time.Duration, funcs ...GracefullyShutdowner) error &#123;</span><br><span class="line">start := time.Now()</span><br><span class="line">var left time.Duration</span><br><span class="line">timer := time.NewTimer(timeout)</span><br><span class="line">c := make(chan struct&#123;&#125;)</span><br><span class="line">for _, g := range funcs &#123;</span><br><span class="line">// 这两步是因为 timeout 是所有函数完毕的 timeout，每次要从新算</span><br><span class="line">elasped := time.Since(start)</span><br><span class="line">left = timeout - elasped</span><br><span class="line">go func(shutdowner GracefullyShutdowner) &#123;</span><br><span class="line">shutdowner.Shutdown(left)</span><br><span class="line">fmt.Printf(&quot;%v, shutdown over\n&quot;, g)</span><br><span class="line">c &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;(g)</span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-timer.C:</span><br><span class="line">fmt.Println(&quot;timeout shit&quot;)</span><br><span class="line">case &lt;-c:</span><br><span class="line">// 继续循环执行下一个 func</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func ShutdownMaker(processTm int) func(time.Duration) error &#123;</span><br><span class="line">return func(time.Duration) error &#123;</span><br><span class="line">time.Sleep(time.Second * time.Duration(processTm))</span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">func TestBMZ3(t *testing.T) &#123;</span><br><span class="line">f1 := ShutdownMaker(2)</span><br><span class="line">f2 := ShutdownMaker(6)</span><br><span class="line">err := SequentialShutdown(3*time.Second, ShutdownFunc(f1), ShutdownFunc(f2))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;error:%s\n&quot;, err.Error())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="管道模式"><a href="#管道模式" class="headerlink" title="管道模式"></a>管道模式</h2><p>也就是流水线的形式。<br>直接举例子——偶数的平方<br>分成4个环节：</p><ol><li>生成数据序列（通过 NewGenerator 返回一个 channel，之后灌数据到 channel 中），生成完毕后 close 这个 channel。</li><li>过滤出奇数，只保留偶数。偶数发送到下一个环节中，处理完之后关闭输出的 channel</li><li>对偶数进行平方，处理完之后关闭输出的 channel</li><li>将实际结果输出到控制台。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">func NewGenerator(start, count int) &lt;-chan int &#123;</span><br><span class="line">out := make(chan int)</span><br><span class="line">go func() &#123;</span><br><span class="line">for i := start; i &lt; start+count; i++ &#123;</span><br><span class="line">out &lt;- i</span><br><span class="line">&#125;</span><br><span class="line">        close(out)</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">return out</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func filterOdd(in int) (int, bool) &#123;</span><br><span class="line">if in%2 == 0 &#123;</span><br><span class="line">return in, true</span><br><span class="line">&#125; else &#123;</span><br><span class="line">return -1, false</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func square(in int) (int, bool) &#123;</span><br><span class="line">return in * in, true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func execute(f func(int) (int, bool), in &lt;-chan int) &lt;-chan int &#123;</span><br><span class="line">out := make(chan int)</span><br><span class="line">go func() &#123;</span><br><span class="line">for v := range in &#123;</span><br><span class="line">r, ok := f(v)</span><br><span class="line">if ok &#123;</span><br><span class="line">out &lt;- r</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">close(out)</span><br><span class="line">&#125;()</span><br><span class="line">return out</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func TestBMZ4(t *testing.T) &#123;</span><br><span class="line">in := NewGenerator(1, 10)</span><br><span class="line">out := execute(square, execute(filterOdd, in))</span><br><span class="line">for v := range out &#123;</span><br><span class="line">fmt.Println(v)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//res</span><br><span class="line">=== RUN   TestBMZ4</span><br><span class="line">4</span><br><span class="line">16</span><br><span class="line">36</span><br><span class="line">64</span><br><span class="line">100</span><br><span class="line">--- PASS: TestBMZ4 (0.00s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure><p>这种比较容易扩展，假如上面例子再扩展一个功能：过滤掉所有小于100的数，就新增一个函数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">func filterSmall(in int) (int, bool) &#123;</span><br><span class="line">if in &gt;= 100 &#123;</span><br><span class="line">return in, true</span><br><span class="line">&#125; else &#123;</span><br><span class="line">return -1, false</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">// 再在 main 里增加一个流水线即可</span><br><span class="line">func TestBMZ4(t *testing.T) &#123;</span><br><span class="line">in := NewGenerator(1, 10)</span><br><span class="line">out := execute(square, execute(filterOdd, in))</span><br><span class="line">out2 := execute(filterSmall, out)</span><br><span class="line">for v := range out2 &#123;</span><br><span class="line">fmt.Println(v)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="扇出模式"><a href="#扇出模式" class="headerlink" title="扇出模式"></a>扇出模式</h3><p>多个功能相同的 goroutine 从同一个 channel 读取数据并处理，直到这个 channel 关闭。扇出模式会让一组 goroutine 平均分配工作量，进而均衡利用 cpu</p><h3 id="扇入模式"><a href="#扇入模式" class="headerlink" title="扇入模式"></a>扇入模式</h3><p>处理程序面对不止一个输入 channel，于是我们把所有 channel 中的数据汇聚到一个统一的输入 channel，然后一直从新的 channel 中读取并处理，一直到新 channel 因为全部输入 channel 关闭而关闭。<br><img src="/2025/03/10/Go-concurrent-coding-recipe/image.png"><br>一个处理数据集的例子，有两个算子，一个是过滤出偶数，一个是平方，结果是将一个数据集中所有符合算子条件的结果输出到 stdout。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">// 制造数据</span><br><span class="line">func newNumGenerator(start int, count int) &lt;-chan int &#123;</span><br><span class="line">c := make(chan int)</span><br><span class="line">go func() &#123;</span><br><span class="line">for i := start; i &lt; start+count; i++ &#123;</span><br><span class="line">c &lt;- i</span><br><span class="line">&#125;</span><br><span class="line">close(c)</span><br><span class="line">&#125;()</span><br><span class="line">return c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func filterOdd(in int) (int, bool) &#123;</span><br><span class="line">if in%2 == 0 &#123;</span><br><span class="line">return in, true</span><br><span class="line">&#125;</span><br><span class="line">return 0, false</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func square(in int) (int, bool) &#123;</span><br><span class="line">return in * in, true</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 扇出模式，多个 goroutine 从一个同一个 in channel 中消费数据，直到 channel 关闭</span><br><span class="line">func spawnGroup(name string, num int, f func(int) (int, bool), in &lt;-chan int) &lt;-chan int &#123;</span><br><span class="line">groupOut := make(chan int)</span><br><span class="line">var outSlice []chan int</span><br><span class="line">for i := 0; i &lt; num; i++ &#123;</span><br><span class="line">out := make(chan int)</span><br><span class="line">go func(i int) &#123;</span><br><span class="line">name := fmt.Sprintf(&quot;%s-%d:&quot;, name, i)</span><br><span class="line">fmt.Println(name, &quot;begin to work&quot;)</span><br><span class="line">for v := range in &#123;</span><br><span class="line">r, ok := f(v)</span><br><span class="line">if ok &#123;</span><br><span class="line">out &lt;- r</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">close(out)</span><br><span class="line">fmt.Printf(&quot;%s work done\n&quot;, name)</span><br><span class="line">&#125;(i)</span><br><span class="line">outSlice = append(outSlice, out)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 扇入模式，多个 channel 通过多个 goroutine 将数据导入到一个汇总的 channel，导入完之后记得 close 汇总的 channel</span><br><span class="line">go func() &#123;</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">for _, out := range outSlice &#123;</span><br><span class="line">wg.Add(1)</span><br><span class="line">go func(out &lt;-chan int) &#123;</span><br><span class="line">for v := range out &#123;</span><br><span class="line">groupOut &lt;- v</span><br><span class="line">&#125;</span><br><span class="line">wg.Done()</span><br><span class="line">&#125;(out)</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br><span class="line">close(groupOut)</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">return groupOut</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func TestBMZ5(t *testing.T) &#123;</span><br><span class="line">in := newNumGenerator(1, 20)</span><br><span class="line">out := spawnGroup(&quot;square&quot;, 2, square, spawnGroup(&quot;filterOdd&quot;, 3, filterOdd, in))</span><br><span class="line">time.Sleep(3 * time.Second)</span><br><span class="line">fmt.Println(&quot;final result:&quot;)</span><br><span class="line">for v := range out &#123;</span><br><span class="line">fmt.Println(v)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="超时与取消模式"><a href="#超时与取消模式" class="headerlink" title="超时与取消模式"></a>超时与取消模式</h2><p>客户端向服务的发起请求并等待结果是一个典型的场景。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">// 有多个气象中心，我们客户端同时向三个 http server 发送请求，获取第一个返回的结果作为真正的结果</span><br><span class="line">type result struct &#123;</span><br><span class="line">value string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func first(servers ...*httptest.Server) (result, error) &#123;</span><br><span class="line">c := make(chan result, len(servers))</span><br><span class="line"></span><br><span class="line">queryFunc := func(server *httptest.Server) &#123;</span><br><span class="line">url := server.URL</span><br><span class="line">resp, err := http.Get(url)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;error :%s\n&quot;, err.Error())</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">defer resp.Body.Close()</span><br><span class="line">body, _ := ioutil.ReadAll(resp.Body)</span><br><span class="line">c &lt;- result&#123;</span><br><span class="line">value: string(body),</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for _, serv := range servers &#123;</span><br><span class="line">go queryFunc(serv)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return &lt;-c, nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func MokeServer(name string) *httptest.Server &#123;</span><br><span class="line">return httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class="line">fmt.Printf(&quot;%s receive http request\n&quot;, name)</span><br><span class="line">randNum := rand.Intn(8)</span><br><span class="line">fmt.Println(name, &quot;: randnum &quot;, randNum)</span><br><span class="line">time.Sleep(time.Duration(randNum) * time.Second)</span><br><span class="line">w.Write([]byte(name + &quot;:ok&quot;))</span><br><span class="line">&#125;))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func TestBMZ6(t *testing.T) &#123;</span><br><span class="line">result, err := first(MokeServer(&quot;server 1&quot;), MokeServer(&quot;server 2&quot;), MokeServer(&quot;server 3&quot;))</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;invoke first error:%s\n&quot;, err.Error())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(&quot;final result:&quot;, result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个例子没有超时控制，有可能因网络原因一直没有返回，用户体验就很垃了，加上超时的 first 函数如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">func first(servers ...*httptest.Server) (result, error) &#123;</span><br><span class="line">c := make(chan result, len(servers))</span><br><span class="line"></span><br><span class="line">queryFunc := func(server *httptest.Server) &#123;</span><br><span class="line">url := server.URL</span><br><span class="line">resp, err := http.Get(url)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;error :%s\n&quot;, err.Error())</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">defer resp.Body.Close()</span><br><span class="line">body, _ := ioutil.ReadAll(resp.Body)</span><br><span class="line">c &lt;- result&#123;</span><br><span class="line">value: string(body),</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for _, serv := range servers &#123;</span><br><span class="line">go queryFunc(serv)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">select &#123;</span><br><span class="line">case r := &lt;-c:</span><br><span class="line">return r, nil</span><br><span class="line">case &lt;-time.After(2 * time.Second):</span><br><span class="line">return result&#123;&#125;, errors.New(&quot;timeout&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>加上超时之后也有问题，没有在返回的时候释放 request 相关资源，会泄露。这种情况需要使用 context 来取消了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">func first(servers ...*httptest.Server) (result, error) &#123;</span><br><span class="line">c := make(chan result, len(servers))</span><br><span class="line">ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line">defer cancel()</span><br><span class="line">queryFunc := func(i int, server *httptest.Server) &#123;</span><br><span class="line">url := server.URL</span><br><span class="line">req, err := http.NewRequest(&quot;GET&quot;, url, nil)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;new request error :%s \n&quot;, err.Error())</span><br><span class="line">&#125;</span><br><span class="line">req = req.WithContext(ctx)</span><br><span class="line">fmt.Println(i, &quot; query goroutine send req...&quot;)</span><br><span class="line">resp, err := http.DefaultClient.Do(req)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">fmt.Printf(&quot;get response error :%s&quot;, err.Error())</span><br><span class="line">&#125;</span><br><span class="line">defer resp.Body.Close()</span><br><span class="line">body, _ := ioutil.ReadAll(resp.Body)</span><br><span class="line">c &lt;- result&#123;</span><br><span class="line">value: string(body),</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for index, serv := range servers &#123;</span><br><span class="line">go queryFunc(index, serv)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">select &#123;</span><br><span class="line">case r := &lt;-c:</span><br><span class="line">return r, nil</span><br><span class="line">case &lt;-time.After(2 * time.Second):</span><br><span class="line">return result&#123;&#125;, errors.New(&quot;timeout&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用 ctx.WithCancel 创建了一个可取消的 ctx。通过 defer cancel 指定 cancel 函数在 first 执行前被执行，尚在途中的的 goroutine 都会收到 cancel 指令而退出。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python-learning</title>
      <link href="/2025/03/10/python-learning/"/>
      <url>/2025/03/10/python-learning/</url>
      
        <content type="html"><![CDATA[<h2 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a>设计哲学</h2><p>我用过的语言（java go rust…)，除了 java，别的语言似乎都有独树一帜的<strong>设计哲学</strong>。</p><blockquote><p>不放过每一个黑 java 的时刻，哈哈。</p></blockquote><p>新手学语法，高手看门道。而所谓门道，就是理解一个语言的设计哲学。<br>我在网上教程看到一些给 python 标榜简单，我表示非常认同；<br>但是还有其他标签，比如 “优雅” “明确”, 这不明摆着搞笑的</p><blockquote><p>那么多动态传参，纯解释型，怎么有人好意思说明确<br>优雅可能是相对的，至少 python 相比我心目中殿堂级语言 go 来讲，看不出半点优雅。</p></blockquote><p>当然也有可能我目前在 python 造诣不高，下面继续精炼和学习吧</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ol><li>动态解释型语言：随时改源码就可立刻测试，无需编译，秒杀各种需要编译型的构建时间</li><li>语法简单：小学生可以学不会一元一次方程，但是分分钟学会 Python</li><li>库丰富：因为语法简单，所以很多人喜欢用，喜欢用就用这个语言造轮子，现在轮子造的比 java 还多了</li><li>好理解：可以当做脚本语言，更符合菜鸟程序员喜欢的<strong>面向过程</strong></li></ol><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ol><li>运行速度&#x3D;&#x3D;屎，我见过最慢的</li><li>依赖，环境管理工具不统一，被 go 完爆不解释</li><li>只有伪多线程：GIL 锁的限制，让本来执行就慢的语言雪上加霜</li><li>代码明文，对于能编译的语言，反编译其实都有较大难度；而像 java 这种假装编译的，源码被别人获取不要太简单，python 和 java 一样，或者比 Java 还菜</li></ol><h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>for x in list(set):<br>    &#x2F;&#x2F; …</p><p>while x &gt; 0:<br>    &#x2F;&#x2F; …</p><h3 id="模式匹配"><a href="#模式匹配" class="headerlink" title="模式匹配"></a>模式匹配</h3><p>python3.10 以后才支持使用 match(go&#x2F;java 里的 switch)</p><h3 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h3><h4 id="不写-return-返回-None"><a href="#不写-return-返回-None" class="headerlink" title="不写 return 返回 None"></a>不写 return 返回 None</h4><p>def abc(x):<br>当没写 return 这一行时，返回的是 None</p><h4 id="返回多值返回-tuple"><a href="#返回多值返回-tuple" class="headerlink" title="返回多值返回 tuple"></a>返回多值返回 tuple</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def A(x):</span><br><span class="line">    return x+1,x-1</span><br><span class="line">b = def(10)</span><br><span class="line">// b 是 (11,9) 的tuple</span><br></pre></td></tr></table></figure><h4 id="定义形参默认值"><a href="#定义形参默认值" class="headerlink" title="定义形参默认值"></a>定义形参默认值</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def B(x=10):</span><br><span class="line">    print(x)</span><br><span class="line">B(11) // 11</span><br><span class="line">B() // 10</span><br></pre></td></tr></table></figure><h4 id="形参必须用不变对象"><a href="#形参必须用不变对象" class="headerlink" title="形参必须用不变对象"></a>形参必须用不变对象</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def C(x=[]):</span><br><span class="line">    x.append(10)</span><br><span class="line">C() // [10]</span><br><span class="line">c() // [10,10]</span><br></pre></td></tr></table></figure><p>Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，<br>每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def add_end(L=None):</span><br><span class="line">    if L is None:</span><br><span class="line">        L = []</span><br><span class="line">    L.append(&#x27;END&#x27;)</span><br><span class="line">    return L</span><br></pre></td></tr></table></figure><p>这个代码就不管怎么调，都是从 [] 开始 append 的</p><blockquote><p>默认参数必须指向不变对象</p></blockquote><h3 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def calc(numbers):</span><br><span class="line">    sum = 0</span><br><span class="line">    for n in numbers:</span><br><span class="line">        sum = sum + n * n</span><br><span class="line">    return sum</span><br><span class="line"></span><br><span class="line">print(calc([1, 2, 3, 4, 5])) // 55</span><br><span class="line">// 这得先拼好形参，我们可以直接这样定义</span><br><span class="line">def calc(*numbers):</span><br><span class="line">    sum = 0</span><br><span class="line">    for n in numbers:</span><br><span class="line">        sum = sum + n * n</span><br><span class="line">    return sum</span><br><span class="line">print(calc(1,2,3)) // 14</span><br><span class="line">nums = [1,2,3]</span><br><span class="line">print(calc(*nums)) // 14</span><br></pre></td></tr></table></figure><blockquote><p>*nums表示把nums这个list的所有元素作为可变参数传进去。这种写法相当有用，而且很常见。</p></blockquote><h3 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def person(name, age, **kw):</span><br><span class="line">    print(&#x27;name:&#x27;, name, &#x27;age:&#x27;, age, &#x27;other:&#x27;, kw)</span><br><span class="line">person(&#x27;bmz&#x27;,10,city=&#x27;a&#x27;) // name: bmz age: 10 other: &#123;&#x27;city&#x27;: &#x27;a&#x27;&#125;</span><br></pre></td></tr></table></figure><p>这样 **kw 提供了扩展性，可以任意传入不是必须的值，和可变参数类似，可以先声明一个 extra 的 dict，然后把 **extra 传入</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">extra = &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125;</span><br><span class="line">person(&#x27;Jack&#x27;, 24, **extra)</span><br><span class="line">// name: Jack age: 24 other: &#123;&#x27;city&#x27;: &#x27;Beijing&#x27;, &#x27;job&#x27;: &#x27;Engineer&#x27;&#125;</span><br></pre></td></tr></table></figure><h3 id="组合参数"><a href="#组合参数" class="headerlink" title="组合参数"></a>组合参数</h3><p>在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。<br>但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。<br><code>def f1(a, b, c=0, *args, **kw):</code><br>有一个可读性不太好的用法，但是很简便，就是用 tuple 或 dict 调用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// tuple</span><br><span class="line">def f1(a, b, c=0, *args, **kw):</span><br><span class="line">    print(&#x27;a =&#x27;, a, &#x27;b =&#x27;, b, &#x27;c =&#x27;, c, &#x27;args =&#x27;, args, &#x27;kw =&#x27;, kw)</span><br><span class="line">args = (1, 2, 3, 4)</span><br><span class="line">kw = &#123;&#x27;d&#x27;: 99, &#x27;x&#x27;: &#x27;#&#x27;&#125;</span><br><span class="line">f1(*args, **kw) // a = 1 b = 2 c = 3 args = (4,) kw = &#123;&#x27;d&#x27;: 99, &#x27;x&#x27;: &#x27;#&#x27;&#125;</span><br><span class="line"></span><br><span class="line">// dict</span><br><span class="line"></span><br><span class="line">def f2(a, b, c=0, *, d, **kw):</span><br><span class="line">    print(&#x27;a =&#x27;, a, &#x27;b =&#x27;, b, &#x27;c =&#x27;, c, &#x27;d =&#x27;, d, &#x27;kw =&#x27;, kw)</span><br><span class="line"></span><br><span class="line">args = (1, 2, 3)</span><br><span class="line">kw = &#123;&#x27;d&#x27;: 88, &#x27;x&#x27;: &#x27;#&#x27;&#125;</span><br><span class="line">f2(*args, **kw) // a = 1 b = 2 c = 3 d = 88 kw = &#123;&#x27;x&#x27;: &#x27;#&#x27;&#125;</span><br></pre></td></tr></table></figure><p>所以，对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。</p><blockquote><p>虽然有这么多形参写法，但要是有函数真的用这么多组合，可读性必定很屎，堆屎哥out</p></blockquote><h3 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def fact(n):</span><br><span class="line">    if n==1:</span><br><span class="line">        return 1</span><br><span class="line">    return n * fact(n - 1)</span><br><span class="line">print(fact(5)) // 120</span><br></pre></td></tr></table></figure><blockquote><p>python 没有对尾递归做优化，很屎，所以递归的时候注意不要 stackOverFlow</p></blockquote><h2 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h2><h3 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h3><p>这个和 go 一样左闭右开，比如例子<br><code>L = [1,2,3,4,5]</code><br><code>L2 = L[1:3] // L2 = [2,3]</code><br>也支持使用负数索引从后往前取，比如<br><code>L3 = L[-2:0] // L3 = [4,5]</code><br>代表倒数第二个到倒数第0个</p><h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><p>python 的 for 循环是高度抽象的，不仅可以作用在 list 或 tuple 上，还可以在<strong>迭代对象</strong>上<br>如何判断一个对象是可迭代对象呢？方法是通过collections.abc模块的Iterable类型判断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from collections.abc import Iterable</span><br><span class="line">print(isinstance(&#x27;abc&#x27;, Iterable))</span><br><span class="line">&#x27;&#x27;&#x27;检查 str 是否可迭代&#x27;&#x27;&#x27;</span><br><span class="line">isinstance([1,2,3], Iterable)</span><br><span class="line">&#x27;&#x27;&#x27;检查 list 是否可迭代&#x27;&#x27;&#x27;</span><br><span class="line">isinstance(123, Iterable)</span><br><span class="line">&#x27;&#x27;&#x27;检查 int是否可迭代&#x27;&#x27;&#x27;</span><br></pre></td></tr></table></figure><p>最后一个小问题，如果要对list实现类似Java那样的下标循环怎么办？<br>Python内置的enumerate函数可以把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">for i, value in enumerate([&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]):</span><br><span class="line">...     print(i, value)</span><br><span class="line">...</span><br><span class="line">0 A</span><br><span class="line">1 B</span><br><span class="line">2 C</span><br><span class="line"></span><br><span class="line">for x, y in [(1, 1), (2, 4), (3, 9)]:</span><br><span class="line">...     print(x, y)</span><br><span class="line">...</span><br><span class="line">1 1</span><br><span class="line">2 4</span><br><span class="line">3 9</span><br></pre></td></tr></table></figure><h3 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h3><p>用来创建 list 的生成式</p><ul><li>正常声明一个 list<br><code>L = list(range(1,11))</code></li><li>如果想生成 n*n 作为元素，可以这么写：<br><code>L = [x * x for x in range(10)]</code><br>此时 L &#x3D; [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]</li><li>更牛逼的是，可以将条件语句写到最后，筛选一些元素<br><code>[x * x for x in range(1, 11) if x % 2 == 0]</code><br>此时 L &#x3D; [4, 16, 36, 64, 100]</li><li>更更牛逼的是，可以双层循环<br><code>L = [m + n for m in &#39;ABC&#39; for n in &#39;XYZ&#39;]</code><br>此时 L &#x3D; [‘AX’, ‘AY’, ‘AZ’, ‘BX’, ‘BY’, ‘BZ’, ‘CX’, ‘CY’, ‘CZ’]</li></ul><p>所以运用表达式可以一行搞定一些代码，可读性也还行，这个语法糖确实可以用一用<br>想在表达式里使用 if else，不能直接把 else 写最后。<br>需要先将 if 的代码块写 if 前面， else 的代码块写 for 前<br><code>[x+1 if x % 2 == 0 else -x for x in range(1, 11)]</code><br>此时 L &#x3D; [-1, 3, -3, 5, -5, 7, -7, 9, -9, 11]</p><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>一边循环一边计算的机制。类似动态规划的思想，用个别几个变量一直迭代一直算到最后<br><code>g = (x * x for x in range(10))</code><br>此时 g 的类型是 generator<br>generator 保存的是算法，每次调用 next(g)，是计算 g 的下一个元素的值，直到算到最后一个元素<br>但我们是聪明的程序员，一直 next(g) 有点蠢了， generator 其实是个 Iterator，我们可以 for 循环<br>比如我们生成一个斐波那契函数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def fib(max):</span><br><span class="line">    n, a, b = 0, 0, 1</span><br><span class="line">    while n &lt; max:</span><br><span class="line">        yield b</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        n = n + 1</span><br><span class="line">    return &#x27;done&#x27;</span><br><span class="line">f = fib(6)</span><br><span class="line">for x in f:</span><br><span class="line">    print(x) // 1 1 2 3 5 8</span><br></pre></td></tr></table></figure><p>这里用 yield 关键字将 fib 方法变成了一个 generator.<br>generator 函数的执行流程和普通函数不同，普通函数是遇到 return 就返回。<br>generator 函数是在米次调用 next() 的是时候执行，遇到 yield 就返回，再次执行时是从上一次的 yield 返回的地方执行</p><blockquote><p>这个设计还挺有意思</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def odd():</span><br><span class="line">    print(&#x27;step 1&#x27;)</span><br><span class="line">    yield 1</span><br><span class="line">    print(&#x27;step 2&#x27;)</span><br><span class="line">    yield(3)</span><br><span class="line">    print(&#x27;step 3&#x27;)</span><br><span class="line">    yield(5)</span><br><span class="line">g = odd()</span><br><span class="line">print(next(g)) // 1</span><br><span class="line">print(next(g)) // 3</span><br><span class="line">print(next(g)) // 5</span><br></pre></td></tr></table></figure><h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><p>for 循环可以作用于以下数据结构： list tuple dict set str generator(带有 yield 的 func)<br>这些可以进循环的类型统称为 Iterable，可迭代对象<br>使用 isinstance 可以判断一个对象是否是可迭代<br><code>from collections.abc import Iterator print(isinstance(g,Iterator)) // True</code><br>生成器不但可以被 for 循环，也可以被 next，可以被 next 调用的函数是 Iterator，称之为迭代器对象<br>生成器都是 Iterable 的，但 list dict str 只是 Iterable，并不是 Iterator，因为他们不能被 next 调用</p><blockquote><p>python 认为 Iterator 是一个数据流，可以无限的灌入数据，迭代数据，不需要知道长度<br>而 dict list 他们是有定长的，不符合这个定义</p></blockquote><h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><h3 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h3><p>就是函数作为一等公民，把其他函数作为形参，就叫 <em>高阶函数</em>,有点烦这种叫法</p><h4 id="map-reduce"><a href="#map-reduce" class="headerlink" title="map&#x2F;reduce"></a>map&#x2F;reduce</h4><blockquote><p>wtf 叫这个名，你撞枪口了小子</p></blockquote><p>理念跟 google 的 mr 思想是一样的，只是单机SB版罢了，怎么好意思叫这个的。。。</p><h4 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h4><p>挺好用的，就是过滤集合里的一些元素</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def is_odd(n):</span><br><span class="line">    return n % 2 == 1</span><br><span class="line">L = list(filter(lambda x:x%2==1, range(1, 20)))</span><br><span class="line">print(L) // [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]</span><br></pre></td></tr></table></figure><blockquote><p>lambda 是匿名函数，和 go 里 func(x int) { &#x2F;&#x2F; xxx }() 是一个意思，只不过写到一行去了</p></blockquote><h4 id="sorted"><a href="#sorted" class="headerlink" title="sorted"></a>sorted</h4><p>排序，写一个排序函数，然后会根据返回值进行字典序的排序</p><h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><p>关键字lambda表示匿名函数，冒号前面的x表示函数参数。</p><p>匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。</p><p>用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = lambda x: x * x</span><br><span class="line">print(f) // &lt;function &lt;lambda&gt; at 0x101c6ef28&gt;</span><br><span class="line">f(5) // 25</span><br></pre></td></tr></table></figure><p>同样，也可以把匿名函数作为返回值返回，比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def build(x, y):</span><br><span class="line">return lambda: x * x + y * y</span><br></pre></td></tr></table></figure><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>函数是一等公民，里面有一个 <strong>name</strong> 的属性，可以通过 func.<strong>name</strong> 拿到函数的名称<br>假如我们要增强一个函数(比如我这个函数是 def now(): ),又不希望改 now() 里的代码，<br>我们就会用装饰器来动态增强，这就是装饰器(decorator)<br>本质上 decorator 是返回函数的一个高阶函数<br>比如我们要打印日志</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def log(func):</span><br><span class="line">    def wrapper(*args, **kw):</span><br><span class="line">        print(&#x27;call %s():&#x27; % func.__name__)</span><br><span class="line">        return func(*args, **kw)</span><br><span class="line">    return wrapper</span><br><span class="line">@log</span><br><span class="line">def now():</span><br><span class="line">    print(&#x27;2025-03-10&#x27;)</span><br><span class="line">now() // call now: \n 2025-03-10</span><br></pre></td></tr></table></figure><p>实际上就是 log() 的返回值是一个函数 wrapper，再执行 wrapper(func)</p><h3 id="偏函数"><a href="#偏函数" class="headerlink" title="偏函数"></a>偏函数</h3><p>用 functools.partial 包装一些内置函数，比如要构建一个将字符串改成2进制的函数 int2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import functools</span><br><span class="line">int2 = functools.partial(int, base=2)</span><br><span class="line">print(int2(&#x27;10101&#x27;))</span><br></pre></td></tr></table></figure><h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><p>python 中一个 .py 文件就是一个 module，模块就是为了提高可维护性的，让干一类事的东西都写到一个 .py 文件里</p><blockquote><p>编写模块时注意不要将函数名和内置函数名字冲突了</p></blockquote><p>定位到一个模块，实际上是 $包.$文件<br>我们很常见的写法是 import xxx.abc，这个 xxx.abc 就是模块名<br>import 一个模块之后，就可以用这个模块下的所有功能了</p><h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><ul><li>正常的函数和变量是 Public ，也就是不加任何修饰的变量</li><li><strong>xxx</strong> 是特殊变量，可以直接引用，但有特殊用处，一般自己变量别这么命名</li><li>_xxx 或 __xxx 代表非公开，不应该直接被引用，但不是语言强制的，想用还是直接用，非常 <em>dynamic</em></li></ul><h3 id="如何安装三方模块"><a href="#如何安装三方模块" class="headerlink" title="如何安装三方模块"></a>如何安装三方模块</h3><p>pip 可以安装三方的模块包，一般来说三方包都会在 python 官网 pypi.python.org 托管，比如一个包名为 Pillow<br><code>pip install Pillow</code><br>以前使用过 anaconda 来管理，这个包等于预装了很多常用的三方包，numpy flask 这些<br>后面 anaconda.Inc 搞出法务问题，还是回归 pip install<br>python 解释器会在当前目录搜索所有已安装的模块和三方模块，搜素路径是 sys.path 中，有当前项目的目录，也有 .venv 里的一些目录，很多…<br><code>print(sys.path)</code><br>当在这些目录都找不到 import 的模块时，就会报错了<br>那怎么变化要搜索的路径呢？因为很多时候三方下载的包在别处</p><ol><li>改 sys.path<br><code>sys.path.append(&#39;myPath&#39;)</code></li><li>环境变量配置 PYTHONPATH，这些目录会自动添加到搜索路径<br><code>export PYTHONPATH=myPath</code></li></ol><h2 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h2><h3 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    def __init__(self, name, age):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;person walk&quot;)</span><br><span class="line"></span><br><span class="line">class Student(Person):</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;student walk&quot;)</span><br><span class="line"></span><br><span class="line">class Teacher(Person):</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;teacher walk&quot;)</span><br><span class="line"></span><br><span class="line">Person = Teacher(&quot;John&quot;, 22)</span><br><span class="line">Person.walk() // teacher walk</span><br></pre></td></tr></table></figure><p>注意 <strong>init</strong>(self, 一堆参数),第一个参数用于是 self<br>这个类似于构造方法吧，有了 init 后，就不能随便在创建类的实例时传参了，必须传 init 声明的参数(name age)</p><h3 id="鸭子类型"><a href="#鸭子类型" class="headerlink" title="鸭子类型"></a>鸭子类型</h3><p>和静态语言不同的时，假如有时一个函数形参是个 Person，那传入对象必须是 Person 或 Person 的子类，否则无法调用 walk<br>python 里只需要传入的对象有 walk 方法即可，跟类型无关</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def Help(p):</span><br><span class="line">    p.walk()</span><br><span class="line">class SB(object):</span><br><span class="line">    def __init__(self, id):</span><br><span class="line">        self.id = id</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;sb[%s] walk&quot; % self.id)</span><br><span class="line">s = SB(&#x27;sb-01&#x27;)</span><br><span class="line">Help(s) // sb[sb-01] walk</span><br></pre></td></tr></table></figure><blockquote><p>非常 dynamic</p></blockquote><h3 id="获取对象信息"><a href="#获取对象信息" class="headerlink" title="获取对象信息"></a>获取对象信息</h3><h4 id="使用-type"><a href="#使用-type" class="headerlink" title="使用 type()"></a>使用 type()</h4><p>type() 可以判断对象类型，不管基本还是自定义的，但他返回的是 class 类型<br>所以当我们判断两个变量 type 是否相同<br><code>type(123) == type(456) // True</code><br><code>type(123) == type(&#39;abc&#39;) // False</code><br>基本类型可以直接写 int str 等，但是判断对象是否是函数怎么办？<br>用 types 里的变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def fn():</span><br><span class="line">    pass</span><br><span class="line">type(fn)==types.FunctionType // True</span><br><span class="line">type(abs)==types.BuiltinFunctionType // True</span><br><span class="line">type((x for x in range(10)))==types.GeneratorType // True</span><br></pre></td></tr></table></figure><h4 id="使用-isinstance"><a href="#使用-isinstance" class="headerlink" title="使用 isinstance()"></a>使用 isinstance()</h4><p>一般判断 class 类型都是用 isinstance(),这里可以获取到继承关系</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p2 = Student(&quot;John&quot;,23)</span><br><span class="line">print(isinstance(p2, Person)) // True</span><br></pre></td></tr></table></figure><h4 id="实例属性和类属性"><a href="#实例属性和类属性" class="headerlink" title="实例属性和类属性"></a>实例属性和类属性</h4><ol><li>可以用 self 给实例和类绑定属性，比如用 <strong>init</strong> 里设置</li><li>实例.$新属性 &#x3D; ‘China’，就可以增加没定义过的属性了</li></ol><h3 id="slots"><a href="#slots" class="headerlink" title="slots"></a><strong>slots</strong></h3><p>绑定属性可以，函数也是一等公民，也可以绑定函数，wtf? nb<br>但给一个对象绑定的属性，new 一个新实例的时候，新实例肯定不知道，为了给所有实例都绑定新方法，就是用 class</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def set_score(self, score):</span><br><span class="line">    self.score = score</span><br><span class="line">Student.set_score = set_score</span><br></pre></td></tr></table></figure><p>但有很多时候我们想限制实例，只允许 Student 添加 age 和 name 属性，此时就是用 slot</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class Student(object):</span><br><span class="line">    __slots__ = (&#x27;name&#x27;, &#x27;age&#x27;) # 用tuple定义允许绑定的属性名称</span><br></pre></td></tr></table></figure><p>此时 score 不在 slots 里，没法添加<br>但是我用 python3.9 的时候，假如父类没写 slots，子类写了，子类的实例依旧可以绑定新属性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">class Person(object):</span><br><span class="line">    __slots__ = (&#x27;name&#x27;, &#x27;age&#x27;,&#x27;score&#x27;)</span><br><span class="line">    def __init__(self, name, age):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;person walk&quot;)</span><br><span class="line"></span><br><span class="line">class Student(Person):</span><br><span class="line">    __slots__ = (&#x27;name&#x27;, &#x27;age&#x27;)</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;student walk&quot;)</span><br><span class="line"></span><br><span class="line">class Teacher(Person):</span><br><span class="line">    def walk(self):</span><br><span class="line">        print(&quot;teacher walk&quot;)</span><br><span class="line"></span><br><span class="line">def set_age(self, age):</span><br><span class="line">    self.age = age</span><br><span class="line"></span><br><span class="line">s = Student(&quot;John&quot;, 22)</span><br><span class="line">s.score = 99</span><br><span class="line">print(s.score) // 99</span><br></pre></td></tr></table></figure><p>但当 Person 父类也写 slots 后，就不能添加了</p><h3 id="property"><a href="#property" class="headerlink" title="@property"></a>@property</h3><p>绑定属性时有时也不想直接暴露属性，这时候需要 bean<br>@property 写的方法代表这个是这个属性的 getter<br>@score.setter 代表是 setter</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Student(object):</span><br><span class="line">    @property</span><br><span class="line">    def score(self):</span><br><span class="line">        return self._score</span><br><span class="line"></span><br><span class="line">    @score.setter</span><br><span class="line">    def score(self, value):</span><br><span class="line">        if not isinstance(value, int):</span><br><span class="line">            raise ValueError(&#x27;score must be an integer!&#x27;)</span><br><span class="line">        if value &lt; 0 or value &gt; 100:</span><br><span class="line">            raise ValueError(&#x27;score must between 0 ~ 100!&#x27;)</span><br><span class="line">        self._score = value</span><br><span class="line">s = Student()</span><br><span class="line">s.score = 66 // 这行转化为 s.score(66)</span><br><span class="line">s.score // 转化为 s.score()</span><br></pre></td></tr></table></figure><p>这样 Student 就不需要去定义 score 本身，这样 score 这个属性就必须通过 bean 的方式，无法随意更改他</p><h3 id="多重继承"><a href="#多重继承" class="headerlink" title="多重继承"></a>多重继承</h3><p>这个必须点赞，不用写什么 extends 接一堆，而是直接 class C(ParentA, ParentB): 就代表继承自 A B 了</p><h3 id="定制类"><a href="#定制类" class="headerlink" title="定制类"></a>定制类</h3><p>类似 <strong>slots</strong> 和 <strong>len</strong> 这种变量可以定制类的某些特性，其实还有一些特殊的函数帮我们定制类</p><ol><li><strong>str</strong><br>toString() 罢了，帮助打印的,这样我们在 print(s) 的时候，自然就是 formatted 之后的字符串了</li><li><strong>iter</strong><br>如果是可以用于 for in 遍历的变量，必须实现这个方法，返回一个迭代对象<br>在实现 <strong>iter</strong> 的同时也必须实现 <strong>next</strong>(), 这里是遍历到每个元素时拿到下一个值</li><li><strong>getattr</strong><br>获取全部的属性，挺好用的，有的时候有才调，没有不调</li><li><strong>call</strong><br>实例有自己的属性和方法，这些都得先声明出一个对象，然后 $对象.xxx()<br>实际可以直接执行 $对象() 来执行某些操作</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Student(Person):</span><br><span class="line">    __slots__ = (&#x27;name&#x27;, &#x27;age&#x27;)</span><br><span class="line">    def __call__(self, *args, **kwargs):</span><br><span class="line">        print(&quot;Student call&quot;)</span><br><span class="line">s = Student(&quot;John&quot;, 22)</span><br><span class="line">s() // Student call</span><br></pre></td></tr></table></figure><h3 id="枚举类"><a href="#枚举类" class="headerlink" title="枚举类"></a>枚举类</h3><p><code>from enum import Enum</code><br>声明之后可以写这样的枚举</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from enum import Enum, unique</span><br><span class="line">Month = Enum(&#x27;Month&#x27;, (&#x27;Jan&#x27;, &#x27;Feb&#x27;, &#x27;Mar&#x27;, &#x27;Apr&#x27;, &#x27;May&#x27;, &#x27;Jun&#x27;, &#x27;Jul&#x27;, &#x27;Aug&#x27;, &#x27;Sep&#x27;, &#x27;Oct&#x27;, &#x27;Nov&#x27;, &#x27;Dec&#x27;))</span><br><span class="line">@unique</span><br><span class="line">class Weekday(Enum):</span><br><span class="line">    Sun = 0 # Sun的value被设定为0</span><br><span class="line">    Mon = 1</span><br><span class="line">    Tue = 2</span><br><span class="line">    Wed = 3</span><br><span class="line">    Thu = 4</span><br><span class="line">    Fri = 5</span><br><span class="line">    Sat = 6</span><br><span class="line">    </span><br><span class="line">s = Student(&quot;John&quot;, 22)</span><br><span class="line">s.month = Month.Mar</span><br><span class="line">s() // Month.Mar</span><br></pre></td></tr></table></figure><p>修饰到 class 上更灵活一些，可以 Weekday.Tue 或者 Weekday[‘Tue’] 或者 Weekday(2)</p><h3 id="metaclass"><a href="#metaclass" class="headerlink" title="metaclass"></a>metaclass</h3><blockquote><p>Ambari agent 代码的核心就是基于元类搞的</p></blockquote><p>作用：定义 metaclass 再创建类<br>暂时不多说吧，现在工作根本用不上这么高大上的东东</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><h3 id="try-except-finally"><a href="#try-except-finally" class="headerlink" title="try except finally"></a>try except finally</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    print(&#x27;try...&#x27;)</span><br><span class="line">    r = 10 / 0</span><br><span class="line">    print(&#x27;result:&#x27;, r)</span><br><span class="line">except ZeroDivisionError as e:</span><br><span class="line">    print(&#x27;except:&#x27;, e)</span><br><span class="line">finally:</span><br><span class="line">    print(&#x27;finally...&#x27;)</span><br></pre></td></tr></table></figure><h3 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h3><p>报错的时候会按照调用栈挨个抛到上一个调用，直到被 except，要不就 exit 了</p><h3 id="错误类型"><a href="#错误类型" class="headerlink" title="错误类型"></a>错误类型</h3><p>所有 Exception 都是 BaseException 的子类<br>捕获异常时，需要注意 except 顺序<br>因为一旦一个 exception 是另一个的子类，写到前面的捕获父类会永远捕获这个子类，有时就走不到自己期望的代码块里了</p><h2 id="单测"><a href="#单测" class="headerlink" title="单测"></a>单测</h2><p>基于 import unittest<br>测试类都是 unittest.TestCase 的子类</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import unittest</span><br><span class="line"></span><br><span class="line">from mydict import Dict</span><br><span class="line"></span><br><span class="line">class TestDict(unittest.TestCase):</span><br><span class="line">    def test_init(self):</span><br><span class="line">        d = Dict(a=1, b=&#x27;test&#x27;)</span><br><span class="line">        self.assertEqual(d.a, 1)</span><br><span class="line">        self.assertEqual(d.b, &#x27;test&#x27;)</span><br><span class="line">        self.assertTrue(isinstance(d, dict))</span><br><span class="line"></span><br><span class="line">    def test_key(self):</span><br><span class="line">        d = Dict()</span><br><span class="line">        d[&#x27;key&#x27;] = &#x27;value&#x27;</span><br><span class="line">        self.assertEqual(d.key, &#x27;value&#x27;)</span><br><span class="line"></span><br><span class="line">    def test_attr(self):</span><br><span class="line">        d = Dict()</span><br><span class="line">        d.key = &#x27;value&#x27;</span><br><span class="line">        self.assertTrue(&#x27;key&#x27; in d)</span><br><span class="line">        self.assertEqual(d[&#x27;key&#x27;], &#x27;value&#x27;)</span><br><span class="line"></span><br><span class="line">    def test_keyerror(self):</span><br><span class="line">        d = Dict()</span><br><span class="line">        with self.assertRaises(KeyError):</span><br><span class="line">            value = d[&#x27;empty&#x27;]</span><br><span class="line"></span><br><span class="line">    def test_attrerror(self):</span><br><span class="line">        d = Dict()</span><br><span class="line">        with self.assertRaises(AttributeError):</span><br><span class="line">            value = d.empty</span><br></pre></td></tr></table></figure><p>运行采用如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    unittest.main()</span><br></pre></td></tr></table></figure><p>这样可以直接 python mydict_test.py 来运行单测；<br>推荐是 python -m mydict_test,mydict_test2，这样可以一次批量执行一堆单测文件，更高效一点</p><h3 id="setup-和-teardown"><a href="#setup-和-teardown" class="headerlink" title="setup 和 teardown"></a>setup 和 teardown</h3><p>编写 bmr-canary 时写过几百遍了，挺好用的单测代码模式<br>当一个继承了 unittest.TestCase 的类实现了这两个方法，分别会在执行前后执行完成后执行这俩方法</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go using slice concurrent gracefully</title>
      <link href="/2025/03/09/Go-using-slice-concurrent-gracefully/"/>
      <url>/2025/03/09/Go-using-slice-concurrent-gracefully/</url>
      
        <content type="html"><![CDATA[<p>go 1.9 引入了 sync.Map ，标准库里支持了并发安全的 map，但是没有并发安全的 slice，需要我们自己实现。</p><h2 id="笨笨方案：加锁"><a href="#笨笨方案：加锁" class="headerlink" title="笨笨方案：加锁"></a>笨笨方案：加锁</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">slc := make([]int, 0, 1000)</span><br><span class="line">var wg sync.WaitGroup</span><br><span class="line">var lock sync.Mutex</span><br><span class="line"></span><br><span class="line">for i := 0; i &lt; 1000; i++ &#123;</span><br><span class="line">wg.Add(1)</span><br><span class="line">go func(a int) &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">      // 加锁</span><br><span class="line">lock.Lock()</span><br><span class="line">defer lock.Unlock()</span><br><span class="line">slc = append(slc, a)</span><br><span class="line">&#125;(i)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">   wg.Wait()</span><br><span class="line">fmt.Println(len(slc))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>适合：性能要求不高的场景，谁都能想到的方法</p><h2 id="优雅方案：channel-串行化操作"><a href="#优雅方案：channel-串行化操作" class="headerlink" title="优雅方案：channel 串行化操作"></a>优雅方案：channel 串行化操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">type ServiceData struct &#123;</span><br><span class="line">ch   chan int // 用来 同步的channel</span><br><span class="line">data []int    // 存储数据的slice</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s *ServiceData) Schedule() &#123;</span><br><span class="line">// 从 channel 接收数据</span><br><span class="line">for i := range s.ch &#123;</span><br><span class="line">s.data = append(s.data, i)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s *ServiceData) Close() &#123;</span><br><span class="line">// 最后关闭 channel</span><br><span class="line">close(s.ch)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s *ServiceData) AddData(v int) &#123;</span><br><span class="line">s.ch &lt;- v // 发送数据到 channel</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func NewScheduleJob(size int, done func()) *ServiceData &#123;</span><br><span class="line">s := &amp;ServiceData&#123;</span><br><span class="line">ch:   make(chan int, size),</span><br><span class="line">data: make([]int, 0),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">go func() &#123;</span><br><span class="line">// 并发地 append 数据到 slice</span><br><span class="line">s.Schedule()</span><br><span class="line">done()</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">return s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">var (</span><br><span class="line">wg sync.WaitGroup</span><br><span class="line">n  = 1000</span><br><span class="line">)</span><br><span class="line">c := make(chan struct&#123;&#125;)</span><br><span class="line"></span><br><span class="line">// new 了这个 job 后，该 job 就开始准备从 channel 接收数据了</span><br><span class="line">s := NewScheduleJob(n, func() &#123; c &lt;- struct&#123;&#125;&#123;&#125; &#125;)</span><br><span class="line"></span><br><span class="line">wg.Add(n)</span><br><span class="line">for i := 0; i &lt; n; i++ &#123;</span><br><span class="line">go func(v int) &#123;</span><br><span class="line">defer wg.Done()</span><br><span class="line">s.AddData(v)</span><br><span class="line"></span><br><span class="line">&#125;(i)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">wg.Wait()</span><br><span class="line">s.Close()</span><br><span class="line">&lt;-c</span><br><span class="line"></span><br><span class="line">fmt.Println(len(s.data))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>适合：性能要求高一些的场景，利用了 channel 优势</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go map usage</title>
      <link href="/2025/03/08/Go-map-usage/"/>
      <url>/2025/03/08/Go-map-usage/</url>
      
        <content type="html"><![CDATA[<h2 id="不要依赖遍历-map-所得到的元素顺序"><a href="#不要依赖遍历-map-所得到的元素顺序" class="headerlink" title="不要依赖遍历 map 所得到的元素顺序"></a>不要依赖遍历 map 所得到的元素顺序</h2><p>go runtime 在初始化 map 迭代器时对起始位置做了随机处理，导致不同次的 for range 遍历返回顺序不同。</p><h2 id="尽可能使用-v-ok-map-key"><a href="#尽可能使用-v-ok-map-key" class="headerlink" title="尽可能使用 v, ok :&#x3D; map[key]"></a>尽可能使用 v, ok :&#x3D; map[key]</h2><p>读取 key 不存在的值不会报错，而是返回0值，这可能会造成错误</p><h2 id="删除不存在的-key，不会-panic"><a href="#删除不存在的-key，不会-panic" class="headerlink" title="删除不存在的 key，不会 panic"></a>删除不存在的 key，不会 panic</h2><p>所以一般先 v, ok 判断是不是存在,再根据内容进行 delete</p><h2 id="使用-len-map-获取-map-k-v-数量"><a href="#使用-len-map-获取-map-k-v-数量" class="headerlink" title="使用 len(map)获取 map k-v 数量"></a>使用 len(map)获取 map k-v 数量</h2><p>时间复杂度是 O(1) 的</p><h2 id="hmap-是-map-类型的-header，存储了后续-map-类型操作所需的所有信息。代表了-map-的描述符"><a href="#hmap-是-map-类型的-header，存储了后续-map-类型操作所需的所有信息。代表了-map-的描述符" class="headerlink" title="hmap 是 map 类型的 header，存储了后续 map 类型操作所需的所有信息。代表了 map 的描述符"></a>hmap 是 map 类型的 header，存储了后续 map 类型操作所需的所有信息。代表了 map 的描述符</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// A header for a Go map.</span><br><span class="line">type hmap struct &#123;</span><br><span class="line">   // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go.</span><br><span class="line"> // Make sure this stays in sync with the compiler&#x27;s definition.</span><br><span class="line"> count int // # live cells == size of map. Must be first (used by len() builtin)</span><br><span class="line"> flags uint8</span><br><span class="line"> B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items)</span><br><span class="line"> noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> hash0 uint32 // hash seed</span><br><span class="line"> buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0.</span><br><span class="line"> oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing</span><br><span class="line"> nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> extra *mapextra // optional fields</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>count ：map 中的元素个数，len() 返回的就是 count 值</li><li>flags ：map 所处的状态，有 iterator oldIterator hashWriting sameSizeGrow 四种状态</li><li>B ：bucket 数量以2为底的对数， 2^B &#x3D; bucket 数</li><li>noverflow ：overflow bucket 的大约数量</li><li>hash0 ：哈希函数种子值</li><li>buckets ：指向 bucket 数组的指针</li><li>oldBuckets ：map 扩容阶段指向前一个 bucket 数组的指针</li><li>nevacuate ：在 map 扩容阶段充当扩容进度计数器。所有下标小于 nevacuate 的 bucket 都已经完成了数据排空和迁移</li><li>extra ：可选字段，如果有 overflow bucket 存在，且 key value 都因不包含指针而被内联的情况下，extra 存储所有指向 overflow bucket 的指针，保证 overflow bucket 始终可用(不被 gc)</li></ol><h2 id="bucket-内部结构"><a href="#bucket-内部结构" class="headerlink" title="bucket 内部结构"></a>bucket 内部结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bucket[0] bucket[1] bucket[xxx]...</span><br><span class="line">tophash[0] tophash[0] ...</span><br><span class="line">tophash[1] tophash[1] ...</span><br><span class="line">key[0] key[0] ...</span><br><span class="line">key[1] key[1] ...</span><br><span class="line">value[0] value[0] ...</span><br><span class="line">... ... ...</span><br><span class="line">overflow overflow ...</span><br></pre></td></tr></table></figure><p>默认 bucket 数为8，当某个 bucket 的 8 个 slot 都有值且 map 还没达到扩容条件时，运行时会建立 overflow bucket，并将该 overflow bucket 挂在上面 bucket 末尾的 overflow 指针上，此时两个 bucket 形成了链表，这个结构将持续到下一次 map 扩容。</p><ol><li>tophash<br>对 key 的 hashcode 进行两分，低位区用于选定 bucket，高位区用于在某个 bucket 中确定 key 的位置。所以每个 bucket 中的 tophash 是用于快速定位 key 位置——空间换时间。</li><li>key<br>tophash 下面是一片连续内存区域，存储所有 key。<br>Q : runtime 怎么知道 key 的大小呢？<br>A : 声明 map 变量时，runtime 根据 map 的数据类型生产 maptype 实例，编译时会将所有 map 的操作重写成 runtime 对应的函数调用，这些函数的一个参数都是 maptype 的指针类型。<br>也就是说，go runtime 是根据 maptype 中的信息确定 key 类型和大小。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">type maptype struct &#123;</span><br><span class="line">   typ _type</span><br><span class="line"> key *_type</span><br><span class="line"> elem *_type</span><br><span class="line"> bucket *_type // internal type representing a hash bucket</span><br><span class="line"> // function for hashing keys (ptr to key, seed) -&gt; hash</span><br><span class="line"> hasher func(unsafe.Pointer, uintptr) uintptr</span><br><span class="line"> keysize uint8 // size of key slot</span><br><span class="line"> elemsize uint8 // size of elem slot</span><br><span class="line"> bucketsize uint16 // size of bucket</span><br><span class="line"> flags uint32</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>value<br>value 区域是连续的内存。<br>分开 key value 存储，而不是 kv 相邻的存储，带来了算法的复杂性，但是减少了内存对齐带来的浪费。<br>key 或 value 的数据长度大于一定数值时，runtime 不会在 bucket 直接存储，而是存储 key value 的指针。<br>当前最大值为：<br>maxKeySize &#x3D; 128<br>maxElemSize &#x3D; 128</li></ol><h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><p>指扩充 bucket 数量，并重新在 buckets 之间分配数据。</p><h3 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h3><p>count &gt; loadFactor * 2^B 或者 overflow bucket 过多。 默认的 loadFactor 是 6.5 (factorNum 13&#x2F; factorDen 2)</p><h3 id="因-overflow-bucket-过多而扩容"><a href="#因-overflow-bucket-过多而扩容" class="headerlink" title="因 overflow bucket 过多而扩容"></a>因 overflow bucket 过多而扩容</h3><p>新建一个和当前规模相同的 bucket 数组，然后在 map 进行插入和删除操作时进行排空和迁移。</p><h3 id="因-loadfactor-超过水位"><a href="#因-loadfactor-超过水位" class="headerlink" title="因 loadfactor 超过水位"></a>因 loadfactor 超过水位</h3><p>新建一个两倍当前规模的 bucket 数组，原 bucket 数组会挂在 hmap 的 oldBuckets 指针下面，直到原 buckets 数组中所有数据都 assign 和 delete 到新数组，源 Bucket 数组才释放。<br>本质上的迁移和排空，同7.1一样，是在之后对 map 的 assign &amp; delele 的操作的时候进行的。</p><h2 id="map-与-并发"><a href="#map-与-并发" class="headerlink" title="map 与 并发"></a>map 与 并发</h2><p>hmap 本身是有状态的，通过 hmap.flags 记录。<br>同时对 map 进行并发读写会触发 panic，只对 map 进行并发读是没有问题的。<br>如果想要使用并发写安全的，使用 sync.Map 类型<br>因为 map 可以自动扩容，map 中 value 是可能变化的，所以不能获取 map 中 value 的地址，这个约束在编译期间就生效。</p><h2 id="尽量使用-cap-参数创建-map"><a href="#尽量使用-cap-参数创建-map" class="headerlink" title="尽量使用 cap 参数创建 map"></a>尽量使用 cap 参数创建 map</h2><p>如果可能的话，对 map 的初始规模进行粗略估算，使用 cap 初始化 map 会减少 map 的频繁扩容次数，频繁扩容会降低 map 的性能。</p><h2 id="map-的-key"><a href="#map-的-key" class="headerlink" title="map 的 key"></a>map 的 key</h2><p>map的key必须支持相等运算符（&#x3D;&#x3D;、!&#x3D;）<br>go里面不支持运算符的数据类型：func、slice、map，所以不能用这三种类型作为map的key<br>一个场景：<br>math.NaN()作为map的key，因为NaN每次hash的结果都不一样，所以用NaN作为key保存的数据读取不出，并且每保存一次都会多一个NaN作为key的数据。<br>总结：func、slice、map 不能作为map的key， math.NaN()不要作为map的key</p><h2 id="map-的-value"><a href="#map-的-value" class="headerlink" title="map 的 value"></a>map 的 value</h2><p>map 是不可寻址的（not addressable），如果用结构体作为map的value，不能直接修改value的字段值。<br>解决办法有：</p><ol><li>重新给key赋值一个新的结构体</li><li>用结构体指针做map的value</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go test</title>
      <link href="/2025/03/08/Go-test/"/>
      <url>/2025/03/08/Go-test/</url>
      
        <content type="html"><![CDATA[<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p>单元测试文件都以_test.go 结尾，这样 go 编译器会在执行 go test xxx 命令时找到_test.go 结尾文件的</p><p>Test + 大写(t *testing.T)<br>Test_函数名(t *testing.T)<br>并认为这种函数是单元测试函数</p><h3 id="包名"><a href="#包名" class="headerlink" title="包名"></a>包名</h3><p>package s1<br>package s1_test<br>两种都可以</p><h3 id="表格驱动"><a href="#表格驱动" class="headerlink" title="表格驱动"></a>表格驱动</h3><p>用 VSCODE 可以直接右键 generate unit case test file<br>可以使用很多的 case</p><h3 id="单独找出失败的单元测试结果"><a href="#单独找出失败的单元测试结果" class="headerlink" title="单独找出失败的单元测试结果"></a>单独找出失败的单元测试结果</h3><p>使用 github rakyll&#x2F;gotest 库<br>go install github.com&#x2F;rakyll&#x2F;gotest@latest<br>以前可能用 go test -v . 来执行单元测试<br>现在用 gotest -v .来执行，可以发现失败的为红色，更突出的显示了单测结果</p><h3 id="golden-file"><a href="#golden-file" class="headerlink" title="golden file"></a>golden file</h3><p>利用专门的测试文件来存储 case 的用例，然后统一执行和跟这个文件进行比较</p><h2 id="什么是-testing-T"><a href="#什么是-testing-T" class="headerlink" title="什么是 testing.T"></a>什么是 testing.T</h2><p>testing.T 和 testing.B interface<br>testing.T 的一些方法：<br>Fail（失败之后继续执行）&#x2F;FailNow（失败之后立马返回，后面不执行）&#x2F;Failed（）&#x2F;Fatal（先输出一行日志，再标记为失败返回）&#x2F;Fatalf（按格式化输出日志）<br>Log&#x2F;Logf&#x2F;Error（LOG + FAILNOW）&#x2F;Errorf<br>Skip&#x2F;SkipNow&#x2F;Skipf&#x2F;Skipped<br>Helper 辅助<br>Parallel 并行运行 case，在 Run 里面执行 t.Parallel()</p><p>TestMain 测试套件<br>testing.M<br>func TestMain(m *testing.M) {<br>log.Printf(“before test main”)<br>m.Run()<br>log.Printf(“after test main”)<br>}<br>运行 go test -run .<br>会利用这个测试函数去做一些准备的工作，m.Run 代表全部执行，执行之后我们再清理。</p><h2 id="go-test-命令"><a href="#go-test-命令" class="headerlink" title="go test 命令"></a>go test 命令</h2><p>详细的自己执行一下 go help test 就行了<br>这里写一下我经常用的命令参数<br>go test<br>-count n 指定执行几遍，benchmark 来指定看看效果<br>-json 结果用 json 呈现<br>-list 正则查询包下面有哪些单测函数<br>-parallel n 指定并发度<br>-run 正则来过滤一些单测函数<br>-short 短测试，减少测试时间<br>-timeout 指定测试时间，最多多少，默认10min，比如-timeout 3s<br>-v 打印详细输出<br>-vet list 指定执行单测前检查哪些项</p><h2 id="代码覆盖率"><a href="#代码覆盖率" class="headerlink" title="代码覆盖率"></a>代码覆盖率</h2><p>把某个目录下面的代码覆盖统计数字导出到 cover.out，但不太直观<br>go test -coverprofile cover.out .&#x2F;…</p><p>把某个目录下面的代码覆盖统计数字导出到 html 文件，相对清晰，使用 open cover.html 打开这个文件<br>go tool cover -html&#x3D;cover.out -o cover.html</p><p>通过这个命令将生成 html 的背景色改成白色<br>go tool cover -o cover2.html -html&#x3D;cover.out;sed -i ‘s&#x2F;black&#x2F;whitesmoke&#x2F;g’ cover2.html; open cover2.html</p><p>生成 treemap 的图片，绿色代表覆盖高的，红色代表覆盖低<br>go install github.com&#x2F;&#x2F;nikolaydubina&#x2F;go-cover-treemap@latest<br>go-cover-treemap -coverprofile cover.out &gt; out.svg</p><blockquote><p>加了包名之后可以 cached 这次的覆盖率，不使用 cached 的时候在 go test -count&#x3D;1，每次都从新看覆盖率</p></blockquote><h2 id="单测里怎么-mock-各种对象"><a href="#单测里怎么-mock-各种对象" class="headerlink" title="单测里怎么 mock 各种对象"></a>单测里怎么 mock 各种对象</h2><h3 id="goconvey"><a href="#goconvey" class="headerlink" title="goconvey"></a>goconvey</h3><p>断言框架,我喜欢嵌套的和他的嵌套展示</p><h3 id="gomonkey"><a href="#gomonkey" class="headerlink" title="gomonkey"></a>gomonkey</h3><p>比较好用,但是目前没法 mock private function return,有点吐血</p><h3 id="go-sqlite-来模拟-gorm-实例"><a href="#go-sqlite-来模拟-gorm-实例" class="headerlink" title="go sqlite 来模拟 gorm 实例"></a>go sqlite 来模拟 gorm 实例</h3><p>很经典的 teardown 代码,保存一下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">func MockDB() string &#123;</span><br><span class="line">    tempDBFile, err := os.CreateTemp(&quot;&quot;, &quot;*.db&quot;)</span><br><span class="line">utDB, err := gorm.Open(sqlite.Open(tempDBFile.Name()), &amp;gorm.Config&#123;</span><br><span class="line">Logger: logger.Default.LogMode(logger.Silent),</span><br><span class="line">&#125;)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">panic(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">database.DB = utDB</span><br><span class="line"></span><br><span class="line">err = utDB.AutoMigrate(</span><br><span class="line">// 一堆自己定义的 orm struct 的指针</span><br><span class="line">)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">panic(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return tempDBFile.Name() // 返回的是临时 sqlite 的目录</span><br><span class="line">&#125;</span><br><span class="line">// 实际单测使用中</span><br><span class="line">func TestXXX(t *testing.T) &#123;</span><br><span class="line">    path := MockDB()</span><br><span class="line">    defer os.Remove(path)</span><br><span class="line">    // 具体的单测</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go omitempty</title>
      <link href="/2025/03/07/Go-omitempty/"/>
      <url>/2025/03/07/Go-omitempty/</url>
      
        <content type="html"><![CDATA[<h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>主要是配合 marshall 和 unmarshall 来使用.<br>举个例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">type address struct &#123;</span><br><span class="line">Street  string `json:&quot;street&quot;`  // 街道</span><br><span class="line">Ste     string `json:&quot;suite&quot;`   // 单元（可以不存在）</span><br><span class="line">City    string `json:&quot;city&quot;`    // 城市</span><br><span class="line">State   string `json:&quot;state&quot;`   // 州/省</span><br><span class="line">Zipcode string `json:&quot;zipcode&quot;` // 邮编</span><br><span class="line">&#125;</span><br><span class="line">func main() &#123;</span><br><span class="line">  data := `&#123;</span><br><span class="line">&quot;street&quot;: &quot;200 Larkin St&quot;,</span><br><span class="line">&quot;city&quot;: &quot;San Francisco&quot;,</span><br><span class="line">&quot;state&quot;: &quot;CA&quot;,</span><br><span class="line">&quot;zipcode&quot;: &quot;94102&quot;</span><br><span class="line">&#125;`</span><br><span class="line">addr := new(address)</span><br><span class="line">json.Unmarshal([]byte(data), &amp;addr)</span><br><span class="line"></span><br><span class="line">        // 处理了一番 addr 变量...</span><br><span class="line"></span><br><span class="line">addressBytes, _ := json.MarshalIndent(addr, &quot;&quot;, &quot;    &quot;)</span><br><span class="line">fmt.Printf(&quot;%s\n&quot;, string(addressBytes))</span><br><span class="line">&#125;</span><br><span class="line">/** 结果</span><br><span class="line">&#123;</span><br><span class="line">    &quot;street&quot;: &quot;200 Larkin St&quot;,</span><br><span class="line">    &quot;suite&quot;: &quot;&quot;,</span><br><span class="line">    &quot;city&quot;: &quot;San Francisco&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;CA&quot;,</span><br><span class="line">    &quot;zipcode&quot;: &quot;94102&quot;</span><br><span class="line">&#125;</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>omitempty 表示在这条信息如果没有提供，序列化 json 的时候就不包含默认值了</p><h2 id="陷阱"><a href="#陷阱" class="headerlink" title="陷阱"></a>陷阱</h2><h3 id="无法忽略嵌套结构体"><a href="#无法忽略嵌套结构体" class="headerlink" title="无法忽略嵌套结构体"></a>无法忽略嵌套结构体</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">type address struct &#123;</span><br><span class="line">Street     string     `json:&quot;street&quot;`</span><br><span class="line">Ste        string     `json:&quot;suite,omitempty&quot;`</span><br><span class="line">City       string     `json:&quot;city&quot;`</span><br><span class="line">State      string     `json:&quot;state&quot;`</span><br><span class="line">Zipcode    string     `json:&quot;zipcode&quot;`</span><br><span class="line">Coordinate coordinate `json:&quot;coordinate,omitempty&quot;`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type coordinate struct &#123;</span><br><span class="line">Lat float64 `json:&quot;latitude&quot;`</span><br><span class="line">Lng float64 `json:&quot;longitude&quot;`</span><br><span class="line">&#125;</span><br><span class="line">/** 结果依旧有零值</span><br><span class="line">&#123;</span><br><span class="line">    &quot;street&quot;: &quot;200 Larkin St&quot;,</span><br><span class="line">    &quot;city&quot;: &quot;San Francisco&quot;,</span><br><span class="line">    &quot;state&quot;: &quot;CA&quot;,</span><br><span class="line">    &quot;zipcode&quot;: &quot;94102&quot;,</span><br><span class="line">    &quot;coordinate&quot;: &#123;</span><br><span class="line">        &quot;latitude&quot;: 0,</span><br><span class="line">        &quot;longitude&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>即使在 address 中对 coordinate 加了 omitempty，实际 json unmarshall 的时候还是会带上空坐标信息</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>为了达到我们想要的效果，可以把坐标定义为指针类型，这样 Golang 就能知道一个指针的“空值”是多少了，否则面对一个我们自定义的结构， Golang 是猜不出我们想要的空值的。于是有了如下的结构体定义</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">type address struct &#123;</span><br><span class="line">Street     string      `json:&quot;street&quot;`</span><br><span class="line">Ste        string      `json:&quot;suite,omitempty&quot;`</span><br><span class="line">City       string      `json:&quot;city&quot;`</span><br><span class="line">State      string      `json:&quot;state&quot;`</span><br><span class="line">Zipcode    string      `json:&quot;zipcode&quot;`</span><br><span class="line">Coordinate *coordinate `json:&quot;coordinate,omitempty&quot;`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type coordinate struct &#123;</span><br><span class="line">Lat float64 `json:&quot;latitude&quot;`</span><br><span class="line">Lng float64 `json:&quot;longitude&quot;`</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">“street”: “200 Larkin St”,</span><br><span class="line">“city”: “San Francisco”,</span><br><span class="line">“state”: “CA”,</span><br><span class="line">“zipcode”: “94102”</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="当-omitempty-表示的字段赋值恰好为空值时，这个字段将不会展示"><a href="#当-omitempty-表示的字段赋值恰好为空值时，这个字段将不会展示" class="headerlink" title="当 omitempty 表示的字段赋值恰好为空值时，这个字段将不会展示"></a>当 omitempty 表示的字段赋值恰好为空值时，这个字段将不会展示</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">type coordinate struct &#123;</span><br><span class="line">Lat float64 `json:&quot;latitude,omitempty&quot;`</span><br><span class="line">Lng float64 `json:&quot;longitude,omitempty&quot;`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">cData := `&#123;</span><br><span class="line">&quot;latitude&quot;: 0.0,</span><br><span class="line">&quot;longitude&quot;: 0.0</span><br><span class="line">&#125;`</span><br><span class="line">c := new(coordinate)</span><br><span class="line">json.Unmarshal([]byte(cData), &amp;c)</span><br><span class="line"></span><br><span class="line">        // 具体处理逻辑...</span><br><span class="line"></span><br><span class="line">coordinateBytes, _ := json.MarshalIndent(c, &quot;&quot;, &quot;    &quot;)</span><br><span class="line">fmt.Printf(&quot;%s\n&quot;, string(coordinateBytes)) // 结果是 &#123;&#125;, 可我希望是有零值的</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解决方案也是将这两个字段类型变成 *float64, 这样marshal 出就是0值了</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go new and make</title>
      <link href="/2025/03/06/Go-new-and-make/"/>
      <url>/2025/03/06/Go-new-and-make/</url>
      
        <content type="html"><![CDATA[<p>new 是对任何对象的内存分配,分配完内存后把指向的地址返回回来<br>make 是专门对 slice map chan 类型进行内存分配和初始化</p><p>举个例子<br>当 new([]int)的时候，是不能给他直接赋值的,会报下面的错误</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">func TestSetBmz(t *testing.T) &#123;</span><br><span class="line">a := new([]int)</span><br><span class="line">(*a)[0] = 1</span><br><span class="line">fmt.Printf(&quot;%v&quot;, a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 报错</span><br><span class="line">=== RUN   TestSetBmz</span><br><span class="line">--- FAIL: TestSetBmz (0.00s)</span><br><span class="line">panic: runtime error: index out of range [0] with length 0 [recovered]</span><br><span class="line">panic: runtime error: index out of range [0] with length 0</span><br></pre></td></tr></table></figure><p>也就是说，new 只管内存分配，不管引用对象的初始化<br>这也引申出来：当对自定义的类型指针进行赋值，如果没有 new 这个对象直接赋值，是会 panic 的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">type Student struct &#123;</span><br><span class="line">name string</span><br><span class="line">age  int</span><br><span class="line">&#125;</span><br><span class="line">var s *Student</span><br><span class="line">s = new(Student) // 缺少这步就会 panic</span><br><span class="line">s.name = &quot;bie&quot;</span><br><span class="line">   fmt.Println(s)</span><br></pre></td></tr></table></figure><p>当没有 s &#x3D; new(Student) 这一行时,会 panic 出现 NPE</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">panic: runtime error: invalid memory address or nil pointer dereference [recovered]</span><br><span class="line">panic: runtime error: invalid memory address or nil pointer dereference</span><br><span class="line">[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x50ae7a]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go func as first class citizen</title>
      <link href="/2025/03/05/Go-func-as-first-class-citizen/"/>
      <url>/2025/03/05/Go-func-as-first-class-citizen/</url>
      
        <content type="html"><![CDATA[<p>谓一等公民，就是指我们可以像对待值一样去对待某个语法。拥有一等公民待遇的语法元素会被存储在变量中，可以传递、在函数内部创建或作为返回值。动态型语言还支持一等公民的类型检查。<br>函数可以正常创建 func xxx() {}<br>一等公民能干嘛呢?我们列一下</p><h2 id="函数可以在函数内创建"><a href="#函数可以在函数内创建" class="headerlink" title="函数可以在函数内创建"></a>函数可以在函数内创建</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">func TestSomeFunc(t *testing.T)  &#123;</span><br><span class="line">   p := func(x int) &#123;</span><br><span class="line">      fmt.Println(x)</span><br><span class="line">   &#125;</span><br><span class="line">   p(2)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="作为类型"><a href="#作为类型" class="headerlink" title="作为类型"></a>作为类型</h2><p>type HandlerFunc func(x int)</p><h2 id="存储到变量中"><a href="#存储到变量中" class="headerlink" title="存储到变量中"></a>存储到变量中</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">type BMZ struct &#123;</span><br><span class="line">    Handler func(x int)</span><br><span class="line">&#125;</span><br><span class="line">func TestXXX(t *testing.T) &#123;</span><br><span class="line">    bmz := BMZ&#123;&#125;</span><br><span class="line">    p := func(x int) &#123;</span><br><span class="line">        fmt.Println(x)</span><br><span class="line">    &#125;</span><br><span class="line">    bmz.Handler = p</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="作为传参和返回值"><a href="#作为传参和返回值" class="headerlink" title="作为传参和返回值"></a>作为传参和返回值</h2><p>这个不用多说了吧…</p><h2 id="除了作为基本成员之外的特殊用法"><a href="#除了作为基本成员之外的特殊用法" class="headerlink" title="除了作为基本成员之外的特殊用法"></a>除了作为基本成员之外的特殊用法</h2><p>除了可以像普通值一样被创建和使用外,当然这里也有一些特殊用法,很有意思</p><h3 id="对函数进行显示转换"><a href="#对函数进行显示转换" class="headerlink" title="对函数进行显示转换"></a>对函数进行显示转换</h3><p>Go 标准库 http 包里经典的使用,定义一个 type xxx func ，xxx 实现某个接口，之后可以直接用 xxx(otherFunc) 的方式 将其他 func 显示转化成实现这个接口的 func。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type HandleFunc func(ResponseWriter, *Request)</span><br><span class="line">server.ListenAndServe()</span><br></pre></td></tr></table></figure><h3 id="函数化编程"><a href="#函数化编程" class="headerlink" title="函数化编程"></a>函数化编程</h3><h4 id="柯里化"><a href="#柯里化" class="headerlink" title="柯里化"></a>柯里化</h4><p>把接收的多个参数转换成接收一个单一参数的函数，并返回接收余下的参数和返回结果。<br>可以使用闭包来实现柯里化。<br>闭包是函数内部定义的匿名函数，并且允许该匿名函数访问定义它外部的变量。</p><h4 id="函子"><a href="#函子" class="headerlink" title="函子"></a>函子</h4><p>本身是一个容器类型（slice map channel），容器需要实现一个方法，该方法接收一个函数类型参数，并在容器的每个元素上应用哪个函数，得到一个新函子，原函子内部的元素值不受影响。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">func TestSomeFunc(t *testing.T)  &#123;</span><br><span class="line">   sl1 := []int&#123;1,2,3,4&#125;</span><br><span class="line">   f := intSliceFunctorImpl1&#123;sl: sl1&#125;</span><br><span class="line">   fmt.Printf(&quot;origin sl : %v\n&quot;, f.sl)</span><br><span class="line">   mapperFunc1 := func(x int) int &#123;</span><br><span class="line">      return x + 10</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   mapperFunc2 := func(x int) int &#123;</span><br><span class="line">      return x * x</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   map1 := f.F1(mapperFunc1)</span><br><span class="line">   fmt.Printf(&quot;map1 : %v\n&quot;, map1)</span><br><span class="line">   map2 := map1.F1(mapperFunc2)</span><br><span class="line">   fmt.Printf(&quot;map2 : %v\n&quot;, map2)</span><br><span class="line">   fmt.Printf(&quot;origin slice : %v\n&quot;, sl1)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type IntSliceFactor interface &#123;</span><br><span class="line">   F1(fn func(int) int) IntSliceFactor</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type intSliceFunctorImpl1 struct &#123;</span><br><span class="line">   sl []int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (i intSliceFunctorImpl1) F1(fn func(int) int) IntSliceFactor &#123;</span><br><span class="line">   newInts := make([]int, len(i.sl))</span><br><span class="line">   for i, v := range i.sl &#123;</span><br><span class="line">      tmp := fn(v)</span><br><span class="line">      newInts[i] = tmp</span><br><span class="line"> &#125;</span><br><span class="line">   return intSliceFunctorImpl1&#123;sl: newInts&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结果是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">origin sl : [1 2 3 4]</span><br><span class="line">map1 : &#123;[11 12 13 14]&#125;</span><br><span class="line">map2 : &#123;[121 144 169 196]&#125;</span><br><span class="line">origin slice : [1 2 3 4]</span><br></pre></td></tr></table></figure><p>稍微解释一下：<br>函子是 IntSliceFactor 接口，intSliceFunctorImpl1 是函子的载体。F1函数就是函子要实现的方法。自己在 main 方法里实现的匿名函数作为转换函数，并将其作为参数传入 f1方法中，达到了函子的目的：计算每个容器的内容并返回新容器，老容器中的容器不受影响。同时返回的新容器也可以继续应用新的函数，继续转化容器。<br>函子非常适合用来对容器集合元素进行批量同构处理，而且代码也比每次对容器中的元素进行遍历优雅简洁很多。</p><blockquote><p>PS: 在 GO 1.18泛型支持后，函子的优势将被放大。没有泛型，代表每种容器都实现一套 Functor 机制，有了泛型，则可以使用一个函子定义来转化多种类型的容器。</p></blockquote><h4 id="延续式传递"><a href="#延续式传递" class="headerlink" title="延续式传递"></a>延续式传递</h4><p>在递归的函数中使用 ： 去掉一个 func1 函数的返回值，在传参中传入一个func2，传参和返回值与 func1一样，func2 作为递归时的使用。举一个阶乘的例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">func TestSomeFunc(t *testing.T)  &#123;</span><br><span class="line">   factorial(5, func(y int) &#123;</span><br><span class="line">      fmt.Printf(&quot;res:= %d \n&quot;, y)</span><br><span class="line">   &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func factorial(n int, f func(int))&#123;</span><br><span class="line">   if n == 1 &#123;</span><br><span class="line">      f(1)</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">      factorial(n-1, func(y int) &#123;</span><br><span class="line">         f(n * y)</span><br><span class="line">      &#125;)</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>深刻理解 Go 的语言哲学,不要为了符合某些编码特点风格而滥用函数特质</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go ab ba</title>
      <link href="/2025/03/05/Go-ab-ba/"/>
      <url>/2025/03/05/Go-ab-ba/</url>
      
        <content type="html"><![CDATA[<h2 id="不会真正实际对象值，只会在函数内交换"><a href="#不会真正实际对象值，只会在函数内交换" class="headerlink" title="不会真正实际对象值，只会在函数内交换"></a>不会真正实际对象值，只会在函数内交换</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">func TestSetBmz(t *testing.T) &#123;</span><br><span class="line">a := make(Set)</span><br><span class="line">a.Add(1)</span><br><span class="line">a.Add(2)</span><br><span class="line">a.Add(3)</span><br><span class="line">b := make(Set)</span><br><span class="line">b.Add(&quot;bie&quot;)</span><br><span class="line">b.Add(1)</span><br><span class="line">    // 前后结果一致</span><br><span class="line">fmt.Printf(&quot;a: %v, b: %v\n&quot;, a.List(), b.List())</span><br><span class="line">a.change(b)</span><br><span class="line">fmt.Printf(&quot;a: %v, b: %v\n&quot;, a.List(), b.List())</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s Set) change(other Set) &#123;</span><br><span class="line">fmt.Printf(&quot;self : %v, other : %v\n&quot;, s.List(), other.List())</span><br><span class="line">s, other = other, s</span><br><span class="line">fmt.Printf(&quot;self : %v, other : %v\n&quot;, s.List(), other.List())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="会真正交换实际对象值"><a href="#会真正交换实际对象值" class="headerlink" title="会真正交换实际对象值"></a>会真正交换实际对象值</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">func TestSetBmz(t *testing.T) &#123;</span><br><span class="line">a := make(Set)</span><br><span class="line">a.Add(1)</span><br><span class="line">a.Add(2)</span><br><span class="line">a.Add(3)</span><br><span class="line">b := make(Set)</span><br><span class="line">b.Add(&quot;bie&quot;)</span><br><span class="line">b.Add(1)</span><br><span class="line">    // 实际结果 a b 已经互换,</span><br><span class="line">    // 说明 *a 代表的实际数据已经跟 *other 互换了，但是指针没变</span><br><span class="line">fmt.Printf(&quot;a: %v, b: %v\n&quot;, a.List(), b.List())</span><br><span class="line">a.change(&amp;b)</span><br><span class="line">fmt.Printf(&quot;a: %v, b: %v\n&quot;, a.List(), b.List())</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (s *Set) change(other *Set) &#123;</span><br><span class="line">fmt.Printf(&quot;self : %v, other : %v\n&quot;, s.List(), other.List())</span><br><span class="line">*s, *other = *other, *s</span><br><span class="line">fmt.Printf(&quot;self : %v, other : %v\n&quot;, s.List(), other.List())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go init</title>
      <link href="/2025/03/04/Go-init/"/>
      <url>/2025/03/04/Go-init/</url>
      
        <content type="html"><![CDATA[<p>go 中有两个特殊函数<br>一个是 main 包里的 main 函数。<br>一个是包的 init 函数。<br>nit 是无参数、无返回值的函数。<br>如果包定义了 init 函数，go runtime 会负责在包初始化时调用 Init。程序中是不能显示调用 init 的。一个 go 包可以包含多个 init，每个组成 go 包的 go 文件里可以定义多个。go runtime 会顺序调用一个包的不同 init 函数，每个 init 在程序过程中只会执行一次。</p><blockquote><p>PS:不要依赖 init 函数的执行次序</p></blockquote><h2 id="初始化顺序"><a href="#初始化顺序" class="headerlink" title="初始化顺序"></a>初始化顺序</h2><p>init 函数的执行顺序排在其所在包的包级变量之后。<br>也就是说在一个包中，初始化顺序为<br>import 的包→ import包的 import …. → const → var → init</p><h2 id="使用-init-函数检查包级变量初始状态"><a href="#使用-init-函数检查包级变量初始状态" class="headerlink" title="使用 init 函数检查包级变量初始状态"></a>使用 init 函数检查包级变量初始状态</h2><p>重置包级变量值<br>对包级变量进行初始化<br>注册模式<br>比如数据库驱动包使用 import _ “github.com&#x2F;lib&#x2F;pq”这种方式使用，原因就是在 pq 包的 conn.go 中，init 函数做了一些事。<br>空别名方式导入 lib&#x2F;pq 副作用就是 go runtime 会将 lib&#x2F;pq 作为 main 的依赖包并初始化 pg 包，所以会执行 pq 包的 init 函数。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go defer</title>
      <link href="/2025/03/03/Go-defer/"/>
      <url>/2025/03/03/Go-defer/</url>
      
        <content type="html"><![CDATA[<h2 id="运作机制"><a href="#运作机制" class="headerlink" title="运作机制"></a>运作机制</h2><ol><li>只有在函数和方法内部可以使用</li><li>defer 后面只能接函数和方法。defer 会将 defered 函数注册到所在 goroutine 用于存放 defered 函数的栈中，这些 defered 函数将在函数退出前按 LIFO 的顺序执行。</li><li>defer 执行的时机</li></ol><p>执行到函数体尾部<br>某个错误处理分支显示调用 return<br>panic<br>所以 defer 是一个在任何情况下都能为函数收尾的功能。</p><h2 id="常见用法"><a href="#常见用法" class="headerlink" title="常见用法"></a>常见用法</h2><ol><li>拦截 panic<br>实例</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">func factorial() []byte&#123;</span><br><span class="line">   // do something</span><br><span class="line"> defer func() &#123;</span><br><span class="line">      if recover() != nil &#123;</span><br><span class="line">         panic(&quot;deal with error&quot;) // 正常情况会处理panic，这里是直接抛出新 panic</span><br><span class="line"> &#125;</span><br><span class="line">   &#125;()</span><br><span class="line">   return make([]byte, 0)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>修改函数的具名返回值<br>主要还是错误处理，func xxx () err error ，defer 里把 err 的值改了，在 panic 之类的场景函数还会返回 err。 </li><li>输出调试信息 </li><li>还原变量的值</li></ol><h2 id="使用的问题"><a href="#使用的问题" class="headerlink" title="使用的问题"></a>使用的问题</h2><ol><li>如果 defer 的函数有返回值，会被自动丢弃</li><li>一些内置函数不能直接作为内置函数，必须要包装到一个自定义(通常是匿名)函数中</li><li>执行时机</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">func TestSomeFunc(t *testing.T)  &#123;</span><br><span class="line">   s1 := []int&#123;1, 2, 3&#125;</span><br><span class="line">   defer func(a []int) &#123;</span><br><span class="line">      fmt.Println(a)</span><br><span class="line">   &#125;(s1)</span><br><span class="line">   s1 = []int&#123;3, 2, 1&#125;</span><br><span class="line">&#125;</span><br><span class="line">// 1 2 3</span><br><span class="line">func TestSomeFunc(t *testing.T)  &#123;</span><br><span class="line">   s1 := []int&#123;1, 2, 3&#125;</span><br><span class="line">   defer func(a *[]int) &#123;</span><br><span class="line">      fmt.Println(a)</span><br><span class="line">   &#125;(&amp;s1)</span><br><span class="line">   s1 = []int&#123;3, 2, 1&#125;</span><br><span class="line">&#125;</span><br><span class="line">/ / 3 2 1</span><br></pre></td></tr></table></figure><p>上面例子明显看出，第一个例子的 defer func 注册到栈时，会对参数进行求值，此时压入栈的数据是 func{[]int{1,2,3}}<br>第二个例子压入栈的数据是 func(&amp;s1)</p><h2 id="性能损耗"><a href="#性能损耗" class="headerlink" title="性能损耗"></a>性能损耗</h2><p>1.14后性能损耗几乎与不使用 defer 一样了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go panic and recover</title>
      <link href="/2025/03/03/Go-panic-and-recover/"/>
      <url>/2025/03/03/Go-panic-and-recover/</url>
      
        <content type="html"><![CDATA[<h2 id="panic"><a href="#panic" class="headerlink" title="panic"></a>panic</h2><p>Panic 不是 java 的 checked exception<br>panic 是一个内置函数，用来停止当前常规控制流并启动 panicking 过程。<br>当函数 F 调用 panic()时，函数 F 的执行停止，函数 F 中已经执行过的 defer 执行的会正常执行，然后将 F 的控制权返回给调用者。<br>对于 F 的调用者而言，函数 F 之后的行为就如同调用者调用的函数是 panic 一样，该 panic 会在这个堆栈上一直进行下去，直到 goroutine 中所有的函数全部返回，此时程序将会崩溃退出。</p><p>上面的描述清楚的说明了 panic 是不得已而为之，而不是 java try-catch 中的有意而为之<br>因为 panic 一般代表重大 bug ，所以 panic 最好的处理方法就是让程序快速崩溃，而不是像 try-catch 一样去处理他。</p><p>综上所述，panic 更像 java 的 runtimeException + Error。</p><h2 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h2><p>尽可能少的使用 panic<br>api 调用者没有义务处理 panic<br>未被捕获的 panic 意味着游戏结束（程序退出）</p><h2 id="典型应用"><a href="#典型应用" class="headerlink" title="典型应用"></a>典型应用</h2><p>充当断言作用：作为 switch case 的 default 或者在程序员认为不会走到的分支执行，如果执行 panic 意味着代码走到了非预期的代码分支。<br>简化错误处理控制结构： panic 是一直在堆栈传递的，直到某个堆栈函数的 defer 捕获（recover)才会停止蔓延</p><h2 id="一些小坑"><a href="#一些小坑" class="headerlink" title="一些小坑"></a>一些小坑</h2><p>闭包的函数 panic 依旧会传染到整个程序.<br>简单来说就是声明 goroutine 的地方写 recover, 是捕获不到这个 goroutine 内部的 panic 的.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-error</title>
      <link href="/2025/03/03/Go-error/"/>
      <url>/2025/03/03/Go-error/</url>
      
        <content type="html"><![CDATA[<p><strong>Go 是基于错误值比较的, 这点尤为重要</strong></p><h2 id="错误值构造"><a href="#错误值构造" class="headerlink" title="错误值构造"></a>错误值构造</h2><p>先说说如何声明一个错误,在 Go 1.13 之后,我推荐使用 fmt.Errorf 配合 %w 格式化符号来返回基于字符串的错误<br>fmt.Errorf 的结果是一个错误类型, 底层是 fmt.wrapError,<br>比1.13 之前的 errorString 多了 unwrap 方法，wrapError 类型包装的错误值在保证错误链中可以被检视到。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">type wrapError struct &#123;</span><br><span class="line">   msg string</span><br><span class="line"> err error</span><br><span class="line">&#125;</span><br><span class="line">func (e *wrapError) Error() string &#123;</span><br><span class="line">   return e.msg</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (e *wrapError) Unwrap() error &#123;</span><br><span class="line">   return e.err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Go-里的-error-有四种处理策略"><a href="#Go-里的-error-有四种处理策略" class="headerlink" title="Go 里的 error 有四种处理策略"></a>Go 里的 error 有四种处理策略</h2><p>透明处理<br>不关心错误上下文，执行简单错误处理逻辑并返回。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">func a() error &#123;</span><br><span class="line">   err := do()</span><br><span class="line">   if err != nil &#123;</span><br><span class="line">      // easy op</span><br><span class="line"> return err</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func do() error &#123;</span><br><span class="line">   return errors.New(&quot;giao&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="哨兵处理"><a href="#哨兵处理" class="headerlink" title="哨兵处理"></a>哨兵处理</h2><p>不能根据透明错误值就做出处理的判断时</p><ul><li>先使用 var 设定一些哨兵 error</li><li>使用 switch 判断 err 是否属于某个哨兵，然后写专门的处理逻辑。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">var (</span><br><span class="line">   ErrInvalidUnreadByte = errors.New(&quot;bufio: invalid use of UnreadByte&quot;)</span><br><span class="line">   ErrInvalidUnreadRune = errors.New(&quot;bufio: invalid use of UnreadRune&quot;)</span><br><span class="line">   ErrBufferFull = errors.New(&quot;bufio: buffer full&quot;)</span><br><span class="line">   ErrNegativeCount = errors.New(&quot;bufio: negative count&quot;)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">var b bufio.ReadWriter</span><br><span class="line">_, err := b.Peek(1)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">   switch err &#123;</span><br><span class="line">   case bufio.ErrBufferFull:</span><br><span class="line">      //xxx</span><br><span class="line"> case bufio.ErrInvalidUnreadByte:</span><br><span class="line">      //xxx</span><br><span class="line"> default:</span><br><span class="line">      //xxx</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if _, err := b.Peek(2); err == bufio.ErrBufferFull &#123;</span><br><span class="line">   // deal with buffer full error</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>哨兵错误值使用 ErrXXX 的格式命名。但是对于 api 来讲，暴露哨兵，也代表这些错误值和包的公共函数同哨兵一起成为 API 的一部分了。<br>从1.13开始，标准库 errors 包里提供了 Is 方法用于错误处理方对错误值进行检视<br><code>if errors.Is(err, bufio.ErrBufferFull) &#123; // 具体逻辑 &#125;</code></p><blockquote><p>PS:我很喜欢使用 Go 原生 errors 包的 Is As 等函数,而不是 go.dev&#x2F;pkg 里的那个 errors 包</p></blockquote><p>如果 error 类型变量是一个 wrap error， erros.Is 方法会沿着 wrap error 的错误链与链上所有被包装的错误进行比较，直到查到一个匹配错误。比如下面的例子，会认为 err2 是一个 ErrBufferFull 的错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">err1 := fmt.Errorf(&quot;wrap error1 :%w&quot;, bufio.ErrBufferFull)</span><br><span class="line">err2 := fmt.Errorf(&quot;wrap error2 :%w&quot;, err1)</span><br><span class="line">if errors.Is(err2, bufio.ErrBufferFull) &#123;</span><br><span class="line">   //xxx</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="错误值类型检视"><a href="#错误值类型检视" class="headerlink" title="错误值类型检视"></a>错误值类型检视</h2><p>利用类型断言和类型选择，判断 err 的类型来确定错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// 通过类型断言</span><br><span class="line">for _, item := range decodeTypeErrorTests &#123;</span><br><span class="line">   err := Unmarshal([]byte(item.src), item.dest)</span><br><span class="line">   if _, ok := err.(*UnmarshalTypeError); !ok &#123;</span><br><span class="line">      t.Errorf(&quot;expected type error for Unmarshal(%q, type %T): got %T&quot;,</span><br><span class="line"> item.src, item.dest, err)</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">// 通过类型选择机制 switch case</span><br><span class="line">func (d *decodeState) addErrorContext(err error) error &#123;</span><br><span class="line">   if d.errorContext.Struct != nil || len(d.errorContext.FieldStack) &gt; 0 &#123;</span><br><span class="line">      switch err := err.(type) &#123;</span><br><span class="line">      case *UnmarshalTypeError:</span><br><span class="line">         err.Struct = d.errorContext.Struct.Name()</span><br><span class="line">         err.Field = strings.Join(d.errorContext.FieldStack, &quot;.&quot;)</span><br><span class="line">         return err</span><br><span class="line"> &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>自定义到处错误以 XXXError 命名。</p><h2 id="标准库-errors-As-方法用于错误处理方对错误值进行检视"><a href="#标准库-errors-As-方法用于错误处理方对错误值进行检视" class="headerlink" title="标准库 errors.As 方法用于错误处理方对错误值进行检视"></a>标准库 errors.As 方法用于错误处理方对错误值进行检视</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if _, ok := err.(*MyError); ok &#123;</span><br><span class="line">   // xxx</span><br><span class="line">&#125;</span><br><span class="line">// 概念类似于：</span><br><span class="line">var e *MyError</span><br><span class="line">if errors.As(err, &amp;e)&#123;</span><br><span class="line">   // xxx</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>区别只是当 error 类型变量底层是 wrapError 的话，erros.As 会与 errors.Is 一样沿错误链进行寻找。</p><h2 id="错误行为特征检视"><a href="#错误行为特征检视" class="headerlink" title="错误行为特征检视"></a>错误行为特征检视</h2><p>定义新的Error interface，确定新方法来确定错误处理分支</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">type Error interface &#123;</span><br><span class="line">   error</span><br><span class="line"> Timeout() bool // Is the error a timeout?</span><br><span class="line"> Temporary() bool // Is the error temporary?</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// net/http/server.go</span><br><span class="line">if ne, ok := err.(net.Error); ok &amp;&amp; ne.Temporary() &#123;</span><br><span class="line">   if tempDelay == 0 &#123;</span><br><span class="line">      tempDelay = 5 * time.Millisecond</span><br><span class="line"> &#125; else &#123;</span><br><span class="line">      tempDelay *= 2</span><br><span class="line"> &#125;</span><br><span class="line">   if max := 1 * time.Second; tempDelay &gt; max &#123;</span><br><span class="line">      tempDelay = max</span><br><span class="line"> &#125;</span><br><span class="line">   srv.logf(&quot;http: Accept error: %v; retrying in %v&quot;, err, tempDelay)</span><br><span class="line">   time.Sleep(tempDelay)</span><br></pre></td></tr></table></figure><h2 id="如何优化反复出现的-if-err-nil"><a href="#如何优化反复出现的-if-err-nil" class="headerlink" title="如何优化反复出现的 if err !&#x3D; nil {}"></a>如何优化反复出现的 if err !&#x3D; nil {}</h2><p>本质上没有什么好的方法,看过 rob pike 的文章就知道,这虽然看着很冗余,但是直接,而且是显式的,而简单显式就是 Go 哲学里的一部分.</p><h2 id="使用-if-err-func-err-nil"><a href="#使用-if-err-func-err-nil" class="headerlink" title="使用 if err :&#x3D; func(); err !&#x3D; nil"></a>使用 if err :&#x3D; func(); err !&#x3D; nil</h2><p>只是视觉上少了那么一两行,完全没卵用</p><h2 id="重构-err-nil-过多的函数和方法-分解成多个子方法"><a href="#重构-err-nil-过多的函数和方法-分解成多个子方法" class="headerlink" title="重构 err !&#x3D; nil 过多的函数和方法,分解成多个子方法"></a>重构 err !&#x3D; nil 过多的函数和方法,分解成多个子方法</h2><p>我的经验是一旦函数内封装了超过5个 err 处理的函数,这里可能有一些不清晰的地方了</p><h2 id="check-handle-风格化"><a href="#check-handle-风格化" class="headerlink" title="check&#x2F;handle 风格化"></a>check&#x2F;handle 风格化</h2><p>利用 panic&#x2F;recover 封装一套跳转机制,性能下降不说,看起来很像很 java shit, <strong>非常不推荐</strong></p><h2 id="封装内置-error-状态"><a href="#封装内置-error-状态" class="headerlink" title="封装内置 error 状态"></a>封装内置 error 状态</h2><p>将 err 作为自己定义的一个 struct 的成员,可以参考 gorm 的 db.ERROR 那种方式,没用过,<strong>不敢推荐</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-receiver</title>
      <link href="/2025/03/03/Go-receiver/"/>
      <url>/2025/03/03/Go-receiver/</url>
      
        <content type="html"><![CDATA[<p>对于golang的函数如:<br><code>func (s *struct1)func1(a int,b ...string)(int)&#123; return 1&#125;</code><br>这里(s *struct1)的意义是func1代表struct1这个结构体的一个方法,可以调用s.func1来执行,类似于java中的类方法.<br>在网上找了一个不错的解答:<br><img src="/2025/03/03/Go-receiver/image.png"><br>在我开发了一段时间后回顾,我有了自己的总结.</p><h2 id="Go-方法的特点"><a href="#Go-方法的特点" class="headerlink" title="Go 方法的特点"></a>Go 方法的特点</h2><ol><li>首字母决定是不是导出方法</li><li>方法定义要与类型定义放在同一个包内。引申：不能为原生类型(int float64 map 等)添加方法，只能是自定义的类型；不能横跨 Go 包为其他包内的自定义类型定义方法</li><li>每个方法只有一个 receiver 参数，一个方法只能绑定一个类型</li><li>receiver 参数的基类型本身不能是指针类型或者接口类型</li></ol><p>##方法的本质<br>带 receiver 的方法会转化成 将 receiver 作为第一个参数传入方法参数列表的普通函数，转化后的函数称为<strong>方法原型</strong><br>举例来说：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">type T struct &#123;</span><br><span class="line">   a int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (t T) Get() int &#123;</span><br><span class="line">   return t.a</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func Get(t T) int &#123;</span><br><span class="line">   return t.a</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面 GET方法就是 T.Get 的方法原型。<br>进而说一下 go 方法的本质：一个以方法锁绑定类型实例为第一个参数的普通函数。</p><h2 id="选择正确的-receiver-类型"><a href="#选择正确的-receiver-类型" class="headerlink" title="选择正确的 receiver 类型"></a>选择正确的 receiver 类型</h2><p>到底是使用 T 还是 *T?<br>我们先来看一个 Go 的两个设计:<br>Go 函数参数采取的是值传递。所以当直接使用 T 作为 receiver 时，使用的是 T 的一个副本T’，任何修改都不会影响本来的 T。<br>无论是 T 还 *T 作为 receiver,都不会因为生命的对象是什么类型而改变,也就是说什么时候都可以调用 T 或 *T receive 的函数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">type BMZ struct&#123;&#125;</span><br><span class="line">func(b *BMZ) G()&#123;&#125;</span><br><span class="line">func(b BMZ) G2()&#123;&#125;</span><br><span class="line">func TestXXX(t *testing.T) &#123;</span><br><span class="line">    b := BMZ&#123;&#125;</span><br><span class="line">    B.G()</span><br><span class="line">    B.G2()</span><br><span class="line">    b2 := &amp;BMZ&#123;&#125;</span><br><span class="line">    B.G()</span><br><span class="line">    B.G2()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码都可以正常编译运行<br>所以用 T 还是 *T 最主要的区别,在于是否要对原本对象内容进行修改.总结下来:</p><ol><li>如果要对实例内容进行修改，就用*T。</li><li>如果没有对类型修改的需求，两种都可以，但是由于值拷贝，通常情况下 *T 拷贝的开销比 T 小。</li><li>这个类型是否实现了某个接口,实现接口必须是用 *T</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go control statement trap</title>
      <link href="/2025/03/02/Go-control-statement-trap/"/>
      <url>/2025/03/02/Go-control-statement-trap/</url>
      
        <content type="html"><![CDATA[<h2 id="for-range-陷阱"><a href="#for-range-陷阱" class="headerlink" title="for range 陷阱"></a>for range 陷阱</h2><ol><li>for range 中如果使用了goroutine 执行的闭包函数来读写 for range 的内容，则必须 go func(i int, v type)(i, v)，将 i ,v 与闭包函数绑定</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var m = [...]int&#123;1,2,3&#125;</span><br><span class="line">for i, v := range m &#123;</span><br><span class="line">   go func(i, v int) &#123;</span><br><span class="line">      fmt.Println(i, v)</span><br><span class="line">   &#125;(i, v)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>否则 fmt.println 中只会输出最后一次遍历的 i, v 的值。</p><h2 id="参与迭代的是-range-表达式的副本"><a href="#参与迭代的是-range-表达式的副本" class="headerlink" title="参与迭代的是 range 表达式的副本"></a>参与迭代的是 range 表达式的副本</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func TestXxx(t *testing.T) &#123;</span><br><span class="line">var m = [...]int&#123;1, 2, 3, 4, 5&#125;</span><br><span class="line">var r [5]int</span><br><span class="line">for i, v := range m &#123;</span><br><span class="line">if i == 0 &#123;</span><br><span class="line">m[1] = 11</span><br><span class="line">m[2] = 12</span><br><span class="line">&#125;</span><br><span class="line">r[i] = v</span><br><span class="line">&#125;</span><br><span class="line">t.Log(m) // 1 11 12 4 5</span><br><span class="line">t.Log(r) // 1 2 3 4 5</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们在遍历 m 过程中先将 m[1], m[2] 修改了,但为什么 r 的结果没变化呢?<br>因为 range m 的时候,不是真的在遍历 m, 而是遍历 m 的副本 m’<br>无论 m 怎么被修改, m’ 都是初始化时的值<br>使用指针 &amp;m 或者定义成切片 m[:] 作为 range 的对象,则 r 的值和 m 将相同</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">var m = [...]int&#123;1, 2, 3, 4, 5&#125;</span><br><span class="line">var r [5]int</span><br><span class="line">for i, v := range m[:] &#123;</span><br><span class="line">if i == 0 &#123;</span><br><span class="line">m[1] = 11</span><br><span class="line">m[2] = 12</span><br><span class="line">&#125;</span><br><span class="line">r[i] = v</span><br><span class="line">&#125;</span><br><span class="line">t.Log(m) // 1 11 12 4 5</span><br><span class="line">t.Log(r) // 1 11 12 4 5</span><br></pre></td></tr></table></figure><ol start="3"><li>对 len 会变化的切片 for range</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">var a = []int&#123;1,2,3,4,5&#125;</span><br><span class="line">var r []int</span><br><span class="line"></span><br><span class="line">fmt.Println(a) // 12345</span><br><span class="line">for i, v := range a &#123;</span><br><span class="line">   if i == 0 &#123;</span><br><span class="line">      a = append(a, 6, 7)</span><br><span class="line">   &#125;</span><br><span class="line">   r = append(r, v)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(r) // 12345</span><br><span class="line">fmt.Println(a) // 1234567</span><br></pre></td></tr></table></figure><p>原切片虽然在 for range 中增加了两个元素，len 从5到7，但没有对 r 造成影响。原因是切片 a 的副本 a’ 内部表示的 len 没有变化。<br>结论：<br>range 表达式遍历数组会复制整个数组，遍历 slice 只会复制数组指针和 len cap 变量。使用切片或者指针的消耗大约在使用数组的 50%<br>4. string<br>string 作为 for range 表达式时，go runtime 表示成 []rune，如果字符串中存在非法 utf8字符，那么 v 将返回 0xfffd 这个特殊值，然后在下一轮循环中，v 将前进一个字节。<br>5. map<br>map 作为 range 表达式，会得到一个 map 内部表示的指针。而 go runtime 的 map 表示，是一个 hmap 描述符结构的指针。因此 map 的副本也指向一个 hmap 的指针，即hmap，他们同时指定同一个 hmap，也就是说，改变 map 副本操作也会对源 map 进行操作。<br>for range 迭代map的时候无法保证元素次序是一致的。所以在遍历的时候，如果对 map 进行修改，结果是不确定的，比如*新增一个 k-v，那么后续可能遍历到，也可能没有遍历到；删除一个元素，可能会遍历到，也可能不会。<br>6. channel<br>channel 在 go runtime 内部表示为一个 channel 描述符指针，因此 channel 的指针副本也指向原 channel。<br>for range 最终会以阻塞读的方式阻塞在 channel 表达式上，即便是有缓冲的 chennel 也一样；当 channel 中无数据，for range 也会阻塞，直到 channel 关闭。<br>也就是说，当使用 nil 的 channel 作为 range 表达式会永远阻塞，直到 go runtime 发现程序 deadlock 并 panic。</p><h2 id="break"><a href="#break" class="headerlink" title="break"></a>break</h2><p>go 里的 break 只会跳出最内层的 for switch select。<br>for 中嵌套 select switch 的操作，有的时候根据一些行为要跳出 for 循环。那么只在 select switch case 下面 break 是没用的。这时候必须使用 break [\label]的方式。<br>break label 会终止在外层的 label 循环上<br>continue label 会到外层循环继续执行</p><h2 id="fallthrough"><a href="#fallthrough" class="headerlink" title="fallthrough"></a>fallthrough</h2><p>case 语句如果需要向下个 case 继续执行，就要显示写 fallthrough。<br>case 本身可以包含多个表达式，使用逗号分割。<br>一般情况下，使用 case a, b ,c 的方式要优于<br>case a:<br>fallthrough<br>case b:fallthrough<br>case c:xxx</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go expression of Calculate Value</title>
      <link href="/2025/03/01/Go-expression-of-Calculate-Value/"/>
      <url>/2025/03/01/Go-expression-of-Calculate-Value/</url>
      
        <content type="html"><![CDATA[<h2 id="包级别变量声明语句中的顺序"><a href="#包级别变量声明语句中的顺序" class="headerlink" title="包级别变量声明语句中的顺序"></a>包级别变量声明语句中的顺序</h2><ol><li>在包中，包级别变量初始化按照声明先后顺序进行</li><li>如果某个变量 a 初始化表达式直接或间接需要其他变量 b，那么 a 的初始化在 b 后面</li><li>未初始化且不依赖任何其他变量成为 “ready for initialization”变量</li><li>包基本变量初始化就是一步一步找到下一个”ready for init”变量并对它初始化，直到没有“rfi”变量</li><li>同一个包，但不同文件的变量声明顺序依赖编译器处理文件的顺序：先处理文件中的变量声明顺序先于后处理的声明顺序<br>空变量 _ 也会在包里算一个合法的变量，编译器也会检测他是否是 rfi 变量</li></ol><h2 id="普通求值顺序"><a href="#普通求值顺序" class="headerlink" title="普通求值顺序"></a>普通求值顺序</h2><p>Go 规定表达式操作数中的函数、方法、channal 按照从左至右的顺序。<br>当普通求值顺序与包级变量初始化顺序一起出现的时候，包级变量优先级更高</p><h2 id="赋值语句的求值"><a href="#赋值语句的求值" class="headerlink" title="赋值语句的求值"></a>赋值语句的求值</h2><p>rob pike 留的一个作业：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n0 = 2</span><br><span class="line">n1 = 1</span><br><span class="line">n0, n1 = n0 + n1, n0 的结果是什么？// 3 2</span><br></pre></td></tr></table></figure><p>因为已经初始化过 n0 n1,第三行只考虑前面行里的 n1, n0</p><h2 id="switch-select-语句的表达式求值"><a href="#switch-select-语句的表达式求值" class="headerlink" title="switch&#x2F;select 语句的表达式求值"></a>switch&#x2F;select 语句的表达式求值</h2><p>惰性求值：需要进行求值的时候才会对表达式进行求值<br>switch 语句中，如果 case 中语句不需要执行到，那么将不会执行<br>select 语句中，首先所有 case 的表达式都会由前到后的执行一遍。有一种例外，就是 case 等号左边从 channel 接收数据的表达式不会被求值。<br>如果选择要执行的是一个从 channel 接收数据的 case，此时等号左边的表达式才会被求值。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-mod</title>
      <link href="/2025/02/27/Go-mod/"/>
      <url>/2025/02/27/Go-mod/</url>
      
        <content type="html"><![CDATA[<h2 id="Go-mod-是什么"><a href="#Go-mod-是什么" class="headerlink" title="Go mod 是什么"></a>Go mod 是什么</h2><p>有 Go mod 之前,Go 的依赖管理要么直接用 GOPATH, 要么使用 Go Vendor.</p><ul><li>GOPATH<br>每个项目自己组织依赖包,编译前设置环境变量作为路径,没有依赖管理可言</li><li>Go Vendor<br>Go 1.5 推出的管理工具,在项目根目录用一个 vendor 目录存放依赖包.<br>go build 命令会先查找 vendor 目录,再查找 GOPATH.<br>解决了多个项目使用同一个包的依赖冲突.<br>但如果多个项目想重用相同的依赖包,每个工程都得 copy 一份到自己的 vendor 目录</li><li>Go module<br>Go 1.11 发布,并在 Go 1.16 默认开启作为依赖管理工具.<br>原理就是在项目目录下放置 go.mod 文件,使用 go.mod 文件描述 “模块” 的依赖关系, 并使用 go get 或者 go mod 命令来管理包的下载和更新.<br>实现了依赖包的多版本控制,并可以自动化管理依赖包的下载,安装和编译.<br>模块(module)是什么<br>模块是一堆包 发布,版本控制,分发的一个集合,每个包含 go.mod 的目录就是一个单独的模块.<br>开发者可以将项目拆分成多个模块,每个模块都管理自己的依赖关系和版本控制.</li></ul><h2 id="模块路径"><a href="#模块路径" class="headerlink" title="模块路径"></a>模块路径</h2><p>模块的规范名称, 被 go.mod 中 module 指令声明.</p><p>模块路径由 <strong>存储库根路径</strong>, <strong>存储库目录</strong> 和 <strong>major版本</strong> 组成</p><ul><li>存储库根路径<br>一般是项目根目录,比如 k8s 项目根目录的 go.mod, module 名称是 k8s.io&#x2F;kubernates</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">module k8s.io/kubernetes</span><br><span class="line">go 1.23.0</span><br></pre></td></tr></table></figure><ul><li>存储库目录<br>如果模块在代码仓库根目录没定义,就用存储库目录来描述,比如<br>golang.org&#x2F;x&#x2F;tools&#x2F;gopls</li><li>major 版本<br>假如模块发布版本是 v2 及以上,模块路径必须有 &#x2F;v2 这种后缀路径,比如<br>go.etcd.io&#x2F;etcd&#x2F;client&#x2F;v3</li></ul><h2 id="包路径"><a href="#包路径" class="headerlink" title="包路径"></a>包路径</h2><p>模块路径和路径下的子目录拼起来的,一个模块路径下可能有多个目录作为包.<br>golang.org&#x2F;x&#x2F;net&#x2F;html<br>是 golang.org&#x2F;x&#x2F;net 的包路径之一</p><h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><p>语义版本有3个非负整数,比如 v1.2.3</p><p>major:发布不兼容的接口更改,或某些包被删除,必须递增 major 版本<br>minor:发布兼容的接口更改,或者新增了函数<br>patch:不修改任何接口声明,只是 bugfix 或 improvement<br>值得一提,补丁版本后可以跟着一个标识符,比如 -pre -beta -alpha 这种,表示是一个测试版.有这种后缀的版本代表是不稳定的版本.</p><h3 id="伪版本"><a href="#伪版本" class="headerlink" title="伪版本"></a>伪版本</h3><p>我们经常看到形如<br><code>v0.0.0-20230627132053-2c327efd41e2</code><br>的版本号,这其实就是为版本,是一种特殊格式的 “预发布版本”.<br>伪版本分成三个组成部分:</p><p>基础版本 vX.0.0 或者 vX.Y.Z-0,这个版本是从 git 里的 tag 派生的,假如没有 tag,则版本是 vX.0.0.<br>时间戳,commit 的 utc 时间<br>commit 标识: commit 哈希的前12位</p><h3 id="主版本后缀的重要意义"><a href="#主版本后缀的重要意义" class="headerlink" title="主版本后缀的重要意义"></a>主版本后缀的重要意义</h3><p>还是拿老例子<br><img src="/2025/02/27/Go-mod/dependency-hell-in-go.png"><br>为了让 App 可以解决依赖冲突,<br>在 P1 的 go.mod 定义 require P3 v1.5<br>在 P2 的 go.mod 定义 require P3&#x2F;v2 v2.0<br>就可以了,因为 P3 和 P3&#x2F;v2 被 go.mod 视作 2 个不同的 module,他们可以同时被一个项目引用.</p><h3 id="后缀-incompatible"><a href="#后缀-incompatible" class="headerlink" title="后缀+incompatible"></a>后缀+incompatible</h3><p>经常看到 go.mod 里有这样的依赖版本,这是什么意思呢?<br><code>github.com/desertbit/columnize v2.1.0+incompatible</code><br>去这个项目的 github 一看,其实只发布了 v2.1.0 这个版本<br><img src="/2025/02/27/Go-mod/desertbit-web.png"></p><p>说明这个 incompatible 是 go mod 自己加的,用来标记这个 module 不符合规范,是可能不兼容的.<br>造成这个的原因是:</p><ol><li>这个库有 v2 或以上的 tag 版本了,但 module 里并没有写 &#x2F;v2 这种主版本后缀用于区分不同主版本的模块.<br>比如我自己的一个项目发布了 v2.0.1 的 tag,但 go.mod 里写的是</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">module  bmz-demo/abc</span><br><span class="line">// 而不是</span><br><span class="line">module bmz-demo/abc/v2</span><br></pre></td></tr></table></figure><ol start="2"><li>这个库压根没用 go mod 管理<br>这个在 github 上屡见不鲜了</li></ol><h2 id="go-sum"><a href="#go-sum" class="headerlink" title="go.sum"></a>go.sum</h2><p>这个文件是记录各个依赖项的版本和哈希值,主要是go module 本身用于校验作用,开发者大多时候不用关心这个,无脑 go mod tidy 就行.</p><h2 id="go-mod-里的关键字"><a href="#go-mod-里的关键字" class="headerlink" title="go.mod 里的关键字"></a>go.mod 里的关键字</h2><ol><li>module:定义模块路径</li><li>go:编译这个模块时 go 语言指定最低版本</li><li>toolchain: 声明了与模块一起使用时, Go 工具链的最低版本</li><li>require: 声明特定依赖模块的版本,采用最小版本选择解决依赖冲突.<br>indirect 注释:代表不是我的项目直接依赖,而是依赖的依赖</li><li>exclude: 组织一个模块被 go build 加载</li><li>replace: 当使用一个 package A 时,将他替换成另一个 package 的指定版本</li><li>retract: 没用过,不会</li></ol><h2 id="最小版本选择"><a href="#最小版本选择" class="headerlink" title="最小版本选择"></a>最小版本选择</h2><p>go.mod 描述了当前项目需要哪些依赖和版本<br>go build 编译时可以解析出 DAG 来描述所需要全部包的版本.<br>那么在引用里有两个相同 module 时,选择谁的版本呢?<br>默认情况下,选择版本大的;</p><h2 id="replace"><a href="#replace" class="headerlink" title="replace"></a>replace</h2><p>在 go.mod 显示指定用某个版本,比如我就想用小一点的版本</p><h2 id="exclusion"><a href="#exclusion" class="headerlink" title="exclusion"></a>exclusion</h2><p>使用 exclude 来排除某个版本,假如当前项目引用的 P1 最大是 V1.5(当然P1本身有1.6 1.7 …),只用 exclude P1 v1.5 之后,编译时会选择下一个更高的版本,比如 v1.6</p><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="初始化一个-module"><a href="#初始化一个-module" class="headerlink" title="初始化一个 module"></a>初始化一个 module</h3><p><code>go mod init demo</code></p><h3 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h3><p>进入项目<br><code>go get xxx</code><br><code>go mod tidy</code></p><h3 id="查看版本信息"><a href="#查看版本信息" class="headerlink" title="查看版本信息"></a>查看版本信息</h3><ol><li>查看 gin 的全部历史版本有哪些<br><code>go list -m -versions github.com/gin-gonic/gin</code></li><li>查看依赖的模块信息, 可以 -json 查看结构化信息,也可以 -u 查看升级的信息<br><code>go list -m github.com/gin-gonic/gin</code></li><li>获取指定版本,比如指定 v1.10.0<br><code>go get github.com/gin-gonic/gin@v1.10.0</code></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-compile</title>
      <link href="/2025/02/26/Go-compile/"/>
      <url>/2025/02/26/Go-compile/</url>
      
        <content type="html"><![CDATA[<h2 id="Go-编译过程"><a href="#Go-编译过程" class="headerlink" title="Go 编译过程"></a>Go 编译过程</h2><p>静态型语言都是通过 compile + link 两个阶段组成。<br>非 main 包编译后会形成 .a 文件，这是 go 包的目标文件，这个文件是通过 pack 工具对.o 文件打包形成的。默认情况下，.a 文件生成在临时目录下，除非用 go install 安装到$GOPATH&#x2F;pkg 下，否则看不见.a 文件。如果是可执行程序，.a 文件会在构建可执行程序的link 阶段起作用。</p><h2 id="编译器会重新编译依赖包的源文件还是直接链接包的-a-文件"><a href="#编译器会重新编译依赖包的源文件还是直接链接包的-a-文件" class="headerlink" title="编译器会重新编译依赖包的源文件还是直接链接包的.a 文件"></a>编译器会重新编译依赖包的源文件还是直接链接包的.a 文件</h2><p>在使用第三方包的时候，在第三方包源码存在且对应.a 已经安装的情况下，编译器链接的仍然是根据第三方包最新源码编译出的.a 文件，而不是之前安装的目标文件。</p><h3 id="构建的过程"><a href="#构建的过程" class="headerlink" title="构建的过程"></a>构建的过程</h3><p>假设一个项目（github.com&#x2F;bmz&#x2F;demo）目录如下，main.go 中 import 了 github 地址中的 pkg1包作为依赖：<br><img src="/2025/02/26/Go-compile/pkg1.png" alt="demo-dir"></p><ol><li>建立临时工作目录，命名为 WORK，以后编译、链接均用 $WORK 为当前目录</li><li>编译 app1 的依赖包 pkg1，将目标文件打包后放入 $WORK&#x2F;github.com&#x2F;bmz&#x2F;demo&#x2F;pkg&#x2F;pkg1.a</li><li>编译 app1 的 main 包， 将目标文件打包后放入 $WORK&#x2F;github.com&#x2F;bmz&#x2F;demo&#x2F;cmd&#x2F;app1.a</li><li>链接器将 app1.a pkg1.a 链接成$WORK&#x2F;githubc.om&#x2F;bmz&#x2F;demo&#x2F;cmd&#x2F;app1&#x2F;_obj&#x2F;exe&#x2F;a.out</li><li>将 a.out 改名成 app1</li></ol><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>所谓使用第三方代码库的源码，实际上是链接了以该最新包源码编译、存放在临时目录下的包.a 文件而已<br>而对于标准库中的包，编译器直接链接$GOPATH&#x2F;pkg&#x2F;darwin_amd64下面的 .a 文件，而不是开源地址编译后的</p><h2 id="import-的内容，是包名还是路径名"><a href="#import-的内容，是包名还是路径名" class="headerlink" title="import 的内容，是包名还是路径名"></a>import 的内容，是包名还是路径名</h2><p>编译器在编译过程中比如使用编译单元（一个包）所依赖的包源码。而找到依赖包的源码，需要找到路径，路径分为两部分：基础搜索路径 + 包导入路径</p><h3 id="基础搜索路径"><a href="#基础搜索路径" class="headerlink" title="基础搜索路径"></a>基础搜索路径</h3><p>所有包的基础搜索路径都包括$GOROOT&#x2F;src<br>$GOROOT&#x2F;src 外，不同版本的 go 包含其他搜索路径不同<br>1.11之前，包的基础搜索路径还包括$GOPATH&#x2F;src<br>1.11-1.12，包的基础搜索路径有三种模式<br>GO111MODULE&#x3D;off 时，$GOPATH&#x2F;src<br>GO111MODULE&#x3D;on 时，$GOPATH&#x2F;pkg&#x2F;mod<br>GO111MODULE&#x3D;auto时，在 $GOPATH&#x2F;src 路径下，与 off 相同；而在$GOPATH&#x2F;src 路径外且包含 go.mod，与 on 相同；<br>1.13后<br>off，$GOPATH&#x2F;src<br>auto&#x2F;on，$GOPATH&#x2F;pkg&#x2F;mod</p><h3 id="包导入路径"><a href="#包导入路径" class="headerlink" title="包导入路径"></a>包导入路径</h3><p>就是位于包源码头部的 import 中写的路径</p><h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><p>源文件头部的包导入语句 import 的是文件夹路径,并不是包名。但是 GO 的惯用用法是把最后一个目录名与包名一致。<br>而在代码中使用的，比如 fmt.xxxx() ，这个 fmt 是实实在在的包名;<br>当包名与包导入路径中的最后一个目录名不同时，显示重命名 import 包目录为实际包名<br>比如路径是:<br>import &#x2F;a&#x2F;b&#x2F;c&#x2F;bmz1-path，<br>实际包名 bmz1,那么就写成:<br>import bmz1 “a&#x2F;b&#x2F;c&#x2F;bmz1-path”</p><h2 id="Go-mod"><a href="#Go-mod" class="headerlink" title="Go mod"></a>Go mod</h2><p>详细看 <a href="https://dive2cloud-bmz.github.io/2025/02/27/Go-mod/">https://dive2cloud-bmz.github.io/2025/02/27/Go-mod/</a></p><h2 id="包冲突"><a href="#包冲突" class="headerlink" title="包冲突"></a>包冲突</h2><p>之前在设计哲学的 blog 里简单提过,Go mod 怎么解决依赖冲突,这里用例子详细说一下<br><img src="/2025/02/26/Go-compile/dependency-hell-in-go.png" alt="引用白老师照片"><br>上图的问题是当我构建 app 时,P3 用什么版本呢?<br>Go 的答案是这样的:<br><img src="/2025/02/26/Go-compile/dependency-hell-in-go-3.png" alt="继续引用白老师照片"><br>Go 打破 app 只允许包含一个包(P3)的一个版本.<br>但是不是随便打破,而是有个前提:<br>P1 和 P2 依赖 P3 是不同的 major 版本.这就是语义导入版本,一个代码库里 major 号不同的项目是不同的 module.<br><img src="/2025/02/26/Go-compile/go-yyhppt-01.png"><br>这个设计产生了一个深刻的规范:当一个项目的某个版本对之前的代码是不兼容时,发布这个项目的新版本必须升 major 版本.</p><h3 id="假如我引用的项目都是相同-major-版本-用谁的呢"><a href="#假如我引用的项目都是相同-major-版本-用谁的呢" class="headerlink" title="假如我引用的项目都是相同 major 版本,用谁的呢?"></a>假如我引用的项目都是相同 major 版本,用谁的呢?</h3><p><img src="/2025/02/26/Go-compile/dependency-hell-in-go.png"><br>默认情况下,还用上面的例子,app 会用相同 P3 major 版本里较高的,也就是 V1.2.<br>此时全局的 go.mod 下 P3 的版本会被改成 V1.2</p><h3 id="假如-P3-开发者就是不遵循规范-用相同-major-版本发布了不兼容的代码-V1-1-和-V1-2-天差地别"><a href="#假如-P3-开发者就是不遵循规范-用相同-major-版本发布了不兼容的代码-V1-1-和-V1-2-天差地别" class="headerlink" title="假如 P3 开发者就是不遵循规范,用相同 major 版本发布了不兼容的代码(V1.1 和 V1.2 天差地别)"></a>假如 P3 开发者就是不遵循规范,用相同 major 版本发布了不兼容的代码(V1.1 和 V1.2 天差地别)</h3><p>默认情况下会用高版本的 v1.2<br>假如我就想用 v1.1,那么要去 go.mod 里增加 replace</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">replace (</span><br><span class="line">    xxx/P3 =&gt; xxx/P3 v1.1</span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>How to use string efficiently in Go.</title>
      <link href="/2025/02/18/How-to-use-string-efficiently-in-Go/"/>
      <url>/2025/02/18/How-to-use-string-efficiently-in-Go/</url>
      
        <content type="html"><![CDATA[<h2 id="Go-string-特点"><a href="#Go-string-特点" class="headerlink" title="Go string 特点"></a>Go string 特点</h2><h3 id="string-数据不可变"><a href="#string-数据不可变" class="headerlink" title="string 数据不可变"></a>string 数据不可变</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">str1 := &quot;hello&quot;</span><br><span class="line">str2 := []byte(str1)</span><br><span class="line">str2[0] = &#x27;g&#x27;</span><br><span class="line">fmt.Println(str1)</span><br><span class="line">发现 str1 维持 hello,说明 []byte 的存储与 str1 的存储不是同一个</span><br></pre></td></tr></table></figure><p>再来看更暴力的尝试:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">func modifyString(s *string) &#123;</span><br><span class="line">p := (*uintptr)(unsafe.Pointer(s))</span><br><span class="line">var arr [5]byte = ([5]byte)(unsafe.Pointer(p))</span><br><span class="line">var len int = (int)(unsafe.Pointer(uintptr(unsafe.Pointer(s)) + unsafe.Sizeof((*uintptr)(nil))))</span><br><span class="line">for i := 0 ; i &lt; (len) ; i++ &#123;</span><br><span class="line">p1 := &amp;((arr)[i])</span><br><span class="line">v := p1</span><br><span class="line">p1 = v + 1 // try to change character</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里直接用 unsafe.Pointer 指向 string 的存储块地址,通过指针修改内存中的实际数据,会得到 SIGBUS 的报错，也就是说明 string 底层数据存储只能进行读操作</p><h3 id="零值"><a href="#零值" class="headerlink" title="零值"></a>零值</h3><p>就是 “”,至此一点就完爆 java</p><h3 id="获取长度是-O-1-复杂度的"><a href="#获取长度是-O-1-复杂度的" class="headerlink" title="获取长度是 O(1) 复杂度的"></a>获取长度是 O(1) 复杂度的</h3><p>因为不可变的特性,初始化 string 的时候已经算过 len 并存到一个成员变量里了,因此 len(str) 是 O(1)</p><h3 id="编码使用的-unicode"><a href="#编码使用的-unicode" class="headerlink" title="编码使用的 unicode"></a>编码使用的 unicode</h3><h3 id="多行字符串时使用-xxxx"><a href="#多行字符串时使用-xxxx" class="headerlink" title="多行字符串时使用 xxxx"></a>多行字符串时使用 <code>xxxx</code></h3><p>我觉得很好的功能,写单测或者 raw 文本时很棒</p><h2 id="string-对象的代码表示"><a href="#string-对象的代码表示" class="headerlink" title="string 对象的代码表示"></a>string 对象的代码表示</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type stringStruct struct &#123;</span><br><span class="line">str unsafe.Pointer</span><br><span class="line">len int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>string 类型也只是描述符，不是实际存储，保存的是一个真正和数组长度。<br>接下来看看 string 的实例化过程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// rawstring allocates storage for a new string. The returned</span><br><span class="line">// string and byte slice both refer to the same storage.</span><br><span class="line">// The storage is not zeroed. Callers should use</span><br><span class="line">// b to set the string contents and then drop b.</span><br><span class="line">func rawstring(size int) (s string, b []byte) &#123;</span><br><span class="line">p := mallocgc(uintptr(size), nil, false)</span><br><span class="line"></span><br><span class="line">stringStructOf(&amp;s).str = p</span><br><span class="line">stringStructOf(&amp;s).len = size</span><br><span class="line"></span><br><span class="line">(*slice)(unsafe.Pointer(&amp;b)) = slice&#123;p, size, size&#125;</span><br><span class="line"></span><br><span class="line">return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/2025/02/18/How-to-use-string-efficiently-in-Go/stringRuntimeExpression.png" alt="标示图"></p><p>每个字符串类型变量&#x2F;常量都对应一个 stringStruct 实例，经过 rawString 实例化后，stringStruct 中 str 指针指向了真正存储字符串数据的底层内存区域，同时还创建了一个临时 slice，array 指针也指向真正的内存区域。<br>在 rawString 之后，申请的内存区域还没有被写入数据，这个 slice 就是供后续 runtime 向其中写入数据用的。写完数据后，slice 就被回收了。<br>所以得出一个结论：直接将 string 作为函数的传参也没有太多损耗，因为本质上只是描述符的 str 指针传递而已。<br>经过 benchmark 字符串指针和字符串本身参数传递性能上几乎无差别。</p><h2 id="高效构造"><a href="#高效构造" class="headerlink" title="高效构造"></a>高效构造</h2><p>字符串拼接时,除了直接 + &#x2F; +&#x3D; 之外 ，string 有4种构造方式</p><ul><li>fmt.sprintf</li><li>strings.join</li><li>strings.builder</li><li>bytes.buffer<br>先说结论:这五种方式中，做了预初始化的 strings.builder 链接字符串的效率最高<br>我们先初始化一个 string 的 slice 列表,模拟每个要拼接的元素</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var s []string = []string &#123;</span><br><span class="line">&quot;Rob Pike&quot;,</span><br><span class="line">&quot;Bie MingZhou&quot;,</span><br><span class="line">&quot;SB&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>strings.builder 预初始化方式举例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var b strings.Builder</span><br><span class="line">b.Grow(64) // init as 64</span><br><span class="line">for _, v := range s &#123;</span><br><span class="line">b.WriteString(v)</span><br><span class="line">&#125;</span><br><span class="line">result := b.String()</span><br></pre></td></tr></table></figure><p>预初始化的 bytes.Buffer 和 strings.join 接近，第二第三</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">buf := make([]byte, 0, 64)</span><br><span class="line">b := bytes.NewBuffer(buf)</span><br><span class="line">for _, v := range s &#123;</span><br><span class="line">b.WriteString(v)</span><br><span class="line">&#125;</span><br><span class="line">result := b.String()</span><br><span class="line">strings.join</span><br><span class="line">result := strings.Join(s, &quot;&quot;)</span><br></pre></td></tr></table></figure><p>没有初始化的 strings.builer、bytes.Buffer、操作符连接为第三档。<br>效率最差的是 fmt.Sprintf</p><ul><li>结论</li></ul><ol><li>能预估最终字符串长度时，使用初始化的 strings.builder 构建字符串</li><li>strings.join 构建字符串平均性能最稳定，如果是用字符串slice拼接成一个字符串，是首选</li><li>操作符比较直观，在编译器知晓链接字符串个数情况下，操作符可以得到编译器的优化处理</li><li>fmt.sprintf 适用在多种类型变量构建的字符串</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YARN state machine</title>
      <link href="/2025/02/13/YARN-state-machine/"/>
      <url>/2025/02/13/YARN-state-machine/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>RM 内部维护了四个状态机</p><ol><li>RMApp：维护 App 的生命周期</li><li>RMAppAttempt：维护 App attempt 的生命周期</li><li>RMContainer：维护已分配的 Container 资源使用状态</li><li>RMNode：维护 NM 在 RM 里的生命周期</li></ol><p>按照状态机的常规使用方式（一个对象维护自身的一个状态机），维护状态机的对象有下面几个</p><ol><li>RMAppImpl</li><li>RMAppAttemptImpl</li><li>RMContainerImpl</li><li>RMNodeImpl<blockquote><p>鸟窝老师开源的 <a href="https://github.com/smallnest/gofsm?tab=readme-ov-file">https://github.com/smallnest/gofsm?tab=readme-ov-file</a> 是一个 stateless fsm，等于一个 FSM 管理很多对象的状态轮转，但是2年左右没有 commit 了<br>github 上星数较多的 <a href="https://github.com/looplab/fsm">https://github.com/looplab/fsm</a> 目前看还在迭代，虽然频率低，但有 bugfix 就比没人管的强</p></blockquote></li></ol><h2 id="RMApp"><a href="#RMApp" class="headerlink" title="RMApp"></a>RMApp</h2><p>维护 App 基本信息（名称、队列、启动时间、所以运行尝试【App Attempt】 等等）</p><h2 id="RMAppState"><a href="#RMAppState" class="headerlink" title="RMAppState"></a>RMAppState</h2><p>一个 APP 所处的状态，有 11 种</p><ul><li>NEW<br>初始状态，submitApplication 被调用后，RM 初始化 RMAppImpl 时就是这个状态</li><li>NEW_SAVING<br>给 NEW 的 RMAppImpl 传入的第一个事件，用于记录 app 的基本信息，以便故障恢复</li><li>SUBMITTED<br>在合法性验证和 log saving 之后，RM 会创建一个 RMAppAttemptImpl 对象，进行第一次尝试，此时会将AppImpl状态改为Submitted</li><li>ACCEPTED<br>App 不仅要在 ClientRMService 检查，还要再调度器里检查。两个检查都通过后， App 进入 ACCEPTED 状态</li><li>RUNNING<br>当 AM 已经启动运行， RMAppAttemptImpl 此时是 Running，此时 App 就进入到 RUNNING 状态</li><li>FINAL_SAVING<br>正在保存 RMAppImpl 到存储器，当 RMStateStore 完成 App 状态更新到存储器后，这个状态将改为终态（FINISHED FAILED FINISHING KILLED）。这个状态在状态机角度是 不太好的定义， 因为他让本身的状态流转不清晰了。<br>CASE：<br>RUNNING 的 APP 接受到 ATTEMPT_FAILED 事件后，正常应该进入到 FAILED，但是现在是进到 FINAL_SAVING，同时将 targetFinalState 改成 FAILED，在 SAVING 完成后再将 targetFinalState 改到 state。</li><li>FINISHING<br>RM App 已经完成存储工作，等待 ATTEMPT_FINSIHED 的事件的状态。<br>CASE：<br>RUNNING 接受到ATTEMPT_UNREGISTERED 事件，状态改为 FINAL_SAVING，存储 targetFinalState 为 FINISHING，再接受到APP_UPDATE_SAVED 事件后，状态进入 FINISHING</li><li>FINISHED<br>AM Container 运行完成后</li><li>FAILED<br>AM 运行失败后的状态。收到 ATTEMPT_FAILED 事件后不一定立刻进入 FAILED，而是先检查失败次数是否到配置最大失败上限（默认是2），如果没有达到，则创建新的 RMAppAttempImpl，此时App状态将改为 SUBMITTED;到达最大后才进入 FAILED</li><li>KILLING<br>接受到用户KILL 操作后，先进入 FINAL_SAVING，标记 targetFinalState 为 KILLING</li><li>KILLED<br>RM主动杀死 App 后进入</li></ul><h2 id="RMAppEvent"><a href="#RMAppEvent" class="headerlink" title="RMAppEvent"></a>RMAppEvent</h2><p>状态转换事件，有 12 种<br>当 RMAppEventType 类型的事件发生时，RMAppImpl 内部会根据实际情况进行状态转移，同时触发行为（一个回调函数）</p><ul><li>STARTED<br>客户端调用 submitApplication后触发 STARTED</li><li>RECOVER<br>开启恢复后（yarn.resourcemanager.recovery.enabled），RM重启后会将已提交但未开始运行的APP发送 RECOVER 事件</li><li>KILL</li><li>NODE_UPDATE</li></ul><h2 id="状态转移列表"><a href="#状态转移列表" class="headerlink" title="状态转移列表"></a>状态转移列表</h2><p><img src="/2025/02/13/YARN-state-machine/state-transfer.png" alt="状态转移列表"></p>]]></content>
      
      
      
        <tags>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>other-learning-website</title>
      <link href="/2025/02/11/other-learning-website/"/>
      <url>/2025/02/11/other-learning-website/</url>
      
        <content type="html"><![CDATA[<h2 id="news"><a href="#news" class="headerlink" title="news"></a>news</h2><p><a href="https://zhuanlan.zhihu.com/p/440075429">https://zhuanlan.zhihu.com/p/440075429</a></p><h2 id="openstack"><a href="#openstack" class="headerlink" title="openstack"></a>openstack</h2><p><a href="https://cshihong.github.io/2018/03/08/OpenStack%E7%AE%80%E4%BB%8B/">https://cshihong.github.io/2018/03/08/OpenStack%E7%AE%80%E4%BB%8B/</a></p><h2 id="puppet"><a href="#puppet" class="headerlink" title="puppet"></a>puppet</h2><p><a href="https://www.cnblogs.com/along21/p/10369858.html">https://www.cnblogs.com/along21/p/10369858.html</a></p><h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p><a href="https://docs.jinkan.org/docs/jinja2/templates.html#id7">https://docs.jinkan.org/docs/jinja2/templates.html#id7</a><br><a href="https://www.jianshu.com/p/f04dae701361">https://www.jianshu.com/p/f04dae701361</a></p><h2 id="rust"><a href="#rust" class="headerlink" title="rust"></a>rust</h2><p><a href="https://course.rs/about-book.html">https://course.rs/about-book.html</a></p><h2 id="terraform"><a href="#terraform" class="headerlink" title="terraform"></a>terraform</h2><p><a href="https://github.com/silas/dag">https://github.com/silas/dag</a><br><a href="https://lonegunmanb.github.io/introduction-terraform/">https://lonegunmanb.github.io/introduction-terraform/</a><br><a href="https://github.com/hashicorp/go-plugin">https://github.com/hashicorp/go-plugin</a><br><a href="https://zhuanlan.zhihu.com/p/68739894">https://zhuanlan.zhihu.com/p/68739894</a></p><h2 id="go-plugin"><a href="#go-plugin" class="headerlink" title="go-plugin"></a>go-plugin</h2><p><a href="https://zhuanlan.zhihu.com/p/447311816">https://zhuanlan.zhihu.com/p/447311816</a><br><a href="https://github.com/qqzeng/go-plugin/tree/master">https://github.com/qqzeng/go-plugin/tree/master</a><br><a href="https://github.com/pingcap/tidb/blob/master/docs/design/2018-12-10-plugin-framework.md">https://github.com/pingcap/tidb/blob/master/docs/design/2018-12-10-plugin-framework.md</a></p><h2 id="cloud-provider"><a href="#cloud-provider" class="headerlink" title="cloud provider"></a>cloud provider</h2><p><a href="https://aws.amazon.com/cn/blogs/big-data/category/analytics/amazon-emr/">https://aws.amazon.com/cn/blogs/big-data/category/analytics/amazon-emr/</a><br><a href="https://docs.cloudera.com/cdp-private-cloud-upgrade/latest/upgrade-hdp/topics/hue-upg-integrate-hue-knox.html">https://docs.cloudera.com/cdp-private-cloud-upgrade/latest/upgrade-hdp/topics/hue-upg-integrate-hue-knox.html</a>?<br><a href="https://www.ibm.com/support/pages/e1603-received-when-using-impersonation-oozie-run-jobs-use-%E2%80%9Cdoas%E2%80%9D-command">https://www.ibm.com/support/pages/e1603-received-when-using-impersonation-oozie-run-jobs-use-%E2%80%9Cdoas%E2%80%9D-command</a><br><a href="https://issues.cloudera.org/browse/HUE-3989">https://issues.cloudera.org/browse/HUE-3989</a><br><a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-3x-customizeappconfig.html">https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-3x-customizeappconfig.html</a><br><a href="https://support.huaweicloud.com/devg-mrs/mrs_06_0147.html">https://support.huaweicloud.com/devg-mrs/mrs_06_0147.html</a><br><a href="https://hector.dev/2015/01/24/preparing-ec2-instance-store-with-cloud-init/">https://hector.dev/2015/01/24/preparing-ec2-instance-store-with-cloud-init/</a><br><a href="https://cloudinit.readthedocs.io/en/latest/topics/modules.html#runcmd">https://cloudinit.readthedocs.io/en/latest/topics/modules.html#runcmd</a><br><a href="https://www.ecloudrover.com/h-nd-185.html">https://www.ecloudrover.com/h-nd-185.html</a><br><a href="https://www.cnblogs.com/frankming/p/16281447.html">https://www.cnblogs.com/frankming/p/16281447.html</a><br><a href="https://www.huxiu.com/article/787695.html">https://www.huxiu.com/article/787695.html</a><br><a href="https://blog.csdn.net/qq_46110497/article/details/126751824">https://blog.csdn.net/qq_46110497/article/details/126751824</a><br><a href="https://www.youtube.com/watch?v=P_9WUIu1IDE">https://www.youtube.com/watch?v=P_9WUIu1IDE</a></p><h2 id="cloud-native"><a href="#cloud-native" class="headerlink" title="cloud native"></a>cloud native</h2><p><a href="https://juicefs.com/docs/zh/cloud/">https://juicefs.com/docs/zh/cloud/</a></p><h2 id="如何撤销-git-commit-–am"><a href="#如何撤销-git-commit-–am" class="headerlink" title="如何撤销 git commit –am"></a>如何撤销 git commit –am</h2><p><a href="https://www.jianshu.com/p/97341ed9d89e">https://www.jianshu.com/p/97341ed9d89e</a></p><h2 id="distributed"><a href="#distributed" class="headerlink" title="distributed"></a>distributed</h2><p><a href="https://terwergreen.com/post/heartbeat-detection-of-distributed-system-design-strategy.html">https://terwergreen.com/post/heartbeat-detection-of-distributed-system-design-strategy.html</a><br><a href="https://juicefs.com/zh-cn/blog/engineering/distributed-filesystem-comparison">https://juicefs.com/zh-cn/blog/engineering/distributed-filesystem-comparison</a><br><a href="https://docs.pingcap.com/zh/tidb/stable/dm-high-availability#dm-master-%E5%86%85%E9%83%A8%E6%9E%B6%E6%9E%84">https://docs.pingcap.com/zh/tidb/stable/dm-high-availability#dm-master-%E5%86%85%E9%83%A8%E6%9E%B6%E6%9E%84</a></p><h2 id="raft"><a href="#raft" class="headerlink" title="raft"></a>raft</h2><p><a href="https://www.cnblogs.com/xybaby/p/10124083.html#_label_0">https://www.cnblogs.com/xybaby/p/10124083.html#_label_0</a><br><a href="https://www.cnblogs.com/softidea/p/6517959.html">https://www.cnblogs.com/softidea/p/6517959.html</a><br><a href="https://www.cnblogs.com/mindwind/p/5231986.html">https://www.cnblogs.com/mindwind/p/5231986.html</a></p><h2 id="design-pattern"><a href="#design-pattern" class="headerlink" title="design-pattern"></a>design-pattern</h2><p><a href="https://refactoringguru.cn/design-patterns/builder">https://refactoringguru.cn/design-patterns/builder</a></p><h2 id="maven"><a href="#maven" class="headerlink" title="maven"></a>maven</h2><p><a href="https://blog.csdn.net/yangguosb/article/details/80619481">https://blog.csdn.net/yangguosb/article/details/80619481</a></p><h2 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h2><p><a href="https://www.cnblogs.com/lirunzhou/p/9564909.html">https://www.cnblogs.com/lirunzhou/p/9564909.html</a><br><a href="https://yeasy.gitbook.io/docker_practice/image/dockerfile/copy">https://yeasy.gitbook.io/docker_practice/image/dockerfile/copy</a><br><a href="https://www.lixueduan.com/posts/docker/03-container-core/#3-%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E7%9A%84%E7%A7%98%E5%AF%86">https://www.lixueduan.com/posts/docker/03-container-core/#3-%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E7%9A%84%E7%A7%98%E5%AF%86</a></p><h2 id="other"><a href="#other" class="headerlink" title="other"></a>other</h2><p><a href="https://gitcode.net/open-source-lab/List-of-Chinese-Open-Source-Project-Financing/-/tree/master">https://gitcode.net/open-source-lab/List-of-Chinese-Open-Source-Project-Financing/-/tree/master</a><br><a href="https://segmentfault.com/a/1190000009652120">https://segmentfault.com/a/1190000009652120</a><br><a href="https://blog.csdn.net/wyzidu/article/details/117789524">https://blog.csdn.net/wyzidu/article/details/117789524</a><br><a href="https://baijiahao.baidu.com/s?id=1766310273312312257&wfr=spider&for=pc">https://baijiahao.baidu.com/s?id=1766310273312312257&amp;wfr=spider&amp;for=pc</a><br><a href="https://github.com/yifengyou/learn-kvm">https://github.com/yifengyou/learn-kvm</a><br><a href="https://zhuanlan.zhihu.com/p/143173278?utm_id=0">https://zhuanlan.zhihu.com/p/143173278?utm_id=0</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI2MTk1NDY0Mw==&mid=2247483661&idx=1&sn=59a6f5b31b3b38e6e8080682f6f323d0&chksm=ea53cc31dd2445273b8dcb032a699ad90faf9b2562f8c4711ec38a82b879a7d8346edea07378&scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzI2MTk1NDY0Mw==&amp;mid=2247483661&amp;idx=1&amp;sn=59a6f5b31b3b38e6e8080682f6f323d0&amp;chksm=ea53cc31dd2445273b8dcb032a699ad90faf9b2562f8c4711ec38a82b879a7d8346edea07378&amp;scene=21#wechat_redirect</a><br><a href="https://blog.51cto.com/aishangwei/2124526">https://blog.51cto.com/aishangwei/2124526</a><br><a href="https://github.com/senghoo/golang-design-pattern/tree/master">https://github.com/senghoo/golang-design-pattern/tree/master</a><br><a href="https://www.xiaolincoding.com/os/3_memory/linux_mem.html#_5-%E8%BF%9B%E7%A8%8B%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4%E7%9A%84%E7%AE%A1%E7%90%86">https://www.xiaolincoding.com/os/3_memory/linux_mem.html#_5-%E8%BF%9B%E7%A8%8B%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4%E7%9A%84%E7%AE%A1%E7%90%86</a><br><a href="https://juicefs.com/zh-cn/blog/engineering/go-build-billion-file-system">https://juicefs.com/zh-cn/blog/engineering/go-build-billion-file-system</a><br><a href="https://zhuanlan.zhihu.com/p/619266527">https://zhuanlan.zhihu.com/p/619266527</a><br><a href="https://zhuanlan.zhihu.com/p/533845321?utm_id=0">https://zhuanlan.zhihu.com/p/533845321?utm_id=0</a><br><a href="https://www.junmajinlong.com/linux/systemd/service_2/index.html">https://www.junmajinlong.com/linux/systemd/service_2/index.html</a><br><a href="https://www.calvinneo.com/">https://www.calvinneo.com/</a></p><h2 id="for-interview"><a href="#for-interview" class="headerlink" title="for interview"></a>for interview</h2><p><a href="https://labuladong.online/algo/">https://labuladong.online/algo/</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzU0OTE4MzYzMw==&mid=2247517079&idx=2&sn=6406008df0b99ee3d97bbceaa278f2f2&chksm=fbb10a69ccc6837fde5639b70b4c8ef4f0902f3b728dd4f9a4bded687cac5ff8998af17e0719&scene=27">https://mp.weixin.qq.com/s?__biz=MzU0OTE4MzYzMw==&amp;mid=2247517079&amp;idx=2&amp;sn=6406008df0b99ee3d97bbceaa278f2f2&amp;chksm=fbb10a69ccc6837fde5639b70b4c8ef4f0902f3b728dd4f9a4bded687cac5ff8998af17e0719&amp;scene=27</a><br><a href="https://github.com/jwasham/coding-interview-university">https://github.com/jwasham/coding-interview-university</a></p><h2 id="online-tools"><a href="#online-tools" class="headerlink" title="online tools"></a>online tools</h2><p><a href="https://j2live.ttl255.com/">https://j2live.ttl255.com/</a><br><a href="https://tool.box3.cn/xml-validator.html">https://tool.box3.cn/xml-validator.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> learn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bigdata-learning-website</title>
      <link href="/2025/02/10/bigdata-learning-website/"/>
      <url>/2025/02/10/bigdata-learning-website/</url>
      
        <content type="html"><![CDATA[<h2 id="ambari"><a href="#ambari" class="headerlink" title="ambari"></a>ambari</h2><p><a href="https://hijiazz.gitee.io/ambari-kerberos-descriptior/">https://hijiazz.gitee.io/ambari-kerberos-descriptior/</a><br><a href="https://cwiki.apache.org/confluence/display/AMBARI/Automated+Kerberizaton">https://cwiki.apache.org/confluence/display/AMBARI/Automated+Kerberizaton</a><br><a href="https://blog.csdn.net/ZYC88888/article/details/116496591">https://blog.csdn.net/ZYC88888/article/details/116496591</a><br><a href="https://www.jianshu.com/p/7b9f280b9d73">https://www.jianshu.com/p/7b9f280b9d73</a><br><a href="https://community.cloudera.com/t5/Support-Questions/How-do-I-create-config-group-through-Ambari-Blueprint/td-p/136029">https://community.cloudera.com/t5/Support-Questions/How-do-I-create-config-group-through-Ambari-Blueprint/td-p/136029</a><br><a href="https://www.cnblogs.com/mymelody/p/9435861.html">https://www.cnblogs.com/mymelody/p/9435861.html</a><br><a href="https://github.com/fayson/cdhproject">https://github.com/fayson/cdhproject</a><br><a href="https://blog.csdn.net/a11en_03/article/details/118656653">https://blog.csdn.net/a11en_03/article/details/118656653</a><br><a href="https://cwiki.apache.org/confluence/display/AMBARI/Blueprints#Blueprints-Step2:RegisterBlueprintwithAmbari">https://cwiki.apache.org/confluence/display/AMBARI/Blueprints#Blueprints-Step2:RegisterBlueprintwithAmbari</a><br><a href="https://www.cnblogs.com/basenet855x/p/6782673.html">https://www.cnblogs.com/basenet855x/p/6782673.html</a><br><a href="https://www.jianshu.com/p/2fc3325ab91d">https://www.jianshu.com/p/2fc3325ab91d</a><br><a href="https://blog.csdn.net/devalone/article/details/80781652">https://blog.csdn.net/devalone/article/details/80781652</a><br><a href="https://www.shouxicto.com/article/1943.html">https://www.shouxicto.com/article/1943.html</a><br><a href="https://blog.csdn.net/yeruby/article/details/51167879">https://blog.csdn.net/yeruby/article/details/51167879</a><br><a href="https://blog.csdn.net/qq_37865420/article/details/107183986">https://blog.csdn.net/qq_37865420/article/details/107183986</a><br><a href="https://github.com/cloudera/cm_api">https://github.com/cloudera/cm_api</a></p><h2 id="airflow"><a href="#airflow" class="headerlink" title="airflow"></a>airflow</h2><p><a href="https://gitchat.cn/books/5db9939362adeb3006d193f9/index.html#airflow">https://gitchat.cn/books/5db9939362adeb3006d193f9/index.html#airflow</a><br><a href="https://stackoverflow.com/questions/50365024/apache-airflow-sparksqloperator-keeps-printing-empty-logs">https://stackoverflow.com/questions/50365024/apache-airflow-sparksqloperator-keeps-printing-empty-logs</a><br><a href="https://www.coder.work/article/6720186">https://www.coder.work/article/6720186</a><br><a href="https://www.cnblogs.com/chenboshi/p/13179169.html">https://www.cnblogs.com/chenboshi/p/13179169.html</a><br><a href="https://github.com/apache/airflow/issues/23679">https://github.com/apache/airflow/issues/23679</a><br><a href="https://segmentfault.com/a/1190000041323240">https://segmentfault.com/a/1190000041323240</a><br><a href="https://zhuanlan.zhihu.com/p/517364346">https://zhuanlan.zhihu.com/p/517364346</a><br><a href="https://zhuanlan.zhihu.com/p/352989254">https://zhuanlan.zhihu.com/p/352989254</a><br><a href="https://www.jianshu.com/p/0339928062b5">https://www.jianshu.com/p/0339928062b5</a></p><h2 id="flink"><a href="#flink" class="headerlink" title="flink"></a>flink</h2><p><a href="https://zhuanlan.zhihu.com/p/117654469">https://zhuanlan.zhihu.com/p/117654469</a><br><a href="https://zhuanlan.zhihu.com/p/89616731">https://zhuanlan.zhihu.com/p/89616731</a><br><a href="https://www.jianshu.com/p/9dfd932af0af">https://www.jianshu.com/p/9dfd932af0af</a><br><a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a><br><a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/</a><br><a href="https://juejin.cn/post/7041008470031597575">https://juejin.cn/post/7041008470031597575</a></p><h2 id="atlas"><a href="#atlas" class="headerlink" title="atlas"></a>atlas</h2><p><a href="http://www.360doc.com/content/20/0725/11/22849536_926642448.shtml">http://www.360doc.com/content/20/0725/11/22849536_926642448.shtml</a></p><h2 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h2><p><a href="https://hexiaoqiao.github.io/blog/2016/09/04/hdfs-centralized-cache-management/">https://hexiaoqiao.github.io/blog/2016/09/04/hdfs-centralized-cache-management/</a><br><a href="https://hexiaoqiao.github.io/blog/2017/02/12/namenode-restart-optimization/">https://hexiaoqiao.github.io/blog/2017/02/12/namenode-restart-optimization/</a><br><a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html">https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html</a><br><a href="https://jiamaoxiang.top/2019/12/03/CDH%E9%9B%86%E7%BE%A4%E4%B9%8BYARN%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/">https://jiamaoxiang.top/2019/12/03/CDH%E9%9B%86%E7%BE%A4%E4%B9%8BYARN%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</a><br><a href="https://blog.csdn.net/u012151684/article/details/107926103">https://blog.csdn.net/u012151684/article/details/107926103</a><br><a href="https://www.cnblogs.com/lixiaolun/p/6897706.html">https://www.cnblogs.com/lixiaolun/p/6897706.html</a><br><a href="https://infra.apache.org/jira-guidelines.html#who">https://infra.apache.org/jira-guidelines.html#who</a><br><a href="https://blog.csdn.net/hncscwc/article/details/124358282">https://blog.csdn.net/hncscwc/article/details/124358282</a><br><a href="https://www.jianshu.com/p/617fa722e057">https://www.jianshu.com/p/617fa722e057</a><br><a href="https://levy.at/blog/22">https://levy.at/blog/22</a></p><h2 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h2><p><a href="http://hbasefly.com/category/hbase/">http://hbasefly.com/category/hbase/</a><br><a href="https://www.cnblogs.com/zhangwuji/p/9195806.html">https://www.cnblogs.com/zhangwuji/p/9195806.html</a><br><a href="https://zhuanlan.zhihu.com/p/70365703">https://zhuanlan.zhihu.com/p/70365703</a><br><a href="https://blog.csdn.net/mt0803/article/details/9372227">https://blog.csdn.net/mt0803/article/details/9372227</a><br><a href="https://blog.csdn.net/a772304419/article/details/118084764">https://blog.csdn.net/a772304419/article/details/118084764</a><br><a href="https://tech.youzan.com/hbase-read-optimization-practice/">https://tech.youzan.com/hbase-read-optimization-practice/</a><br><a href="http://openinx.github.io/2019/09/10/tuning-the-hbase-2-write-performance/">http://openinx.github.io/2019/09/10/tuning-the-hbase-2-write-performance/</a><br><a href="https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_hbase_blockcache_configure.html#concept_pqk_smz_dr">https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_hbase_blockcache_configure.html#concept_pqk_smz_dr</a><br><a href="http://hbasefly.com/2016/09/08/hbase-rit/?ogxgrs=oea8a1">http://hbasefly.com/2016/09/08/hbase-rit/?ogxgrs=oea8a1</a><br><a href="https://www.cnblogs.com/ios123/p/6410986.html">https://www.cnblogs.com/ios123/p/6410986.html</a></p><h2 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h2><p><a href="https://www.cnblogs.com/yjt1993/p/11050791.html">https://www.cnblogs.com/yjt1993/p/11050791.html</a></p><h2 id="hudi"><a href="#hudi" class="headerlink" title="hudi"></a>hudi</h2><p><a href="https://zhuanlan.zhihu.com/p/131210053">https://zhuanlan.zhihu.com/p/131210053</a></p><h2 id="hue"><a href="#hue" class="headerlink" title="hue"></a>hue</h2><p><a href="https://github.com/cloudera/hue/issues">https://github.com/cloudera/hue/issues</a><br><a href="https://docs.gethue.com/administrator/configuration/connectors/#apache-spark-sql">https://docs.gethue.com/administrator/configuration/connectors/#apache-spark-sql</a><br><a href="https://gethue.com/blog/querying-spark-sql-with-spark-thrift-server-and-hue-editor/">https://gethue.com/blog/querying-spark-sql-with-spark-thrift-server-and-hue-editor/</a><br><a href="https://github.com/cloudera/hue/issues/2252">https://github.com/cloudera/hue/issues/2252</a><br><a href="https://github.com/cloudera/hue/issues/850">https://github.com/cloudera/hue/issues/850</a><br><a href="https://github.com/gethue/PyHive">https://github.com/gethue/PyHive</a><br><a href="https://github.com/cloudera/hue/issues/1843">https://github.com/cloudera/hue/issues/1843</a><br><a href="https://github.com/cloudera/hue/blob/fd5cbb9edf88ace944d021ada8e0a6d3972686ca/apps/beeswax/src/beeswax/server/hive_server2_lib.py#L790">https://github.com/cloudera/hue/blob/fd5cbb9edf88ace944d021ada8e0a6d3972686ca/apps/beeswax/src/beeswax/server/hive_server2_lib.py#L790</a><br><a href="https://gethue.com/blog/quick-task-sql-editor-for-apache-spark-sql-with-livy/">https://gethue.com/blog/quick-task-sql-editor-for-apache-spark-sql-with-livy/</a></p><h2 id="impala"><a href="#impala" class="headerlink" title="impala"></a>impala</h2><p><a href="http://dongxicheng.org/olap/impala-in-hulu/">http://dongxicheng.org/olap/impala-in-hulu/</a></p><h2 id="knox"><a href="#knox" class="headerlink" title="knox"></a>knox</h2><p><a href="https://github.com/wbwangk/wbwangk.github.io/wiki/knox%E6%B5%8B%E8%AF%95">https://github.com/wbwangk/wbwangk.github.io/wiki/knox%E6%B5%8B%E8%AF%95</a><br><a href="https://knox.apache.org/books/knox-1-5-0/user-guide.html#Introduction">https://knox.apache.org/books/knox-1-5-0/user-guide.html#Introduction</a><br><a href="https://cwiki.apache.org/confluence/display/KNOX/2017/08/14/Understanding+Rewrite+Rules+for+Apache+Knox#UnderstandingRewriteRulesforApacheKnox-Simpleservicerule">https://cwiki.apache.org/confluence/display/KNOX/2017/08/14/Understanding+Rewrite+Rules+for+Apache+Knox#UnderstandingRewriteRulesforApacheKnox-Simpleservicerule</a><br><a href="https://knox.apache.org/">https://knox.apache.org/</a><br><a href="https://cwiki.apache.org/confluence/display/KNOX/2017/08/14/Understanding+Rewrite+Rules+for+Apache+Knox">https://cwiki.apache.org/confluence/display/KNOX/2017/08/14/Understanding+Rewrite+Rules+for+Apache+Knox</a><br><a href="https://www.cnblogs.com/yinzhengjie/p/10096385.html">https://www.cnblogs.com/yinzhengjie/p/10096385.html</a><br><a href="https://support.huaweicloud.com/prtg-hdp-kunpengbds/kunpengknoxhdp_02_0013.html">https://support.huaweicloud.com/prtg-hdp-kunpengbds/kunpengknoxhdp_02_0013.html</a></p><h2 id="livy"><a href="#livy" class="headerlink" title="livy"></a>livy</h2><p><a href="https://livy.incubator.apache.org/docs/latest/rest-api.html#session-kind">https://livy.incubator.apache.org/docs/latest/rest-api.html#session-kind</a><br><a href="https://cloud.tencent.com/developer/article/1194694">https://cloud.tencent.com/developer/article/1194694</a></p><h2 id="oozie"><a href="#oozie" class="headerlink" title="oozie"></a>oozie</h2><p><a href="https://www.cnblogs.com/rossiXYZ/p/13210197.html">https://www.cnblogs.com/rossiXYZ/p/13210197.html</a><br><a href="https://oozie.apache.org/docs/5.1.0/AG_Install.html">https://oozie.apache.org/docs/5.1.0/AG_Install.html</a><br><a href="https://issues.apache.org/jira/secure/attachment/12972188/OOZIE-3516-001.patch">https://issues.apache.org/jira/secure/attachment/12972188/OOZIE-3516-001.patch</a><br><a href="https://docs.cloudera.com/cloudera-manager/7.4.2/configuration-properties/topics/cm_props_cdh720_oozie.html">https://docs.cloudera.com/cloudera-manager/7.4.2/configuration-properties/topics/cm_props_cdh720_oozie.html</a><br><a href="https://ken-ljq.github.io/2019/use-the-sharelib-in-apache-oozie-cdh5/">https://ken-ljq.github.io/2019/use-the-sharelib-in-apache-oozie-cdh5/</a><br><a href="http://www.manongjc.com/detail/50-upilvlrmlolqqqn.html">http://www.manongjc.com/detail/50-upilvlrmlolqqqn.html</a><br><a href="https://cloud.tencent.com/developer/article/1693315">https://cloud.tencent.com/developer/article/1693315</a></p><h2 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h2><p><a href="https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/ebook-sign-up/">https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/ebook-sign-up/</a><br><a href="https://github.com/databricks/Spark-The-Definitive-Guide">https://github.com/databricks/Spark-The-Definitive-Guide</a><br><a href="http://faculty.neu.edu.cn/cc/zhangyf/book/spark.pdf">http://faculty.neu.edu.cn/cc/zhangyf/book/spark.pdf</a><br><a href="https://www.cnblogs.com/itboys/p/10370304.html">https://www.cnblogs.com/itboys/p/10370304.html</a><br><a href="https://issues.apache.org/jira/browse/SPARK-32838">https://issues.apache.org/jira/browse/SPARK-32838</a></p><h2 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h2><p><a href="https://blog.csdn.net/wsdc0521/article/details/108445041">https://blog.csdn.net/wsdc0521/article/details/108445041</a><br><a href="https://blog.csdn.net/hncscwc/article/details/128359113">https://blog.csdn.net/hncscwc/article/details/128359113</a><br><a href="https://blog.csdn.net/zhusirong/article/details/83624242">https://blog.csdn.net/zhusirong/article/details/83624242</a><br><a href="https://blog.csdn.net/u013384984/article/details/80296286?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-80296286-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-80296286-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=4">https://blog.csdn.net/u013384984/article/details/80296286?spm=1001.2101.3001.6650.3&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-80296286-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-80296286-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&amp;utm_relevant_index=4</a><br><a href="https://blog.csdn.net/zhusirong/article/details/83621048?spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-83621048-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-4-83621048-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=5">https://blog.csdn.net/zhusirong/article/details/83621048?spm=1001.2101.3001.6650.4&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-83621048-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-83621048-blog-83624242.pc_relevant_3mothn_strategy_and_data_recovery&amp;utm_relevant_index=5</a><br><a href="https://blog.csdn.net/zhusirong/category_6949430.html">https://blog.csdn.net/zhusirong/category_6949430.html</a><br><a href="https://www.cnblogs.com/love-yh/p/13894421.html">https://www.cnblogs.com/love-yh/p/13894421.html</a></p><h2 id="zeppelin"><a href="#zeppelin" class="headerlink" title="zeppelin"></a>zeppelin</h2><p><a href="https://blog.csdn.net/zyzzxycj/article/details/80762472">https://blog.csdn.net/zyzzxycj/article/details/80762472</a></p><h2 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h2><p><a href="https://cloud.tencent.com/developer/article/1516691">https://cloud.tencent.com/developer/article/1516691</a><br><a href="https://issues.apache.org/jira/browse/ZOOKEEPER-706">https://issues.apache.org/jira/browse/ZOOKEEPER-706</a></p><h2 id="dolphin-scheduler"><a href="#dolphin-scheduler" class="headerlink" title="dolphin scheduler"></a>dolphin scheduler</h2><p><a href="https://blog.csdn.net/DolphinScheduler/article/details/118948803">https://blog.csdn.net/DolphinScheduler/article/details/118948803</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> learn </tag>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-learning-website</title>
      <link href="/2025/02/09/Go-learning-website/"/>
      <url>/2025/02/09/Go-learning-website/</url>
      
        <content type="html"><![CDATA[<h2 id="大牛博客博文"><a href="#大牛博客博文" class="headerlink" title="大牛博客博文"></a>大牛博客博文</h2><p><a href="https://golang2.eddycjy.com/posts/ch2/01-simple-server/">https://golang2.eddycjy.com/posts/ch2/01-simple-server/</a><br><a href="https://colobu.com/">https://colobu.com/</a><br><a href="https://tonybai.com/">https://tonybai.com/</a><br><a href="https://draveness.me/golang/">https://draveness.me/golang/</a><br><a href="https://books.studygolang.com/">https://books.studygolang.com/</a><br><a href="https://medium.com/scum-gazeta/golang-simple-optimization-notes-70bc64673980">https://medium.com/scum-gazeta/golang-simple-optimization-notes-70bc64673980</a><br><a href="https://talkgo.org/">https://talkgo.org/</a><br><a href="https://www.calvinneo.com/">https://www.calvinneo.com</a><br><a href="https://juicefs.com/zh-cn/blog/engineering/go-build-billion-file-system">https://juicefs.com/zh-cn/blog/engineering/go-build-billion-file-system</a></p><h2 id="service-weaver"><a href="#service-weaver" class="headerlink" title="service weaver"></a>service weaver</h2><p><a href="https://cloud.tencent.com/developer/article/2236252">https://cloud.tencent.com/developer/article/2236252</a></p><h2 id="gcache"><a href="#gcache" class="headerlink" title="gcache"></a>gcache</h2><p><a href="https://github.com/bluele/gcache">https://github.com/bluele/gcache</a></p><h2 id="Go-社区推荐的项目组织"><a href="#Go-社区推荐的项目组织" class="headerlink" title="Go 社区推荐的项目组织"></a>Go 社区推荐的项目组织</h2><p><a href="https://giaogiaocat.github.io/go/go-project-structure/">https://giaogiaocat.github.io/go/go-project-structure/</a><br>实际上也因人而异,有的目录我并不喜欢</p><h2 id="Go-template"><a href="#Go-template" class="headerlink" title="Go template"></a>Go template</h2><p><a href="https://cloud.tencent.com/developer/section/1145004">https://cloud.tencent.com/developer/section/1145004</a></p><h2 id="怎么编写可维护的-Go-代码"><a href="#怎么编写可维护的-Go-代码" class="headerlink" title="怎么编写可维护的 Go 代码"></a>怎么编写可维护的 Go 代码</h2><p><a href="https://jogendra.dev/writing-maintainable-go-code">https://jogendra.dev/writing-maintainable-go-code</a></p><h2 id="怎么用泛型"><a href="#怎么用泛型" class="headerlink" title="怎么用泛型"></a>怎么用泛型</h2><p><a href="https://github.com/yougg/gonote/blob/main/gogrammar.md#%E6%B3%9B%E5%9E%8B-generics-go118">https://github.com/yougg/gonote/blob/main/gogrammar.md#%E6%B3%9B%E5%9E%8B-generics-go118</a></p><h2 id="web-服务器使用证书认证客户端"><a href="#web-服务器使用证书认证客户端" class="headerlink" title="web 服务器使用证书认证客户端"></a>web 服务器使用证书认证客户端</h2><p><a href="https://blog.csdn.net/zhengzizhi/article/details/73720069">https://blog.csdn.net/zhengzizhi/article/details/73720069</a></p><h2 id="Go-plugin"><a href="#Go-plugin" class="headerlink" title="Go plugin"></a>Go plugin</h2><p><a href="https://tonybai.com/2021/07/19/understand-go-plugin/">https://tonybai.com/2021/07/19/understand-go-plugin/</a></p><h2 id="rpcx"><a href="#rpcx" class="headerlink" title="rpcx"></a>rpcx</h2><p><a href="https://doc.rpcx.io/part1/quickstart.html">https://doc.rpcx.io/part1/quickstart.html</a></p><h2 id="Go-leveldb"><a href="#Go-leveldb" class="headerlink" title="Go leveldb"></a>Go leveldb</h2><p><a href="https://www.jianshu.com/p/158be75740e8">https://www.jianshu.com/p/158be75740e8</a></p><h2 id="cobra"><a href="#cobra" class="headerlink" title="cobra"></a>cobra</h2><p><a href="https://www.jianshu.com/p/e97f64253313">https://www.jianshu.com/p/e97f64253313</a></p><h2 id="os-exec"><a href="#os-exec" class="headerlink" title="os&#x2F;exec"></a>os&#x2F;exec</h2><p><a href="https://colobu.com/2017/06/19/advanced-command-execution-in-Go-with-os-exec/">https://colobu.com/2017/06/19/advanced-command-execution-in-Go-with-os-exec/</a></p><h2 id="string-和-byte-转化-各种方式对比"><a href="#string-和-byte-转化-各种方式对比" class="headerlink" title="string 和 []byte 转化 各种方式对比"></a>string 和 []byte 转化 各种方式对比</h2><p><a href="https://blog.csdn.net/slphahaha/article/details/109405685">https://blog.csdn.net/slphahaha/article/details/109405685</a></p><h2 id="GC-分析"><a href="#GC-分析" class="headerlink" title="GC 分析"></a>GC 分析</h2><p><a href="https://mp.weixin.qq.com/s/AaHk-yg8D4atbO-zVAvhKQ">https://mp.weixin.qq.com/s/AaHk-yg8D4atbO-zVAvhKQ</a></p><h2 id="工程化规范"><a href="#工程化规范" class="headerlink" title="工程化规范"></a>工程化规范</h2><p><a href="https://mp.weixin.qq.com/s/1cy0vbiU5MZNVazvOsMf5Q">https://mp.weixin.qq.com/s/1cy0vbiU5MZNVazvOsMf5Q</a></p><h2 id="Go-hdfs-client"><a href="#Go-hdfs-client" class="headerlink" title="Go hdfs client"></a>Go hdfs client</h2><p><a href="https://vimsky.com/examples/detail/golang-ex-github.com.colinmarc.hdfs-Client---class.html">https://vimsky.com/examples/detail/golang-ex-github.com.colinmarc.hdfs-Client---class.html</a><br><a href="https://github.com/colinmarc/hdfs">https://github.com/colinmarc/hdfs</a></p><h2 id="Go-native-python"><a href="#Go-native-python" class="headerlink" title="Go native python"></a>Go native python</h2><p><a href="https://linux.cn/article-13564-1.html">https://linux.cn/article-13564-1.html</a></p><h2 id="xml-parser"><a href="#xml-parser" class="headerlink" title="xml parser"></a>xml parser</h2><p><a href="https://blog.csdn.net/xiazhipeng1000/article/details/112737808">https://blog.csdn.net/xiazhipeng1000/article/details/112737808</a></p><h2 id="use-etcd-campaign"><a href="#use-etcd-campaign" class="headerlink" title="use etcd campaign"></a>use etcd campaign</h2><p><a href="https://blog.csdn.net/liyunlong41/article/details/107619563">https://blog.csdn.net/liyunlong41/article/details/107619563</a><br>PINGCAP 的 dm-migration 项目里,dm-master 有使用 etcd 选主样例,很棒<br><a href="https://docs.pingcap.com/zh/tidb/stable/dm-high-availability#dm-master-%E5%86%85%E9%83%A8%E6%9E%B6%E6%9E%84">https://docs.pingcap.com/zh/tidb/stable/dm-high-availability#dm-master-%E5%86%85%E9%83%A8%E6%9E%B6%E6%9E%84</a><br><a href="https://docs.pingcap.com/tidb/stable/dm-arch">https://docs.pingcap.com/tidb/stable/dm-arch</a><br><a href="https://github.com/pingcap/tiflow/tree/release-8.5/dm/master">https://github.com/pingcap/tiflow/tree/release-8.5/dm/master</a></p><h2 id="goroutine-异步通知-error"><a href="#goroutine-异步通知-error" class="headerlink" title="goroutine 异步通知 error"></a>goroutine 异步通知 error</h2><p><a href="https://www.jianshu.com/p/5e7ce22d9831">https://www.jianshu.com/p/5e7ce22d9831</a><br><a href="https://www.jianshu.com/p/edf03d5bd37e">https://www.jianshu.com/p/edf03d5bd37e</a></p><h2 id="omitempty"><a href="#omitempty" class="headerlink" title="omitempty"></a>omitempty</h2><p><a href="https://old-panda.com/2019/12/11/golang-omitempty/">https://old-panda.com/2019/12/11/golang-omitempty/</a></p><h2 id="选项设计模式"><a href="#选项设计模式" class="headerlink" title="选项设计模式"></a>选项设计模式</h2><p><a href="https://learnku.com/articles/69465">https://learnku.com/articles/69465</a></p><h2 id="高性能编程"><a href="#高性能编程" class="headerlink" title="高性能编程"></a>高性能编程</h2><p><a href="https://mp.weixin.qq.com/s/Lv2XTD-SPnxT2vnPNeREbg">https://mp.weixin.qq.com/s/Lv2XTD-SPnxT2vnPNeREbg</a></p><h2 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h2><p><a href="https://blog.csdn.net/yzf279533105/article/details/90450715">https://blog.csdn.net/yzf279533105/article/details/90450715</a></p><h2 id="vscode-debug-setting"><a href="#vscode-debug-setting" class="headerlink" title="vscode debug setting"></a>vscode debug setting</h2><p><a href="https://promacanthus.netlify.app/ide/vscode/03-%E8%B0%83%E8%AF%95golang%E4%BB%A3%E7%A0%81/">https://promacanthus.netlify.app/ide/vscode/03-%E8%B0%83%E8%AF%95golang%E4%BB%A3%E7%A0%81/</a><br><a href="https://blog.csdn.net/wl18271672781/article/details/127792747">https://blog.csdn.net/wl18271672781/article/details/127792747</a></p><h2 id="distributed-task-scheduling"><a href="#distributed-task-scheduling" class="headerlink" title="distributed task scheduling"></a>distributed task scheduling</h2><p><a href="https://github.com/imlgw/scheduler#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%81%8F%E5%90%91">https://github.com/imlgw/scheduler#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%81%8F%E5%90%91</a></p><h2 id="无锁队列结构"><a href="#无锁队列结构" class="headerlink" title="无锁队列结构"></a>无锁队列结构</h2><p><a href="https://github.com/smallnest/queue/blob/master/lockfree_queue.go">https://github.com/smallnest/queue/blob/master/lockfree_queue.go</a><br>其实 channel 更 native,但是也有用这个的时候</p><h2 id="单测"><a href="#单测" class="headerlink" title="单测"></a>单测</h2><p><a href="https://cloud.tencent.com/developer/article/1872029">https://cloud.tencent.com/developer/article/1872029</a><br><a href="https://www.yht7.com/news/194722">https://www.yht7.com/news/194722</a><br><a href="https://bou.ke/blog/monkey-patching-in-go/">https://bou.ke/blog/monkey-patching-in-go/</a></p><h2 id="pprof"><a href="#pprof" class="headerlink" title="pprof"></a>pprof</h2><p><a href="https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-pprof">https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-pprof</a><br><a href="https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-trace">https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-trace</a><br><a href="https://github.com/loadlj/blog/issues/32">https://github.com/loadlj/blog/issues/32</a><br><a href="https://debug-lixiwen.github.io/2021/07/18/shi-zhan/#toc-heading-3">https://debug-lixiwen.github.io/2021/07/18/shi-zhan/#toc-heading-3</a></p><h2 id="面试宝典"><a href="#面试宝典" class="headerlink" title="面试宝典"></a>面试宝典</h2><p><a href="https://github.com/golang-design/go-questions">https://github.com/golang-design/go-questions</a><br>bilibili 关注了个 up 主 golang 老周,也不错</p><h2 id="gin-middleware"><a href="#gin-middleware" class="headerlink" title="gin middleware"></a>gin middleware</h2><p><a href="https://www.cnblogs.com/jiujuan/p/13069995.html">https://www.cnblogs.com/jiujuan/p/13069995.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> learn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>what-does-Go-do-when-starting-app</title>
      <link href="/2025/02/08/what-does-Go-do-when-starting-app/"/>
      <url>/2025/02/08/what-does-Go-do-when-starting-app/</url>
      
        <content type="html"><![CDATA[<h2 id="go-的服务启动时做了什么"><a href="#go-的服务启动时做了什么" class="headerlink" title="go 的服务启动时做了什么"></a>go 的服务启动时做了什么</h2><p><img src="/2025/02/08/what-does-Go-do-when-starting-app/goapp-start-process.png" alt="go-的服务启动时流程简图"><br>真正的开始: 其实是 runtime.rt0_go(SB) 这样的汇编代码<br>runtime.check 代表去检查当前 OS 的信息,确定一些类型的基本<br>runtime.schedinit 是初始化调度器,也就是 P<br>newproc 是启动一个准备运行 main 的协程<br>runtime.mstart 是启动一个 m 去运行上一步的 newproc</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-philosophy</title>
      <link href="/2025/02/08/Go-philosophy/"/>
      <url>/2025/02/08/Go-philosophy/</url>
      
        <content type="html"><![CDATA[<h2 id="Go-的设计哲学杂谈"><a href="#Go-的设计哲学杂谈" class="headerlink" title="Go 的设计哲学杂谈"></a>Go 的设计哲学杂谈</h2><p>这篇博客是 “Go 设计哲学” 中第一篇博客,启动这个系列是为了总结一下这几年写 Go 过程中,我的一些心得和体会.<br>我学生时期是完全写 java 的,包括在第一份工作里也是99%用 java,主要是开发 web 项目和开源的大数据组件(hadoop hive sqoop 等)<br>来到度厂之后呢,开始逐渐转向写 Go.<br>在我的意识里,语言从来只是工具,无论用 Go java C++ 还是什么其他的后端语言,都有路径完成需求.<br>但当我真正转到 Go 后,我发现语言之间不只是 谁因为某些特性更擅长某个领域,又因为这些特性在某个领域拉胯 在业务领域实现上的彼消我长,<br>还有在开发者角度的易用性,开发效率,debug 流程等等.<br>毕竟,编程语言也可以看成一个产品,而这个产品的用户就是开发者.<br>Go 的设计初衷其实是 google 大佬们为了解决 C++ 的一些问题,比如:</p><p>在多 CPU,复杂网络情况下,网络编程模型遇到的问题只能各种规避,而不是彻底解决<br>软件复杂(比如代码行数很多,feature多,多人协作)带来的问题<br>编译太慢<br>我自己翻译过来,Go 的设计目标有:<br>简化在现代 OS 和网络环境下的并发编程 -&gt; GMP<br>好的依赖管理 -&gt; go module<br>光速编译,同时能交叉编译 -&gt; go build<br>Go 的设计哲学可以看煎鱼的教学里的开篇 <a href="https://golang3.eddycjy.com/posts/started-go/">https://golang3.eddycjy.com/posts/started-go/</a></p><h2 id="依赖管理"><a href="#依赖管理" class="headerlink" title="依赖管理"></a>依赖管理</h2><p>老牌的语言都有自己的依赖管理工具,比如:<br>java 的 ant maven gradle<br>python 的 pipenv conda 等<br>Go 用了一个很 trick 但是很聪明的方式: github + Go mod + Go package</p><h2 id="github"><a href="#github" class="headerlink" title="github"></a>github</h2><p>github 是指项目代码库,私有的 gitlab, 公司内部 icode 等等都一样,当自己的项目引用其他项目的某个版本的时候,直接从仓库里获取指定的源码.<br>这样就不用专门开发类似 maven repo 的概念来维护各种版本了,然后把 repo 里各个版本的生命周期也交给 github 来维护.<br>你会说假如有一天 github 挂了,那不是没法编译了吗?<br>是的,但真有这一天吗?就算有,只要你编译过了,本地也有 gomod 缓存,至多是一些新的依赖下不了,不会造成太过毁灭的结果.</p><h2 id="go-mod"><a href="#go-mod" class="headerlink" title="go mod"></a>go mod</h2><p>Go mod 本身是为了解决 GOPATH 构建时代 “依赖地狱” 问题的.<br>详细的可以看这篇博客:<a href="https://dive2cloud-bmz.github.io/2025/02/10/Go-%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/#%E5%8C%85%E5%86%B2%E7%AA%81">https://dive2cloud-bmz.github.io/2025/02/10/Go-程序的构建过程/#包冲突</a></p><h2 id="Go-package"><a href="#Go-package" class="headerlink" title="Go package"></a>Go package</h2><p>在讲 Go package 之前,我们先来看看 java 的包名.<br>比如 Hello.java 的文件第一行, com.bmz.demo<br>Hello.java 的文件路径正好是 src&#x2F;main&#x2F;java&#x2F;com&#x2F;bmz&#x2F;demo&#x2F;Hello.java<br>也就是说 java 的包名和路径是完全一致的.<br>但 java 引用的基本单位是 class, 而不是 package, 也就是我们经常看到<br><code>import java.util.List;</code><br>这样的代码,其实是引用 java.util 包下的 List class</p><p>回到 Go package, Go 的引用最小粒度是包,所以我们写不出引用某某包下的 xxx struct 或者 xxx interface 这种写法</p><p>比较下来,java 的包更多是确定一个 class 的位置, class 才是核心;<br>而 Go 的包是引用的最小单位,一个包下面各种变量都应该围绕这个包的功能来确定;<br>所以一个好的 gopher,应该避免类似 utils, xxx-common 这种没有意义的包,而是用实际的意义来命名包.<br>因为 java 里写 import java.util.List 可以在import 的地方看出这是一个 List 对象;<br>但在 Go 里写 import util 并不知道这个包是干嘛的.<br>现在回过头来思考一下,本身把 struct 比作 class 就是错误的比方.</p><blockquote><p>后续有空写一下我总结的编程命名规范</p></blockquote><p>上面是从开发者角度来解释的,其实 Go package 还有个重要功能是加速编译.<br>因为每个源文件开头就显示指出了一个.go 引用了哪些包,编译器无需读取全部文件就知道一个文件的依赖列表了.<br>Go 有一个要求,不允许包存在循环依赖,这样通过总结各个.go 的依赖列表,就能形成一个 DAG 了.<br>已经编译的包对应的目标文件(xxx.a xxx.o) 不仅记录了导出符号,还记录了依赖包的导出符合.因此编译器在编译一个包 P 的时候,针对 P 依赖的每个包导入,只需要读取一个.a 或者 .o 文件就够了.</p><blockquote><p>后续写一下 Go 是编译构建的过程</p></blockquote><h2 id="对我影响最大的一些项目和人"><a href="#对我影响最大的一些项目和人" class="headerlink" title="对我影响最大的一些项目和人"></a>对我影响最大的一些项目和人</h2><p>百度晁老师, 看他的博客学习了很多<br>我在百度的第一任组长淼哥,带我进入 Go 的世界<br>hashicorp terraform, 对我很多工作具有指导意义的项目<br>cobra 脚手架, 我用它写很多命令行工具,后来发现还有 grumble</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes-learning-summary</title>
      <link href="/2025/02/06/kubernetes-learning-summary/"/>
      <url>/2025/02/06/kubernetes-learning-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>我本科正好是软件工程专业的,知道传统软件研发是有生命周期的,大抵是指 可行性分析-全局设计-详细设计-coding-各种测试-灰度部署-正式部署-运维.<br>学生时期其实已经在接触虚拟机,在虚拟机上部署自己开发的小破程序,学生时代不以为然,无非是课程实验的要求罢了.<br>可是在大数据领域研发从业5年,同时在云计算领域也从业4年后,发现课本里的设计编码测试有各种改进,本质没变;但运维部署环节早就被颠覆了.<br>当然这个颠覆是因为 devops 兴起了, CI&#x2F;CD 各种概念成熟了.K8S 正好是简化 CI&#x2F;CD 的一个标志性技术.<br>于此之外,各种云厂商也在推 k8s 去部署自己的应用,利用 k8s 自动化运维,我对这个被各种大 V 鼓吹的项目更感兴趣了.<br>让我下定决心去了解K8S,还是因为我在百度的产品本身提供的服务被各种用户挑战了, serverless 的概念已经成为各种 paas 产品的下一个方向, 基于虚机提供 paas 虽有市场,但似乎对于新的业务, 基于容器的 serverless 形态才是更优的选择.<br>知其然,也要知其所以然,学习 K8S 已经是后端 RD 学习地图里的必然路径之一了.</p><h2 id="What-is-K8s"><a href="#What-is-K8s" class="headerlink" title="What is K8s"></a>What is K8s</h2><p>一句话:k8s 是<strong>开源容器编排平台</strong>,可以用声明式 API 来自动化部署,管理和扩展容器化应用.<br>k8s 本身分为两个大的部分:<strong>控制平面(master 节点)</strong> 和 <strong>计算设备(计算节点)</strong>, 我称之为 <strong>组件</strong><br>k8s 对外提供的一些灵活扩展性接口,我称之为 插件<br>围绕 k8s 还有一些生态,这些软件本身和 k8s 无关,但是和 k8s 配合起来有不错的效果,我称之为 <strong>附件</strong><br><img src="/2025/02/06/kubernetes-learning-summary/kubernetes-cluster-architecture.svg" alt="k8s 架构图"><br>k8s 的指导思想是 google borg,或者说是 google omega.这个指导思想体现在控制平面上</p><h2 id="控制平面"><a href="#控制平面" class="headerlink" title="控制平面"></a>控制平面</h2><ol><li>kube-apiserver<br>HTTP 服务器,用来管理全部的 API 对象</li><li>kube-scheduler<br>查找尚未绑定到节点的 pod, 以及将 pod 分配给合适的节点</li><li>kube-controler-manager<br>运行各种控制器来实现 k8s api 行为,定期检查集群状态是否和预期相符合</li><li>etcd<br>分布式,强一致性的 KV 存储,保存持久化信息.<blockquote><p>etcd 我在工作中也有一些研究,后续结合 raft 写一篇博客总结</p></blockquote></li><li>cloud-controller-manager(optional)<br>和各个云厂商驱动集成</li></ol><h2 id="计算设备"><a href="#计算设备" class="headerlink" title="计算设备"></a>计算设备</h2><ol><li>kebelet<br>确保 pod 和容器正常运行,解决的是容器的创建和删除</li><li>kube-proxy(optional)<br>监听 api-server,维护节点网络规则,解决负载均衡问题,以实现 Service 功能</li><li>container runtime<br>运行容器的软件,典型的有 containerd, CRI-O, Docker Engine, Mirantis, podman</li></ol><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><ol><li>CoreDNS<br>提供私有域名解析方式,可以让我们用域名来访问服务</li><li>Ingress Controller<br>官方提供了接口,可以实现七层的负载均衡</li></ol><h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><ol><li>Promethus<br>监控</li><li>Dashboard<br>可视化</li><li>Federation<br>多 k8s 集群跨空间的管理能力<blockquote><p>2015年捐赠给 CNCF 作为开源项目.<br>PS:有兴趣的可以去看一下&lt;深入剖析 kubernetes&gt; 这本书第一章,讲述了docker, 容器, 以及 k8s 的发展史.</p></blockquote></li></ol><p><img src="/2025/02/06/kubernetes-learning-summary/Container_Evolution.svg" alt="容器演进过程"></p><h2 id="Why-k8s"><a href="#Why-k8s" class="headerlink" title="Why k8s"></a>Why k8s</h2><p>一句话:容器是打包和运行应用的标准来,而 K8S 提供一个弹性运行分布式系统的框架,来满足多个容器之前的各种复杂关系,比如扩展需求,故障迁移,自我修复等<br>那为什么用 k8s, 不能有其他东西替代吗? 有,但是不如 k8s 好<br>与 k8s 定位类似的项目有2个, docker swarm 和 mesos(同样也是 yarn 的一个竞对)</p><ol><li>docker swarm 是围绕 docker 而存在的,比较轻量级,功能上和 K8s 比欠缺,比较有名的云厂商已经抛弃基于他提供服务了</li><li>mesos 是 UCB 开源的一个资源管理项目,最有名的企业用户是 twitter,年头比较长(在 hadoop2 yarn 诞生之前就有了),相对成熟一点,但设计初衷是管理机器上的进程,而不是管理容器.<br>或者说正是 docker 容器的兴起,加之后面 k8s 在开源社区的影响力,摧毁了 mesos 的市场<br>众所周知 k8s 是个容器编排系统.<br>经过我浅浅的了解,k8s 本质工作是通过声明式 api 让各个容器达到使用者的预期状态.<br>如果是纯编排的,似乎 terraform 就可以完成了.<br>terraform 是专门管理云环境的虚机,各种云服务实例,网络,计算,存储资源的软件<br>K8S 是管理容器,以及容器与容器之前关系的软件<blockquote><p>后续也专门写一篇 hashicorp terraform 的介绍吧</p></blockquote></li></ol><h2 id="When-use-k8s"><a href="#When-use-k8s" class="headerlink" title="When use k8s"></a>When use k8s</h2><p>当要使用的容器需要以下的功能时:</p><ol><li>服务发现和负载均衡</li><li>存储编排(添加本地或云服务器)</li><li>自动部署和回滚</li><li>弹性伸缩</li><li>自我修复</li><li>安全和配置管理 </li><li>大规模 </li><li>开源,不和某家的商业产品绑死</li></ol>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>why-should-I-wirte-blog</title>
      <link href="/2025/01/23/why-should-I-wirte-blog/"/>
      <url>/2025/01/23/why-should-I-wirte-blog/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么写博客"><a href="#为什么写博客" class="headerlink" title="为什么写博客"></a>为什么写博客</h2><p>在2024年底找工作的这段时间里,我意识到工作中积累的很多知识,没有被系统性的储存和整理.<br>我其实是个很愿意去折腾和学习技术的人,我也一直对技术保持热情,但我的知识笔记都是零散的,我至少在</p><ol><li>3种在线服务</li><li>2个桌面软件</li><li>公司 macbook, 以及 linux 开发机里的私人代码库</li><li>iphone 备忘录 各种软件的收藏夹<br>存储各式各样的知识,大部分是我自己编写的知识总结和工作实践,也有小部分是我看到的优秀项目 copy.<br>这些零散的记录对我自己长期发展几乎没有帮助,而且大多情况下还会出现知识的冗余和不一致.<br>经过了一段时间的自我思考,我秉承着日拱一卒,功不唐捐的态度,决定搭建自己的博客.<br>说来惭愧,写第一篇 blog 时,我已经本科毕业5年半了.</li></ol><h2 id="写哪些-topic"><a href="#写哪些-topic" class="headerlink" title="写哪些 topic"></a>写哪些 topic</h2><ol><li>论文译文和自己的心得</li><li>技术底层&#x2F;源码分析</li><li>工作中 case 排查的步骤</li><li>各种服务的搭建&#x2F;部署教程</li><li>一些开发工具的使用心得, shortcut usage 和 magic func</li><li>各种编程语言中超过设计模式之外的妙用<br>伴随着2025新的工作旅程,希望自己能坚持写博客.毕竟 苟有恒 最无益</li></ol>]]></content>
      
      
      <categories>
          
          <category> Chat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Chat </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
